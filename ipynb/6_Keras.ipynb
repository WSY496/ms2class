{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, GaussianNoise, GaussianDropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from  keras.regularizers import l1, l2\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\", \n",
    "        allow_growth=True,\n",
    "#         per_process_gpu_memory_fraction=0.5\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD35_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 7s 6ms/step - loss: 1.9805 - acc: 0.2694 - val_loss: 1.4347 - val_acc: 0.2827\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.8146 - acc: 0.2687 - val_loss: 1.4782 - val_acc: 0.3244\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.7504 - acc: 0.3030 - val_loss: 1.4241 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.6849 - acc: 0.3104 - val_loss: 1.3657 - val_acc: 0.3512\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.7023 - acc: 0.3172 - val_loss: 1.2952 - val_acc: 0.3899\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.5395 - acc: 0.3343 - val_loss: 1.2399 - val_acc: 0.4137\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.5223 - acc: 0.3478 - val_loss: 1.2339 - val_acc: 0.4583\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.5516 - acc: 0.3567 - val_loss: 1.2283 - val_acc: 0.4345\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.5128 - acc: 0.3642 - val_loss: 1.2178 - val_acc: 0.4345\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.4607 - acc: 0.3754 - val_loss: 1.2021 - val_acc: 0.4464\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.4348 - acc: 0.4075 - val_loss: 1.1833 - val_acc: 0.5119\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.3429 - acc: 0.4172 - val_loss: 1.1770 - val_acc: 0.4464\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.3490 - acc: 0.4209 - val_loss: 1.1696 - val_acc: 0.4226\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.2676 - acc: 0.4664 - val_loss: 1.1553 - val_acc: 0.4226\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.2131 - acc: 0.4604 - val_loss: 1.1337 - val_acc: 0.4375\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.1952 - acc: 0.4470 - val_loss: 1.1098 - val_acc: 0.4464\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.2115 - acc: 0.5030 - val_loss: 1.0912 - val_acc: 0.4762\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.1263 - acc: 0.5142 - val_loss: 1.0741 - val_acc: 0.4970\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0949 - acc: 0.5373 - val_loss: 1.0541 - val_acc: 0.5595\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0975 - acc: 0.5254 - val_loss: 1.0413 - val_acc: 0.5952\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0759 - acc: 0.5485 - val_loss: 1.0352 - val_acc: 0.5417\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0206 - acc: 0.5604 - val_loss: 1.0285 - val_acc: 0.5446\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0176 - acc: 0.5739 - val_loss: 1.0164 - val_acc: 0.6012\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.9669 - acc: 0.6000 - val_loss: 1.0044 - val_acc: 0.6220\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.8984 - acc: 0.6045 - val_loss: 0.9945 - val_acc: 0.6488\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.8704 - acc: 0.6328 - val_loss: 0.9860 - val_acc: 0.6399\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.9211 - acc: 0.6149 - val_loss: 0.9805 - val_acc: 0.6458\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.8589 - acc: 0.6396 - val_loss: 0.9727 - val_acc: 0.6280\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.8276 - acc: 0.6567 - val_loss: 0.9672 - val_acc: 0.6399\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.8127 - acc: 0.6687 - val_loss: 0.9622 - val_acc: 0.6369\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.7534 - acc: 0.6866 - val_loss: 0.9565 - val_acc: 0.6280\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.7695 - acc: 0.6821 - val_loss: 0.9528 - val_acc: 0.6161\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.7529 - acc: 0.6933 - val_loss: 0.9492 - val_acc: 0.6131\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.7241 - acc: 0.6955 - val_loss: 0.9453 - val_acc: 0.6339\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.7194 - acc: 0.7000 - val_loss: 0.9424 - val_acc: 0.6369\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.6902 - acc: 0.7201 - val_loss: 0.9368 - val_acc: 0.6399\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.6295 - acc: 0.7507 - val_loss: 0.9288 - val_acc: 0.6637\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.6172 - acc: 0.7425 - val_loss: 0.9232 - val_acc: 0.6905\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.6148 - acc: 0.7493 - val_loss: 0.9174 - val_acc: 0.7083\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.6033 - acc: 0.7634 - val_loss: 0.9162 - val_acc: 0.7232\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.5963 - acc: 0.7619 - val_loss: 0.9173 - val_acc: 0.7381\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.5028 - acc: 0.7888 - val_loss: 0.9205 - val_acc: 0.7262\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4963 - acc: 0.8022 - val_loss: 0.9237 - val_acc: 0.7173\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.4762 - acc: 0.8119 - val_loss: 0.9273 - val_acc: 0.6845\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.4706 - acc: 0.8134 - val_loss: 0.9308 - val_acc: 0.6786\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.4284 - acc: 0.8291 - val_loss: 0.9298 - val_acc: 0.6845\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4308 - acc: 0.8351 - val_loss: 0.9260 - val_acc: 0.7054\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3536 - acc: 0.8709 - val_loss: 0.9265 - val_acc: 0.7173\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3914 - acc: 0.8463 - val_loss: 0.9344 - val_acc: 0.7054\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3864 - acc: 0.8537 - val_loss: 0.9508 - val_acc: 0.7024\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.3305 - acc: 0.8791 - val_loss: 0.9682 - val_acc: 0.6964\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.3472 - acc: 0.8858 - val_loss: 0.9791 - val_acc: 0.6935\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.3161 - acc: 0.8866 - val_loss: 0.9815 - val_acc: 0.6845\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3032 - acc: 0.8873 - val_loss: 0.9880 - val_acc: 0.6905\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.2964 - acc: 0.9000 - val_loss: 0.9965 - val_acc: 0.6905\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2656 - acc: 0.9045 - val_loss: 0.9969 - val_acc: 0.6875\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2717 - acc: 0.9037 - val_loss: 0.9953 - val_acc: 0.6905\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2669 - acc: 0.9067 - val_loss: 0.9978 - val_acc: 0.6964\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.2418 - acc: 0.9134 - val_loss: 1.0030 - val_acc: 0.6964\n",
      "Epoch 60/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.2526 - acc: 0.9194 - val_loss: 1.0075 - val_acc: 0.6845\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD35_pos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "j = []\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f = []\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6845238095238095"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD45_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 7s 5ms/step - loss: 1.9418 - acc: 0.2560 - val_loss: 1.4291 - val_acc: 0.2917\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.8003 - acc: 0.2642 - val_loss: 1.4512 - val_acc: 0.3393\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.7191 - acc: 0.2978 - val_loss: 1.4419 - val_acc: 0.3571\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.6577 - acc: 0.2754 - val_loss: 1.3741 - val_acc: 0.3601\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.6417 - acc: 0.3067 - val_loss: 1.3110 - val_acc: 0.3631\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.5214 - acc: 0.3284 - val_loss: 1.2601 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.5267 - acc: 0.3627 - val_loss: 1.2241 - val_acc: 0.4256\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.5502 - acc: 0.3769 - val_loss: 1.2223 - val_acc: 0.4137\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.4555 - acc: 0.3828 - val_loss: 1.2266 - val_acc: 0.4256\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.4339 - acc: 0.3769 - val_loss: 1.2338 - val_acc: 0.4762\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.3745 - acc: 0.4037 - val_loss: 1.2353 - val_acc: 0.4196\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.3198 - acc: 0.4045 - val_loss: 1.2239 - val_acc: 0.4524\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.3075 - acc: 0.4328 - val_loss: 1.1962 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.3002 - acc: 0.4328 - val_loss: 1.1829 - val_acc: 0.4494\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.2759 - acc: 0.4351 - val_loss: 1.1681 - val_acc: 0.4673\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.2495 - acc: 0.4582 - val_loss: 1.1544 - val_acc: 0.4762\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.2181 - acc: 0.4575 - val_loss: 1.1446 - val_acc: 0.5119\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.1615 - acc: 0.4701 - val_loss: 1.1357 - val_acc: 0.5446\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.1560 - acc: 0.5045 - val_loss: 1.1264 - val_acc: 0.5595\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.1381 - acc: 0.4948 - val_loss: 1.1150 - val_acc: 0.5714\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.1732 - acc: 0.5000 - val_loss: 1.1005 - val_acc: 0.5774\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0941 - acc: 0.5172 - val_loss: 1.0846 - val_acc: 0.5923\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0847 - acc: 0.5231 - val_loss: 1.0651 - val_acc: 0.5714\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0681 - acc: 0.5366 - val_loss: 1.0518 - val_acc: 0.5655\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.0371 - acc: 0.5433 - val_loss: 1.0420 - val_acc: 0.5774\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.0218 - acc: 0.5731 - val_loss: 1.0321 - val_acc: 0.5595\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 945us/step - loss: 0.9609 - acc: 0.5828 - val_loss: 1.0249 - val_acc: 0.5506\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 934us/step - loss: 0.9482 - acc: 0.5724 - val_loss: 1.0207 - val_acc: 0.5327\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 913us/step - loss: 0.9428 - acc: 0.5955 - val_loss: 1.0120 - val_acc: 0.5357\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 916us/step - loss: 0.9342 - acc: 0.5888 - val_loss: 1.0027 - val_acc: 0.5446\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 938us/step - loss: 0.9035 - acc: 0.6104 - val_loss: 0.9919 - val_acc: 0.5506\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 0.8934 - acc: 0.6246 - val_loss: 0.9794 - val_acc: 0.5714\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 925us/step - loss: 0.9037 - acc: 0.6067 - val_loss: 0.9713 - val_acc: 0.6220\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 922us/step - loss: 0.8443 - acc: 0.6313 - val_loss: 0.9654 - val_acc: 0.6280\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 938us/step - loss: 0.8556 - acc: 0.6254 - val_loss: 0.9583 - val_acc: 0.6399\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 923us/step - loss: 0.8293 - acc: 0.6604 - val_loss: 0.9542 - val_acc: 0.6220\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 921us/step - loss: 0.7968 - acc: 0.6604 - val_loss: 0.9535 - val_acc: 0.5982\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 921us/step - loss: 0.7870 - acc: 0.6679 - val_loss: 0.9497 - val_acc: 0.5923\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 911us/step - loss: 0.8014 - acc: 0.6709 - val_loss: 0.9399 - val_acc: 0.6101\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 902us/step - loss: 0.7564 - acc: 0.6791 - val_loss: 0.9312 - val_acc: 0.6429\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 913us/step - loss: 0.7206 - acc: 0.7030 - val_loss: 0.9259 - val_acc: 0.6488\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 919us/step - loss: 0.6838 - acc: 0.7261 - val_loss: 0.9227 - val_acc: 0.6131\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 948us/step - loss: 0.6665 - acc: 0.7209 - val_loss: 0.9201 - val_acc: 0.6012\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 957us/step - loss: 0.6504 - acc: 0.7187 - val_loss: 0.9205 - val_acc: 0.5982\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 0.6176 - acc: 0.7493 - val_loss: 0.9199 - val_acc: 0.5923\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 921us/step - loss: 0.5928 - acc: 0.7493 - val_loss: 0.9070 - val_acc: 0.5982\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 909us/step - loss: 0.5688 - acc: 0.7791 - val_loss: 0.8887 - val_acc: 0.6161\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 894us/step - loss: 0.4989 - acc: 0.8022 - val_loss: 0.8752 - val_acc: 0.6369\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 939us/step - loss: 0.5102 - acc: 0.7918 - val_loss: 0.8649 - val_acc: 0.6518\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 934us/step - loss: 0.5055 - acc: 0.8007 - val_loss: 0.8654 - val_acc: 0.6429\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 939us/step - loss: 0.4749 - acc: 0.8134 - val_loss: 0.8695 - val_acc: 0.6458\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 954us/step - loss: 0.4222 - acc: 0.8493 - val_loss: 0.8675 - val_acc: 0.6399\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 899us/step - loss: 0.4092 - acc: 0.8448 - val_loss: 0.8671 - val_acc: 0.6429\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 0.3793 - acc: 0.8642 - val_loss: 0.8775 - val_acc: 0.6310\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 0.3738 - acc: 0.8619 - val_loss: 0.8880 - val_acc: 0.6310\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 1s 939us/step - loss: 0.3488 - acc: 0.8799 - val_loss: 0.9059 - val_acc: 0.6161\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 1s 957us/step - loss: 0.3500 - acc: 0.8769 - val_loss: 0.9131 - val_acc: 0.6220\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 1s 942us/step - loss: 0.2919 - acc: 0.9000 - val_loss: 0.9117 - val_acc: 0.6280\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 1s 934us/step - loss: 0.2810 - acc: 0.8866 - val_loss: 0.8984 - val_acc: 0.6607\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 1s 913us/step - loss: 0.2595 - acc: 0.9149 - val_loss: 0.8870 - val_acc: 0.6696\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 1s 920us/step - loss: 0.2539 - acc: 0.9149 - val_loss: 0.8776 - val_acc: 0.6786\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 1s 964us/step - loss: 0.2456 - acc: 0.9052 - val_loss: 0.8690 - val_acc: 0.6786\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 1s 962us/step - loss: 0.2446 - acc: 0.9127 - val_loss: 0.8671 - val_acc: 0.6726\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 1s 912us/step - loss: 0.2217 - acc: 0.9246 - val_loss: 0.8712 - val_acc: 0.6845\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 1s 916us/step - loss: 0.2203 - acc: 0.9179 - val_loss: 0.8741 - val_acc: 0.6845\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 1s 924us/step - loss: 0.2270 - acc: 0.9224 - val_loss: 0.8766 - val_acc: 0.6905\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 1s 908us/step - loss: 0.1947 - acc: 0.9336 - val_loss: 0.8769 - val_acc: 0.6875\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 1s 913us/step - loss: 0.2253 - acc: 0.9269 - val_loss: 0.8810 - val_acc: 0.6875\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 1s 949us/step - loss: 0.1909 - acc: 0.9410 - val_loss: 0.8840 - val_acc: 0.6845\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD45_pos.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD65_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 5s 4ms/step - loss: 1.9229 - acc: 0.2701 - val_loss: 1.4263 - val_acc: 0.2798\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 1.7823 - acc: 0.2634 - val_loss: 1.4422 - val_acc: 0.3185\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.7569 - acc: 0.2903 - val_loss: 1.4050 - val_acc: 0.3304\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.6661 - acc: 0.2769 - val_loss: 1.3725 - val_acc: 0.3423\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 1.6190 - acc: 0.3104 - val_loss: 1.3171 - val_acc: 0.3571\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.5514 - acc: 0.3142 - val_loss: 1.2756 - val_acc: 0.3690\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.5300 - acc: 0.3396 - val_loss: 1.2414 - val_acc: 0.4554\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.5409 - acc: 0.3552 - val_loss: 1.2303 - val_acc: 0.4048\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.4779 - acc: 0.3373 - val_loss: 1.2369 - val_acc: 0.4137\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.4455 - acc: 0.3612 - val_loss: 1.2461 - val_acc: 0.4167\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.4141 - acc: 0.3813 - val_loss: 1.2498 - val_acc: 0.4107\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.3738 - acc: 0.3806 - val_loss: 1.2426 - val_acc: 0.4167\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.4073 - acc: 0.3776 - val_loss: 1.2269 - val_acc: 0.4196\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.3505 - acc: 0.3843 - val_loss: 1.2091 - val_acc: 0.4256\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.3413 - acc: 0.3881 - val_loss: 1.1961 - val_acc: 0.4405\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2990 - acc: 0.3978 - val_loss: 1.1859 - val_acc: 0.4821\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.3040 - acc: 0.4261 - val_loss: 1.1797 - val_acc: 0.5268\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2726 - acc: 0.4142 - val_loss: 1.1752 - val_acc: 0.5327\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2740 - acc: 0.4328 - val_loss: 1.1702 - val_acc: 0.5060\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2790 - acc: 0.4246 - val_loss: 1.1617 - val_acc: 0.4970\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2634 - acc: 0.4216 - val_loss: 1.1522 - val_acc: 0.4851\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2335 - acc: 0.4321 - val_loss: 1.1418 - val_acc: 0.4702\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2091 - acc: 0.4716 - val_loss: 1.1300 - val_acc: 0.4792\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.1781 - acc: 0.4687 - val_loss: 1.1197 - val_acc: 0.4881\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.1853 - acc: 0.4694 - val_loss: 1.1107 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2037 - acc: 0.4597 - val_loss: 1.1031 - val_acc: 0.5179\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.1777 - acc: 0.4731 - val_loss: 1.0966 - val_acc: 0.5268\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.1186 - acc: 0.4948 - val_loss: 1.0904 - val_acc: 0.5238\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0904 - acc: 0.5037 - val_loss: 1.0841 - val_acc: 0.5238\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0963 - acc: 0.5075 - val_loss: 1.0803 - val_acc: 0.5149\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0773 - acc: 0.5291 - val_loss: 1.0770 - val_acc: 0.4970\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0772 - acc: 0.5254 - val_loss: 1.0729 - val_acc: 0.4881\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0721 - acc: 0.5343 - val_loss: 1.0684 - val_acc: 0.4851\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0372 - acc: 0.5455 - val_loss: 1.0614 - val_acc: 0.4911\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0823 - acc: 0.5276 - val_loss: 1.0517 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0631 - acc: 0.5187 - val_loss: 1.0449 - val_acc: 0.4970\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.0158 - acc: 0.5694 - val_loss: 1.0406 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.9897 - acc: 0.5694 - val_loss: 1.0356 - val_acc: 0.5089\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.9587 - acc: 0.5694 - val_loss: 1.0301 - val_acc: 0.5089\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.9556 - acc: 0.5873 - val_loss: 1.0207 - val_acc: 0.5149\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.9388 - acc: 0.5933 - val_loss: 1.0077 - val_acc: 0.5357\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.8875 - acc: 0.6306 - val_loss: 0.9970 - val_acc: 0.5476\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.8681 - acc: 0.6284 - val_loss: 0.9902 - val_acc: 0.5744\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.8494 - acc: 0.6269 - val_loss: 0.9873 - val_acc: 0.6190\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.8529 - acc: 0.6358 - val_loss: 0.9880 - val_acc: 0.5744\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.8177 - acc: 0.6597 - val_loss: 0.9851 - val_acc: 0.5714\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.8159 - acc: 0.6567 - val_loss: 0.9758 - val_acc: 0.5863\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.7213 - acc: 0.6873 - val_loss: 0.9659 - val_acc: 0.6012\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.7353 - acc: 0.6881 - val_loss: 0.9559 - val_acc: 0.6220\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.7271 - acc: 0.6993 - val_loss: 0.9495 - val_acc: 0.6012\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.6950 - acc: 0.7030 - val_loss: 0.9442 - val_acc: 0.5982\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.7127 - acc: 0.7164 - val_loss: 0.9427 - val_acc: 0.6280\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.6673 - acc: 0.7261 - val_loss: 0.9508 - val_acc: 0.5863\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.6216 - acc: 0.7470 - val_loss: 0.9635 - val_acc: 0.5685\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.6269 - acc: 0.7388 - val_loss: 0.9780 - val_acc: 0.5387\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5974 - acc: 0.7530 - val_loss: 0.9923 - val_acc: 0.5208\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5932 - acc: 0.7433 - val_loss: 0.9988 - val_acc: 0.5238\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.5802 - acc: 0.7739 - val_loss: 0.9916 - val_acc: 0.5298\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.5309 - acc: 0.7709 - val_loss: 0.9746 - val_acc: 0.5476\n",
      "Epoch 60/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.5334 - acc: 0.7754 - val_loss: 0.9629 - val_acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.5350 - acc: 0.8045 - val_loss: 0.9519 - val_acc: 0.5804\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4747 - acc: 0.8060 - val_loss: 0.9410 - val_acc: 0.5952\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4287 - acc: 0.8269 - val_loss: 0.9351 - val_acc: 0.6042\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4500 - acc: 0.8336 - val_loss: 0.9271 - val_acc: 0.6190\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4511 - acc: 0.8276 - val_loss: 0.9221 - val_acc: 0.6250\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4464 - acc: 0.8269 - val_loss: 0.9274 - val_acc: 0.6071\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4028 - acc: 0.8351 - val_loss: 0.9322 - val_acc: 0.6042\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4044 - acc: 0.8500 - val_loss: 0.9311 - val_acc: 0.6012\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3536 - acc: 0.8642 - val_loss: 0.9257 - val_acc: 0.6161\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3927 - acc: 0.8530 - val_loss: 0.9189 - val_acc: 0.6280\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3710 - acc: 0.8634 - val_loss: 0.9251 - val_acc: 0.6101\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3857 - acc: 0.8552 - val_loss: 0.9425 - val_acc: 0.5923\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3257 - acc: 0.8716 - val_loss: 0.9600 - val_acc: 0.5744\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3103 - acc: 0.8806 - val_loss: 0.9684 - val_acc: 0.5714\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3075 - acc: 0.8799 - val_loss: 0.9550 - val_acc: 0.5893\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3317 - acc: 0.8739 - val_loss: 0.9392 - val_acc: 0.5982\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3400 - acc: 0.8881 - val_loss: 0.9329 - val_acc: 0.6131\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.3103 - acc: 0.8754 - val_loss: 0.9227 - val_acc: 0.6339\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2954 - acc: 0.8866 - val_loss: 0.9118 - val_acc: 0.6429\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3161 - acc: 0.8918 - val_loss: 0.9101 - val_acc: 0.6458\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2955 - acc: 0.9007 - val_loss: 0.9116 - val_acc: 0.6458\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2728 - acc: 0.9015 - val_loss: 0.9074 - val_acc: 0.6458\n",
      "Epoch 83/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2670 - acc: 0.9030 - val_loss: 0.9001 - val_acc: 0.6458\n",
      "Epoch 84/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2627 - acc: 0.9082 - val_loss: 0.9004 - val_acc: 0.6607\n",
      "Epoch 85/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2481 - acc: 0.9097 - val_loss: 0.9103 - val_acc: 0.6429\n",
      "Epoch 86/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2570 - acc: 0.9015 - val_loss: 0.9239 - val_acc: 0.6220\n",
      "Epoch 87/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2297 - acc: 0.9164 - val_loss: 0.9277 - val_acc: 0.6131\n",
      "Epoch 88/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2206 - acc: 0.9231 - val_loss: 0.9307 - val_acc: 0.6042\n",
      "Epoch 89/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2197 - acc: 0.9187 - val_loss: 0.9307 - val_acc: 0.6161\n",
      "Epoch 90/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2054 - acc: 0.9336 - val_loss: 0.9303 - val_acc: 0.6190\n",
      "Epoch 91/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2346 - acc: 0.9201 - val_loss: 0.9336 - val_acc: 0.6190\n",
      "Epoch 92/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.1875 - acc: 0.9313 - val_loss: 0.9379 - val_acc: 0.6012\n",
      "Epoch 93/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2092 - acc: 0.9306 - val_loss: 0.9346 - val_acc: 0.6042\n",
      "Epoch 94/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2226 - acc: 0.9201 - val_loss: 0.9234 - val_acc: 0.6190\n",
      "Epoch 95/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.2068 - acc: 0.9276 - val_loss: 0.9226 - val_acc: 0.6250\n",
      "Epoch 96/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.1816 - acc: 0.9313 - val_loss: 0.9171 - val_acc: 0.6310\n",
      "Epoch 97/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.1858 - acc: 0.9321 - val_loss: 0.9036 - val_acc: 0.6458\n",
      "Epoch 98/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.1965 - acc: 0.9306 - val_loss: 0.8902 - val_acc: 0.6637\n",
      "Epoch 99/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.2075 - acc: 0.9306 - val_loss: 0.8750 - val_acc: 0.6696\n",
      "Epoch 100/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.1977 - acc: 0.9343 - val_loss: 0.8557 - val_acc: 0.6905\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD65_pos.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD35_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 3s 8ms/step - loss: 2.0533 - acc: 0.3351 - val_loss: 1.2986 - val_acc: 0.4362\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 269us/step - loss: 1.8480 - acc: 0.3029 - val_loss: 1.2835 - val_acc: 0.4362\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 275us/step - loss: 1.8657 - acc: 0.2895 - val_loss: 1.3194 - val_acc: 0.4574\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 280us/step - loss: 1.9364 - acc: 0.3003 - val_loss: 1.3557 - val_acc: 0.4574\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 264us/step - loss: 1.6219 - acc: 0.3512 - val_loss: 1.3658 - val_acc: 0.4468\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 265us/step - loss: 1.6639 - acc: 0.3834 - val_loss: 1.3645 - val_acc: 0.4574\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 275us/step - loss: 1.7337 - acc: 0.3780 - val_loss: 1.3318 - val_acc: 0.4894\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 295us/step - loss: 1.6004 - acc: 0.3995 - val_loss: 1.2851 - val_acc: 0.4894\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 274us/step - loss: 1.6495 - acc: 0.3995 - val_loss: 1.2404 - val_acc: 0.4894\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 267us/step - loss: 1.5223 - acc: 0.3753 - val_loss: 1.1909 - val_acc: 0.5106\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 258us/step - loss: 1.4015 - acc: 0.4450 - val_loss: 1.1336 - val_acc: 0.5319\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 296us/step - loss: 1.3890 - acc: 0.4209 - val_loss: 1.0891 - val_acc: 0.5319\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 269us/step - loss: 1.4892 - acc: 0.3834 - val_loss: 1.0532 - val_acc: 0.5426\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 277us/step - loss: 1.2998 - acc: 0.4343 - val_loss: 1.0268 - val_acc: 0.5638\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 279us/step - loss: 1.4375 - acc: 0.4182 - val_loss: 1.0071 - val_acc: 0.5745\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 259us/step - loss: 1.3077 - acc: 0.4424 - val_loss: 0.9948 - val_acc: 0.5745\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 273us/step - loss: 1.2504 - acc: 0.5308 - val_loss: 0.9805 - val_acc: 0.5745\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 270us/step - loss: 1.1683 - acc: 0.4692 - val_loss: 0.9701 - val_acc: 0.6064\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 267us/step - loss: 1.2321 - acc: 0.4853 - val_loss: 0.9697 - val_acc: 0.5851\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 259us/step - loss: 1.2445 - acc: 0.4853 - val_loss: 0.9626 - val_acc: 0.5851\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 264us/step - loss: 1.1943 - acc: 0.4772 - val_loss: 0.9618 - val_acc: 0.5745\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 270us/step - loss: 1.1382 - acc: 0.4960 - val_loss: 0.9573 - val_acc: 0.5851\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 267us/step - loss: 1.0770 - acc: 0.5228 - val_loss: 0.9574 - val_acc: 0.6170\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 263us/step - loss: 1.0448 - acc: 0.5362 - val_loss: 0.9551 - val_acc: 0.6277\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 274us/step - loss: 1.0523 - acc: 0.5067 - val_loss: 0.9554 - val_acc: 0.6170\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 273us/step - loss: 1.0941 - acc: 0.5550 - val_loss: 0.9528 - val_acc: 0.6170\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 289us/step - loss: 0.9955 - acc: 0.5684 - val_loss: 0.9481 - val_acc: 0.6064\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 267us/step - loss: 1.0009 - acc: 0.5657 - val_loss: 0.9453 - val_acc: 0.6064\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 265us/step - loss: 1.0589 - acc: 0.5228 - val_loss: 0.9369 - val_acc: 0.6277\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 268us/step - loss: 0.9969 - acc: 0.5845 - val_loss: 0.9228 - val_acc: 0.6277\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 277us/step - loss: 0.9509 - acc: 0.5791 - val_loss: 0.9089 - val_acc: 0.6383\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 277us/step - loss: 0.9091 - acc: 0.5925 - val_loss: 0.8884 - val_acc: 0.6383\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 278us/step - loss: 0.9004 - acc: 0.5925 - val_loss: 0.8695 - val_acc: 0.6383\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 306us/step - loss: 0.9232 - acc: 0.6086 - val_loss: 0.8502 - val_acc: 0.6489\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 310us/step - loss: 0.9127 - acc: 0.6059 - val_loss: 0.8347 - val_acc: 0.6489\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 305us/step - loss: 0.8641 - acc: 0.6166 - val_loss: 0.8199 - val_acc: 0.6489\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 293us/step - loss: 0.9484 - acc: 0.5791 - val_loss: 0.8129 - val_acc: 0.6489\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 284us/step - loss: 0.8415 - acc: 0.6649 - val_loss: 0.8070 - val_acc: 0.6277\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 259us/step - loss: 0.8249 - acc: 0.6193 - val_loss: 0.8054 - val_acc: 0.6277\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 268us/step - loss: 0.8353 - acc: 0.6488 - val_loss: 0.8061 - val_acc: 0.6277\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 282us/step - loss: 0.8175 - acc: 0.6622 - val_loss: 0.8069 - val_acc: 0.6277\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 280us/step - loss: 0.7701 - acc: 0.6729 - val_loss: 0.8078 - val_acc: 0.6277\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 286us/step - loss: 0.8023 - acc: 0.6649 - val_loss: 0.8071 - val_acc: 0.6277\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 304us/step - loss: 0.7734 - acc: 0.6676 - val_loss: 0.8132 - val_acc: 0.6277\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 260us/step - loss: 0.7402 - acc: 0.6836 - val_loss: 0.8186 - val_acc: 0.6383\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 286us/step - loss: 0.7303 - acc: 0.6890 - val_loss: 0.8239 - val_acc: 0.6383\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 276us/step - loss: 0.6835 - acc: 0.7239 - val_loss: 0.8254 - val_acc: 0.6383\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 275us/step - loss: 0.6613 - acc: 0.7212 - val_loss: 0.8319 - val_acc: 0.6383\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 260us/step - loss: 0.7307 - acc: 0.6971 - val_loss: 0.8374 - val_acc: 0.6489\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 271us/step - loss: 0.7214 - acc: 0.6971 - val_loss: 0.8447 - val_acc: 0.6383\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 273us/step - loss: 0.6976 - acc: 0.7024 - val_loss: 0.8517 - val_acc: 0.6383\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 274us/step - loss: 0.6444 - acc: 0.7265 - val_loss: 0.8622 - val_acc: 0.6383\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 286us/step - loss: 0.7347 - acc: 0.6997 - val_loss: 0.8750 - val_acc: 0.6383\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 296us/step - loss: 0.6237 - acc: 0.7426 - val_loss: 0.8895 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 317us/step - loss: 0.6752 - acc: 0.7212 - val_loss: 0.9075 - val_acc: 0.6383\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 288us/step - loss: 0.6590 - acc: 0.7319 - val_loss: 0.9217 - val_acc: 0.6383\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 301us/step - loss: 0.6771 - acc: 0.7239 - val_loss: 0.9269 - val_acc: 0.6383\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 291us/step - loss: 0.6016 - acc: 0.7560 - val_loss: 0.9304 - val_acc: 0.6596\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 263us/step - loss: 0.6096 - acc: 0.7534 - val_loss: 0.9388 - val_acc: 0.6596\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD35_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD45_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 4s 10ms/step - loss: 2.0206 - acc: 0.2869 - val_loss: 1.3158 - val_acc: 0.4362\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 327us/step - loss: 1.8925 - acc: 0.3056 - val_loss: 1.2813 - val_acc: 0.4468\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 315us/step - loss: 1.8854 - acc: 0.2949 - val_loss: 1.3499 - val_acc: 0.4362\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 310us/step - loss: 1.7426 - acc: 0.3566 - val_loss: 1.3973 - val_acc: 0.4574\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 325us/step - loss: 1.6474 - acc: 0.3727 - val_loss: 1.4106 - val_acc: 0.4574\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 325us/step - loss: 1.5675 - acc: 0.3834 - val_loss: 1.3840 - val_acc: 0.4574\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 340us/step - loss: 1.6529 - acc: 0.3646 - val_loss: 1.3524 - val_acc: 0.4574\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 352us/step - loss: 1.5853 - acc: 0.4209 - val_loss: 1.3101 - val_acc: 0.4681\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 338us/step - loss: 1.6059 - acc: 0.3458 - val_loss: 1.2548 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 311us/step - loss: 1.6598 - acc: 0.3566 - val_loss: 1.2045 - val_acc: 0.5319\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 344us/step - loss: 1.4284 - acc: 0.4129 - val_loss: 1.1569 - val_acc: 0.5319\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 357us/step - loss: 1.3824 - acc: 0.4611 - val_loss: 1.1146 - val_acc: 0.5426\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 356us/step - loss: 1.3966 - acc: 0.4397 - val_loss: 1.0770 - val_acc: 0.5532\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 363us/step - loss: 1.3077 - acc: 0.4477 - val_loss: 1.0471 - val_acc: 0.5745\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 365us/step - loss: 1.4486 - acc: 0.4048 - val_loss: 1.0210 - val_acc: 0.5745\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 373us/step - loss: 1.3181 - acc: 0.4611 - val_loss: 1.0034 - val_acc: 0.5851\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 318us/step - loss: 1.2680 - acc: 0.4853 - val_loss: 0.9896 - val_acc: 0.5851\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 339us/step - loss: 1.2530 - acc: 0.4638 - val_loss: 0.9789 - val_acc: 0.5851\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 320us/step - loss: 1.2659 - acc: 0.4450 - val_loss: 0.9712 - val_acc: 0.5851\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 326us/step - loss: 1.1785 - acc: 0.5174 - val_loss: 0.9675 - val_acc: 0.5851\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 326us/step - loss: 1.1161 - acc: 0.5496 - val_loss: 0.9615 - val_acc: 0.5851\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 323us/step - loss: 1.0871 - acc: 0.5255 - val_loss: 0.9578 - val_acc: 0.5851\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 309us/step - loss: 1.0893 - acc: 0.5228 - val_loss: 0.9565 - val_acc: 0.5851\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 315us/step - loss: 1.0353 - acc: 0.5684 - val_loss: 0.9523 - val_acc: 0.5851\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 324us/step - loss: 1.0416 - acc: 0.5603 - val_loss: 0.9521 - val_acc: 0.5851\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 321us/step - loss: 1.0382 - acc: 0.5523 - val_loss: 0.9489 - val_acc: 0.5851\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 314us/step - loss: 0.9786 - acc: 0.5684 - val_loss: 0.9414 - val_acc: 0.5851\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 341us/step - loss: 1.0256 - acc: 0.5791 - val_loss: 0.9332 - val_acc: 0.5851\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 313us/step - loss: 0.9617 - acc: 0.5684 - val_loss: 0.9256 - val_acc: 0.5957\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 321us/step - loss: 1.0550 - acc: 0.5710 - val_loss: 0.9156 - val_acc: 0.5957\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 309us/step - loss: 0.9685 - acc: 0.5684 - val_loss: 0.9075 - val_acc: 0.6170\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 313us/step - loss: 0.9786 - acc: 0.5737 - val_loss: 0.9030 - val_acc: 0.6277\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 328us/step - loss: 1.0151 - acc: 0.5845 - val_loss: 0.8968 - val_acc: 0.6277\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 314us/step - loss: 0.9358 - acc: 0.5657 - val_loss: 0.8931 - val_acc: 0.6277\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 306us/step - loss: 0.8657 - acc: 0.6354 - val_loss: 0.8904 - val_acc: 0.6383\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 327us/step - loss: 0.8248 - acc: 0.6434 - val_loss: 0.8909 - val_acc: 0.6383\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 321us/step - loss: 0.8994 - acc: 0.6139 - val_loss: 0.8905 - val_acc: 0.6489\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 331us/step - loss: 0.8403 - acc: 0.6247 - val_loss: 0.8902 - val_acc: 0.6596\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 352us/step - loss: 0.8595 - acc: 0.6461 - val_loss: 0.8914 - val_acc: 0.6596\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 345us/step - loss: 0.8268 - acc: 0.6354 - val_loss: 0.8919 - val_acc: 0.6383\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 507us/step - loss: 0.8099 - acc: 0.6676 - val_loss: 0.8927 - val_acc: 0.6489\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 535us/step - loss: 0.8000 - acc: 0.6381 - val_loss: 0.8949 - val_acc: 0.6489\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 520us/step - loss: 0.7805 - acc: 0.6676 - val_loss: 0.8969 - val_acc: 0.6489\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 563us/step - loss: 0.8057 - acc: 0.6381 - val_loss: 0.8991 - val_acc: 0.6383\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 532us/step - loss: 0.8285 - acc: 0.6702 - val_loss: 0.9019 - val_acc: 0.6383\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 437us/step - loss: 0.7487 - acc: 0.7131 - val_loss: 0.9040 - val_acc: 0.6489\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 354us/step - loss: 0.6987 - acc: 0.7239 - val_loss: 0.9088 - val_acc: 0.6489\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 346us/step - loss: 0.7540 - acc: 0.6756 - val_loss: 0.9164 - val_acc: 0.6596\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 418us/step - loss: 0.7482 - acc: 0.6944 - val_loss: 0.9224 - val_acc: 0.6596\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 443us/step - loss: 0.7080 - acc: 0.6997 - val_loss: 0.9269 - val_acc: 0.6596\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 389us/step - loss: 0.7094 - acc: 0.6971 - val_loss: 0.9304 - val_acc: 0.6596\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 523us/step - loss: 0.7066 - acc: 0.7131 - val_loss: 0.9361 - val_acc: 0.6489\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 688us/step - loss: 0.7240 - acc: 0.6944 - val_loss: 0.9428 - val_acc: 0.6596\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 621us/step - loss: 0.6715 - acc: 0.7158 - val_loss: 0.9524 - val_acc: 0.6596\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 631us/step - loss: 0.7420 - acc: 0.6863 - val_loss: 0.9635 - val_acc: 0.6596\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 401us/step - loss: 0.6583 - acc: 0.7319 - val_loss: 0.9765 - val_acc: 0.6489\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 331us/step - loss: 0.6959 - acc: 0.7212 - val_loss: 0.9885 - val_acc: 0.6489\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 335us/step - loss: 0.6057 - acc: 0.7373 - val_loss: 1.0022 - val_acc: 0.6489\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD45_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD65_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 4s 10ms/step - loss: 2.0837 - acc: 0.2869 - val_loss: 1.3364 - val_acc: 0.4043\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 485us/step - loss: 1.9090 - acc: 0.2976 - val_loss: 1.2452 - val_acc: 0.4255\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 463us/step - loss: 1.9388 - acc: 0.2976 - val_loss: 1.2644 - val_acc: 0.5106\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 461us/step - loss: 1.8523 - acc: 0.3190 - val_loss: 1.3075 - val_acc: 0.5106\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 458us/step - loss: 1.7209 - acc: 0.3485 - val_loss: 1.3087 - val_acc: 0.5106\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 472us/step - loss: 1.6821 - acc: 0.3512 - val_loss: 1.2787 - val_acc: 0.5106\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 483us/step - loss: 1.6443 - acc: 0.3592 - val_loss: 1.2445 - val_acc: 0.5106\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 493us/step - loss: 1.6083 - acc: 0.4021 - val_loss: 1.2066 - val_acc: 0.5106\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 459us/step - loss: 1.6956 - acc: 0.3458 - val_loss: 1.1669 - val_acc: 0.5106\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 480us/step - loss: 1.5086 - acc: 0.3914 - val_loss: 1.1338 - val_acc: 0.5106\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 469us/step - loss: 1.4918 - acc: 0.3780 - val_loss: 1.1024 - val_acc: 0.5213\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 462us/step - loss: 1.4130 - acc: 0.3968 - val_loss: 1.0747 - val_acc: 0.5532\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 475us/step - loss: 1.4579 - acc: 0.3780 - val_loss: 1.0574 - val_acc: 0.5532\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 457us/step - loss: 1.4227 - acc: 0.4075 - val_loss: 1.0428 - val_acc: 0.5532\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 459us/step - loss: 1.4699 - acc: 0.3995 - val_loss: 1.0312 - val_acc: 0.5532\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 486us/step - loss: 1.3890 - acc: 0.4209 - val_loss: 1.0240 - val_acc: 0.5638\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 472us/step - loss: 1.2604 - acc: 0.4397 - val_loss: 1.0165 - val_acc: 0.5638\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 489us/step - loss: 1.3184 - acc: 0.4316 - val_loss: 1.0099 - val_acc: 0.5532\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 476us/step - loss: 1.3730 - acc: 0.4263 - val_loss: 1.0046 - val_acc: 0.5638\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 450us/step - loss: 1.3128 - acc: 0.4236 - val_loss: 0.9995 - val_acc: 0.5638\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 494us/step - loss: 1.2931 - acc: 0.4584 - val_loss: 0.9944 - val_acc: 0.5638\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 507us/step - loss: 1.2582 - acc: 0.4370 - val_loss: 0.9914 - val_acc: 0.5745\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 541us/step - loss: 1.2114 - acc: 0.4477 - val_loss: 0.9892 - val_acc: 0.5638\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 531us/step - loss: 1.1397 - acc: 0.4987 - val_loss: 0.9908 - val_acc: 0.5638\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 463us/step - loss: 1.1275 - acc: 0.5067 - val_loss: 0.9904 - val_acc: 0.5532\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 471us/step - loss: 1.2170 - acc: 0.4906 - val_loss: 0.9880 - val_acc: 0.5532\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 466us/step - loss: 1.1426 - acc: 0.5094 - val_loss: 0.9840 - val_acc: 0.5532\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 501us/step - loss: 1.1300 - acc: 0.5067 - val_loss: 0.9797 - val_acc: 0.5532\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 487us/step - loss: 1.1030 - acc: 0.5147 - val_loss: 0.9735 - val_acc: 0.5638\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 464us/step - loss: 1.1446 - acc: 0.4960 - val_loss: 0.9684 - val_acc: 0.5638\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 481us/step - loss: 1.1340 - acc: 0.5201 - val_loss: 0.9625 - val_acc: 0.5851\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 474us/step - loss: 1.1004 - acc: 0.5308 - val_loss: 0.9574 - val_acc: 0.5957\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 474us/step - loss: 0.9910 - acc: 0.5603 - val_loss: 0.9536 - val_acc: 0.5957\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 475us/step - loss: 1.0684 - acc: 0.5201 - val_loss: 0.9524 - val_acc: 0.5957\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 515us/step - loss: 1.0925 - acc: 0.5040 - val_loss: 0.9533 - val_acc: 0.5957\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 486us/step - loss: 1.0631 - acc: 0.5523 - val_loss: 0.9551 - val_acc: 0.5957\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 472us/step - loss: 1.0098 - acc: 0.5818 - val_loss: 0.9570 - val_acc: 0.5957\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 460us/step - loss: 1.0388 - acc: 0.5255 - val_loss: 0.9606 - val_acc: 0.5957\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 460us/step - loss: 0.9780 - acc: 0.5684 - val_loss: 0.9675 - val_acc: 0.5957\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 474us/step - loss: 0.9703 - acc: 0.5952 - val_loss: 0.9738 - val_acc: 0.5957\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 507us/step - loss: 0.9574 - acc: 0.6247 - val_loss: 0.9773 - val_acc: 0.5957\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 477us/step - loss: 0.9236 - acc: 0.5979 - val_loss: 0.9773 - val_acc: 0.6064\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 493us/step - loss: 0.9190 - acc: 0.6086 - val_loss: 0.9744 - val_acc: 0.6064\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 485us/step - loss: 0.9711 - acc: 0.5818 - val_loss: 0.9683 - val_acc: 0.6170\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 503us/step - loss: 0.8450 - acc: 0.6354 - val_loss: 0.9613 - val_acc: 0.6170\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 481us/step - loss: 0.9028 - acc: 0.6113 - val_loss: 0.9555 - val_acc: 0.6383\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 478us/step - loss: 0.9090 - acc: 0.6247 - val_loss: 0.9486 - val_acc: 0.6383\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 512us/step - loss: 0.8425 - acc: 0.6515 - val_loss: 0.9434 - val_acc: 0.6489\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 474us/step - loss: 0.8537 - acc: 0.6408 - val_loss: 0.9414 - val_acc: 0.6489\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 471us/step - loss: 0.8736 - acc: 0.6247 - val_loss: 0.9392 - val_acc: 0.6277\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 463us/step - loss: 0.8273 - acc: 0.6622 - val_loss: 0.9386 - val_acc: 0.6277\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 471us/step - loss: 0.8300 - acc: 0.6488 - val_loss: 0.9371 - val_acc: 0.6277\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 458us/step - loss: 0.8151 - acc: 0.6649 - val_loss: 0.9370 - val_acc: 0.6383\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 476us/step - loss: 0.7778 - acc: 0.6568 - val_loss: 0.9364 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 463us/step - loss: 0.7875 - acc: 0.6622 - val_loss: 0.9353 - val_acc: 0.6383\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 469us/step - loss: 0.7729 - acc: 0.6783 - val_loss: 0.9349 - val_acc: 0.6383\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 495us/step - loss: 0.7529 - acc: 0.6890 - val_loss: 0.9328 - val_acc: 0.6383\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 514us/step - loss: 0.7310 - acc: 0.7024 - val_loss: 0.9317 - val_acc: 0.6383\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 455us/step - loss: 0.7578 - acc: 0.6890 - val_loss: 0.9308 - val_acc: 0.6383\n",
      "Epoch 60/100\n",
      "373/373 [==============================] - 0s 488us/step - loss: 0.7462 - acc: 0.6890 - val_loss: 0.9317 - val_acc: 0.6383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "373/373 [==============================] - 0s 477us/step - loss: 0.7082 - acc: 0.6917 - val_loss: 0.9319 - val_acc: 0.6383\n",
      "Epoch 62/100\n",
      "373/373 [==============================] - 0s 519us/step - loss: 0.7825 - acc: 0.6756 - val_loss: 0.9322 - val_acc: 0.6383\n",
      "Epoch 63/100\n",
      "373/373 [==============================] - 0s 477us/step - loss: 0.6933 - acc: 0.6756 - val_loss: 0.9341 - val_acc: 0.6383\n",
      "Epoch 64/100\n",
      "373/373 [==============================] - 0s 454us/step - loss: 0.7223 - acc: 0.7024 - val_loss: 0.9366 - val_acc: 0.6489\n",
      "Epoch 65/100\n",
      "373/373 [==============================] - 0s 490us/step - loss: 0.6697 - acc: 0.7239 - val_loss: 0.9395 - val_acc: 0.6489\n",
      "Epoch 66/100\n",
      "373/373 [==============================] - 0s 491us/step - loss: 0.6740 - acc: 0.7131 - val_loss: 0.9437 - val_acc: 0.6489\n",
      "Epoch 67/100\n",
      "373/373 [==============================] - 0s 457us/step - loss: 0.6614 - acc: 0.7265 - val_loss: 0.9486 - val_acc: 0.6596\n",
      "Epoch 68/100\n",
      "373/373 [==============================] - 0s 483us/step - loss: 0.6380 - acc: 0.7346 - val_loss: 0.9525 - val_acc: 0.6596\n",
      "Epoch 69/100\n",
      "373/373 [==============================] - 0s 489us/step - loss: 0.6412 - acc: 0.7480 - val_loss: 0.9568 - val_acc: 0.6702\n",
      "Epoch 70/100\n",
      "373/373 [==============================] - 0s 461us/step - loss: 0.6415 - acc: 0.7319 - val_loss: 0.9630 - val_acc: 0.6596\n",
      "Epoch 71/100\n",
      "373/373 [==============================] - 0s 471us/step - loss: 0.5963 - acc: 0.7426 - val_loss: 0.9731 - val_acc: 0.6596\n",
      "Epoch 72/100\n",
      "373/373 [==============================] - 0s 459us/step - loss: 0.5989 - acc: 0.7587 - val_loss: 0.9843 - val_acc: 0.6596\n",
      "Epoch 73/100\n",
      "373/373 [==============================] - 0s 497us/step - loss: 0.6476 - acc: 0.7185 - val_loss: 0.9948 - val_acc: 0.6489\n",
      "Epoch 74/100\n",
      "373/373 [==============================] - 0s 534us/step - loss: 0.6327 - acc: 0.7399 - val_loss: 1.0043 - val_acc: 0.6596\n",
      "Epoch 75/100\n",
      "373/373 [==============================] - 0s 461us/step - loss: 0.6595 - acc: 0.7399 - val_loss: 1.0101 - val_acc: 0.6596\n",
      "Epoch 76/100\n",
      "373/373 [==============================] - 0s 503us/step - loss: 0.6208 - acc: 0.7614 - val_loss: 1.0163 - val_acc: 0.6702\n",
      "Epoch 77/100\n",
      "373/373 [==============================] - 0s 519us/step - loss: 0.5334 - acc: 0.7909 - val_loss: 1.0233 - val_acc: 0.6383\n",
      "Epoch 78/100\n",
      "373/373 [==============================] - 0s 518us/step - loss: 0.5413 - acc: 0.7802 - val_loss: 1.0320 - val_acc: 0.6596\n",
      "Epoch 79/100\n",
      "373/373 [==============================] - 0s 496us/step - loss: 0.5660 - acc: 0.7721 - val_loss: 1.0422 - val_acc: 0.6596\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD65_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [f, j], \n",
    "    index=['Accuracy', 'Time'],\n",
    "    columns = [\n",
    "        'HCD35_Positive','HCD45_Positive','HCD65_Positive',\n",
    "        'HCD35_Negative','HCD45_Negative','HCD65_Negative'\n",
    "    ]\n",
    ").T.to_csv('../result/Keras.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
