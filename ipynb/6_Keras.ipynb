{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, GaussianNoise, GaussianDropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from  keras.regularizers import l1, l2\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\", \n",
    "        allow_growth=True,\n",
    "#         per_process_gpu_memory_fraction=0.5\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD35_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 1.9807 - acc: 0.2716 - val_loss: 1.4502 - val_acc: 0.2798\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 1.8038 - acc: 0.2701 - val_loss: 1.4709 - val_acc: 0.3333\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 625us/step - loss: 1.7190 - acc: 0.2985 - val_loss: 1.4186 - val_acc: 0.3423\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 620us/step - loss: 1.7501 - acc: 0.2739 - val_loss: 1.3578 - val_acc: 0.3571\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 620us/step - loss: 1.6938 - acc: 0.3112 - val_loss: 1.3087 - val_acc: 0.3839\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 619us/step - loss: 1.5389 - acc: 0.3366 - val_loss: 1.2864 - val_acc: 0.3899\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 617us/step - loss: 1.5191 - acc: 0.3642 - val_loss: 1.2539 - val_acc: 0.3750\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 668us/step - loss: 1.5554 - acc: 0.3560 - val_loss: 1.2148 - val_acc: 0.4196\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 623us/step - loss: 1.4803 - acc: 0.3634 - val_loss: 1.1877 - val_acc: 0.4940\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 647us/step - loss: 1.4281 - acc: 0.3925 - val_loss: 1.1851 - val_acc: 0.4375\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 617us/step - loss: 1.4042 - acc: 0.4172 - val_loss: 1.1769 - val_acc: 0.4345\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 648us/step - loss: 1.3318 - acc: 0.4127 - val_loss: 1.1621 - val_acc: 0.4464\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 1.3757 - acc: 0.4201 - val_loss: 1.1459 - val_acc: 0.4792\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 655us/step - loss: 1.2912 - acc: 0.4418 - val_loss: 1.1297 - val_acc: 0.4970\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 667us/step - loss: 1.2216 - acc: 0.4433 - val_loss: 1.1079 - val_acc: 0.5417\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 626us/step - loss: 1.2306 - acc: 0.4507 - val_loss: 1.0919 - val_acc: 0.5417\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 617us/step - loss: 1.1691 - acc: 0.4963 - val_loss: 1.0826 - val_acc: 0.5595\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 614us/step - loss: 1.1476 - acc: 0.5030 - val_loss: 1.0768 - val_acc: 0.5744\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 639us/step - loss: 1.1121 - acc: 0.5037 - val_loss: 1.0709 - val_acc: 0.5179\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 643us/step - loss: 1.0954 - acc: 0.5246 - val_loss: 1.0628 - val_acc: 0.5357\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 622us/step - loss: 1.0889 - acc: 0.5239 - val_loss: 1.0576 - val_acc: 0.5714\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 631us/step - loss: 1.0255 - acc: 0.5470 - val_loss: 1.0546 - val_acc: 0.5685\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 1.0102 - acc: 0.5761 - val_loss: 1.0471 - val_acc: 0.5565\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 620us/step - loss: 0.9755 - acc: 0.5828 - val_loss: 1.0412 - val_acc: 0.5565\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 0.9412 - acc: 0.5784 - val_loss: 1.0381 - val_acc: 0.5595\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 672us/step - loss: 0.9131 - acc: 0.6119 - val_loss: 1.0405 - val_acc: 0.5476\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 616us/step - loss: 0.9094 - acc: 0.6157 - val_loss: 1.0413 - val_acc: 0.5298\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.9015 - acc: 0.6112 - val_loss: 1.0297 - val_acc: 0.5536\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 622us/step - loss: 0.8778 - acc: 0.6440 - val_loss: 1.0150 - val_acc: 0.5893\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 620us/step - loss: 0.8139 - acc: 0.6530 - val_loss: 1.0043 - val_acc: 0.6161\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 622us/step - loss: 0.8033 - acc: 0.6582 - val_loss: 0.9970 - val_acc: 0.6250\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 0.7646 - acc: 0.6731 - val_loss: 0.9942 - val_acc: 0.6220\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 622us/step - loss: 0.7744 - acc: 0.6664 - val_loss: 0.9907 - val_acc: 0.6190\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 618us/step - loss: 0.7379 - acc: 0.6821 - val_loss: 0.9838 - val_acc: 0.6220\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 631us/step - loss: 0.7428 - acc: 0.6664 - val_loss: 0.9771 - val_acc: 0.6399\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 645us/step - loss: 0.6890 - acc: 0.7127 - val_loss: 0.9739 - val_acc: 0.6458\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 653us/step - loss: 0.6630 - acc: 0.7216 - val_loss: 0.9767 - val_acc: 0.6369\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 636us/step - loss: 0.6544 - acc: 0.7269 - val_loss: 0.9803 - val_acc: 0.6310\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 640us/step - loss: 0.6198 - acc: 0.7351 - val_loss: 0.9747 - val_acc: 0.6458\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 626us/step - loss: 0.6129 - acc: 0.7463 - val_loss: 0.9656 - val_acc: 0.6696\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 637us/step - loss: 0.6117 - acc: 0.7515 - val_loss: 0.9624 - val_acc: 0.7054\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 648us/step - loss: 0.5429 - acc: 0.7731 - val_loss: 0.9650 - val_acc: 0.7113\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 629us/step - loss: 0.5019 - acc: 0.7836 - val_loss: 0.9660 - val_acc: 0.6994\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 650us/step - loss: 0.5195 - acc: 0.7851 - val_loss: 0.9642 - val_acc: 0.6786\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 630us/step - loss: 0.4950 - acc: 0.8052 - val_loss: 0.9582 - val_acc: 0.6845\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 643us/step - loss: 0.4642 - acc: 0.8090 - val_loss: 0.9510 - val_acc: 0.7054\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 616us/step - loss: 0.4419 - acc: 0.8239 - val_loss: 0.9447 - val_acc: 0.7202\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 616us/step - loss: 0.4006 - acc: 0.8552 - val_loss: 0.9428 - val_acc: 0.7232\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 635us/step - loss: 0.4331 - acc: 0.8351 - val_loss: 0.9451 - val_acc: 0.7113\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 639us/step - loss: 0.4167 - acc: 0.8530 - val_loss: 0.9604 - val_acc: 0.7173\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 660us/step - loss: 0.3834 - acc: 0.8679 - val_loss: 0.9746 - val_acc: 0.7054\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 622us/step - loss: 0.3538 - acc: 0.8664 - val_loss: 0.9766 - val_acc: 0.6935\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 631us/step - loss: 0.3374 - acc: 0.8657 - val_loss: 0.9658 - val_acc: 0.6994\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 1s 623us/step - loss: 0.3265 - acc: 0.8739 - val_loss: 0.9657 - val_acc: 0.7173\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 1s 614us/step - loss: 0.3342 - acc: 0.8784 - val_loss: 0.9732 - val_acc: 0.7024\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 1s 635us/step - loss: 0.2919 - acc: 0.8888 - val_loss: 0.9823 - val_acc: 0.7083\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 0.2816 - acc: 0.8970 - val_loss: 0.9925 - val_acc: 0.6994\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 1s 643us/step - loss: 0.2935 - acc: 0.9000 - val_loss: 1.0107 - val_acc: 0.7024\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 1s 677us/step - loss: 0.2842 - acc: 0.9022 - val_loss: 1.0381 - val_acc: 0.6994\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 1s 615us/step - loss: 0.2633 - acc: 0.9127 - val_loss: 1.0634 - val_acc: 0.6726\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 1s 610us/step - loss: 0.2486 - acc: 0.9187 - val_loss: 1.0736 - val_acc: 0.6756\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 1s 624us/step - loss: 0.2455 - acc: 0.9000 - val_loss: 1.0585 - val_acc: 0.6786\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 1s 651us/step - loss: 0.2125 - acc: 0.9254 - val_loss: 1.0452 - val_acc: 0.6994\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 1s 667us/step - loss: 0.2200 - acc: 0.9254 - val_loss: 1.0386 - val_acc: 0.7113\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 1s 639us/step - loss: 0.2044 - acc: 0.9366 - val_loss: 1.0334 - val_acc: 0.7113\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 1s 626us/step - loss: 0.1827 - acc: 0.9328 - val_loss: 1.0318 - val_acc: 0.7054\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 1s 631us/step - loss: 0.1736 - acc: 0.9381 - val_loss: 1.0316 - val_acc: 0.7054\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 1s 643us/step - loss: 0.2173 - acc: 0.9343 - val_loss: 1.0326 - val_acc: 0.7232\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD35_pos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "j = []\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f = []\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7232142857142857"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD45_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.9326 - acc: 0.2552 - val_loss: 1.4605 - val_acc: 0.2827\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 709us/step - loss: 1.8309 - acc: 0.2701 - val_loss: 1.4606 - val_acc: 0.3244\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 726us/step - loss: 1.7561 - acc: 0.2784 - val_loss: 1.4392 - val_acc: 0.3482\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 1.6477 - acc: 0.2813 - val_loss: 1.3723 - val_acc: 0.3601\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 709us/step - loss: 1.6721 - acc: 0.2776 - val_loss: 1.3129 - val_acc: 0.3780\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 741us/step - loss: 1.5234 - acc: 0.3299 - val_loss: 1.2584 - val_acc: 0.3601\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 760us/step - loss: 1.4856 - acc: 0.3590 - val_loss: 1.2315 - val_acc: 0.3720\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 1.5595 - acc: 0.3328 - val_loss: 1.2372 - val_acc: 0.3720\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 746us/step - loss: 1.4560 - acc: 0.3590 - val_loss: 1.2388 - val_acc: 0.3839\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 765us/step - loss: 1.4837 - acc: 0.3575 - val_loss: 1.2446 - val_acc: 0.3899\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.3642 - acc: 0.3948 - val_loss: 1.2413 - val_acc: 0.4762\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 1.3803 - acc: 0.4007 - val_loss: 1.2283 - val_acc: 0.4494\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 707us/step - loss: 1.2934 - acc: 0.4306 - val_loss: 1.2092 - val_acc: 0.4464\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 1.3009 - acc: 0.4321 - val_loss: 1.1878 - val_acc: 0.4494\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 732us/step - loss: 1.2774 - acc: 0.4463 - val_loss: 1.1675 - val_acc: 0.4643\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 715us/step - loss: 1.2892 - acc: 0.4470 - val_loss: 1.1517 - val_acc: 0.4732\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 1.2348 - acc: 0.4813 - val_loss: 1.1403 - val_acc: 0.4702\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 1.1820 - acc: 0.4769 - val_loss: 1.1272 - val_acc: 0.4821\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 1.1606 - acc: 0.4836 - val_loss: 1.1165 - val_acc: 0.5030\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 1.1230 - acc: 0.4955 - val_loss: 1.1088 - val_acc: 0.5060\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 711us/step - loss: 1.1555 - acc: 0.5007 - val_loss: 1.0991 - val_acc: 0.5179\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 766us/step - loss: 1.1054 - acc: 0.5082 - val_loss: 1.0879 - val_acc: 0.5357\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 777us/step - loss: 1.0982 - acc: 0.5104 - val_loss: 1.0742 - val_acc: 0.5387\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 753us/step - loss: 1.0592 - acc: 0.5351 - val_loss: 1.0611 - val_acc: 0.5565\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 713us/step - loss: 1.0470 - acc: 0.5448 - val_loss: 1.0498 - val_acc: 0.5655\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 1.0201 - acc: 0.5604 - val_loss: 1.0412 - val_acc: 0.5774\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 753us/step - loss: 0.9881 - acc: 0.5664 - val_loss: 1.0320 - val_acc: 0.5774\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 739us/step - loss: 0.9847 - acc: 0.5694 - val_loss: 1.0185 - val_acc: 0.5774\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 745us/step - loss: 0.9510 - acc: 0.5672 - val_loss: 1.0056 - val_acc: 0.5655\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.9094 - acc: 0.5985 - val_loss: 0.9962 - val_acc: 0.5565\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 742us/step - loss: 0.9117 - acc: 0.5970 - val_loss: 0.9859 - val_acc: 0.5476\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 771us/step - loss: 0.8657 - acc: 0.6239 - val_loss: 0.9749 - val_acc: 0.5536\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 743us/step - loss: 0.8683 - acc: 0.6358 - val_loss: 0.9661 - val_acc: 0.5744\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 744us/step - loss: 0.8822 - acc: 0.6358 - val_loss: 0.9595 - val_acc: 0.6131\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 756us/step - loss: 0.8469 - acc: 0.6306 - val_loss: 0.9531 - val_acc: 0.6280\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.8482 - acc: 0.6418 - val_loss: 0.9477 - val_acc: 0.6101\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 737us/step - loss: 0.7676 - acc: 0.6694 - val_loss: 0.9447 - val_acc: 0.6012\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 736us/step - loss: 0.8088 - acc: 0.6709 - val_loss: 0.9384 - val_acc: 0.6012\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 0.7869 - acc: 0.6582 - val_loss: 0.9286 - val_acc: 0.6607\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 0.7338 - acc: 0.6985 - val_loss: 0.9231 - val_acc: 0.6905\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.6832 - acc: 0.7022 - val_loss: 0.9218 - val_acc: 0.6845\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.6378 - acc: 0.7343 - val_loss: 0.9209 - val_acc: 0.6845\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 715us/step - loss: 0.6499 - acc: 0.7231 - val_loss: 0.9172 - val_acc: 0.6875\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 734us/step - loss: 0.6138 - acc: 0.7425 - val_loss: 0.9087 - val_acc: 0.6786\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.5938 - acc: 0.7634 - val_loss: 0.9004 - val_acc: 0.6756\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 710us/step - loss: 0.5603 - acc: 0.7709 - val_loss: 0.8924 - val_acc: 0.7024\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 772us/step - loss: 0.5449 - acc: 0.7940 - val_loss: 0.8836 - val_acc: 0.7202\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 747us/step - loss: 0.4662 - acc: 0.8052 - val_loss: 0.8769 - val_acc: 0.7381\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 713us/step - loss: 0.4804 - acc: 0.8127 - val_loss: 0.8760 - val_acc: 0.7411\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 734us/step - loss: 0.4883 - acc: 0.8060 - val_loss: 0.8837 - val_acc: 0.7054\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.4377 - acc: 0.8321 - val_loss: 0.8840 - val_acc: 0.7173\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 771us/step - loss: 0.3826 - acc: 0.8575 - val_loss: 0.8736 - val_acc: 0.7143\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.3894 - acc: 0.8493 - val_loss: 0.8516 - val_acc: 0.7173\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 0.3563 - acc: 0.8649 - val_loss: 0.8386 - val_acc: 0.7083\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 1s 750us/step - loss: 0.3389 - acc: 0.8784 - val_loss: 0.8358 - val_acc: 0.7083\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 0.3404 - acc: 0.8724 - val_loss: 0.8354 - val_acc: 0.6935\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 0.3649 - acc: 0.8776 - val_loss: 0.8381 - val_acc: 0.7024\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 1s 730us/step - loss: 0.2875 - acc: 0.8933 - val_loss: 0.8478 - val_acc: 0.7113\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 1s 781us/step - loss: 0.2861 - acc: 0.9007 - val_loss: 0.8641 - val_acc: 0.7024\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 1s 750us/step - loss: 0.2471 - acc: 0.9119 - val_loss: 0.8844 - val_acc: 0.6994\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 0.2731 - acc: 0.9119 - val_loss: 0.9001 - val_acc: 0.6577\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 0.2521 - acc: 0.9134 - val_loss: 0.8962 - val_acc: 0.6518\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 1s 715us/step - loss: 0.2430 - acc: 0.9119 - val_loss: 0.8860 - val_acc: 0.6696\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 0.2467 - acc: 0.9224 - val_loss: 0.8806 - val_acc: 0.6935\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 1s 732us/step - loss: 0.2526 - acc: 0.9172 - val_loss: 0.8790 - val_acc: 0.6994\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 1s 702us/step - loss: 0.2225 - acc: 0.9269 - val_loss: 0.8805 - val_acc: 0.7113\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 0.1962 - acc: 0.9291 - val_loss: 0.8813 - val_acc: 0.7232\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.2219 - acc: 0.9269 - val_loss: 0.8870 - val_acc: 0.7054\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 1s 746us/step - loss: 0.1859 - acc: 0.9373 - val_loss: 0.8932 - val_acc: 0.6935\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 1s 726us/step - loss: 0.1938 - acc: 0.9351 - val_loss: 0.8968 - val_acc: 0.6935\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.1732 - acc: 0.9373 - val_loss: 0.9024 - val_acc: 0.6935\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 1s 750us/step - loss: 0.1869 - acc: 0.9410 - val_loss: 0.9130 - val_acc: 0.6815\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 1s 738us/step - loss: 0.1738 - acc: 0.9396 - val_loss: 0.9255 - val_acc: 0.6667\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.1994 - acc: 0.9321 - val_loss: 0.9431 - val_acc: 0.6607\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 1s 737us/step - loss: 0.1598 - acc: 0.9425 - val_loss: 0.9444 - val_acc: 0.6726\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 1s 736us/step - loss: 0.1618 - acc: 0.9358 - val_loss: 0.9470 - val_acc: 0.6815\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD45_pos.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD65_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.9340 - acc: 0.2612 - val_loss: 1.4266 - val_acc: 0.2946\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 1.8289 - acc: 0.2575 - val_loss: 1.3672 - val_acc: 0.3304\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 1.7796 - acc: 0.2978 - val_loss: 1.3388 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 1.7010 - acc: 0.2687 - val_loss: 1.2982 - val_acc: 0.3542\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 726us/step - loss: 1.6005 - acc: 0.3134 - val_loss: 1.2477 - val_acc: 0.3780\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 700us/step - loss: 1.5114 - acc: 0.3187 - val_loss: 1.2200 - val_acc: 0.3988\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 702us/step - loss: 1.5471 - acc: 0.3224 - val_loss: 1.2085 - val_acc: 0.4702\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 712us/step - loss: 1.5412 - acc: 0.3396 - val_loss: 1.2076 - val_acc: 0.4405\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 707us/step - loss: 1.4525 - acc: 0.3567 - val_loss: 1.2073 - val_acc: 0.4077\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 707us/step - loss: 1.4589 - acc: 0.3560 - val_loss: 1.2057 - val_acc: 0.4107\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 726us/step - loss: 1.4442 - acc: 0.3694 - val_loss: 1.1990 - val_acc: 0.4167\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 730us/step - loss: 1.4259 - acc: 0.3642 - val_loss: 1.1858 - val_acc: 0.4196\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 755us/step - loss: 1.3560 - acc: 0.3784 - val_loss: 1.1747 - val_acc: 0.4345\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 1.3638 - acc: 0.3910 - val_loss: 1.1683 - val_acc: 0.4464\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 1.3276 - acc: 0.3910 - val_loss: 1.1597 - val_acc: 0.5060\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 706us/step - loss: 1.3088 - acc: 0.3993 - val_loss: 1.1538 - val_acc: 0.5060\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 703us/step - loss: 1.3049 - acc: 0.4149 - val_loss: 1.1486 - val_acc: 0.5446\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 736us/step - loss: 1.2559 - acc: 0.4336 - val_loss: 1.1430 - val_acc: 0.5536\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 730us/step - loss: 1.2458 - acc: 0.4418 - val_loss: 1.1351 - val_acc: 0.5208\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 780us/step - loss: 1.2457 - acc: 0.4254 - val_loss: 1.1283 - val_acc: 0.4940\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 741us/step - loss: 1.2555 - acc: 0.4254 - val_loss: 1.1212 - val_acc: 0.4821\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 734us/step - loss: 1.2027 - acc: 0.4425 - val_loss: 1.1157 - val_acc: 0.4732\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 710us/step - loss: 1.1722 - acc: 0.4545 - val_loss: 1.1090 - val_acc: 0.4732\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 747us/step - loss: 1.1857 - acc: 0.4761 - val_loss: 1.1016 - val_acc: 0.4762\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 754us/step - loss: 1.1689 - acc: 0.4799 - val_loss: 1.0944 - val_acc: 0.4821\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 1.1586 - acc: 0.4709 - val_loss: 1.0867 - val_acc: 0.5089\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.1555 - acc: 0.4776 - val_loss: 1.0809 - val_acc: 0.5208\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.1235 - acc: 0.4948 - val_loss: 1.0741 - val_acc: 0.5238\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 698us/step - loss: 1.1104 - acc: 0.5022 - val_loss: 1.0668 - val_acc: 0.5327\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 713us/step - loss: 1.0887 - acc: 0.4978 - val_loss: 1.0601 - val_acc: 0.5446\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 705us/step - loss: 1.0641 - acc: 0.5194 - val_loss: 1.0522 - val_acc: 0.5476\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 712us/step - loss: 1.0500 - acc: 0.5366 - val_loss: 1.0437 - val_acc: 0.5506\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 699us/step - loss: 1.0769 - acc: 0.5164 - val_loss: 1.0363 - val_acc: 0.5685\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 700us/step - loss: 1.0307 - acc: 0.5455 - val_loss: 1.0306 - val_acc: 0.5774\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 1.0387 - acc: 0.5321 - val_loss: 1.0249 - val_acc: 0.5804\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 1.0362 - acc: 0.5366 - val_loss: 1.0193 - val_acc: 0.5476\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 0.9972 - acc: 0.5716 - val_loss: 1.0145 - val_acc: 0.5446\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 707us/step - loss: 0.9893 - acc: 0.5731 - val_loss: 1.0079 - val_acc: 0.5506\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 709us/step - loss: 0.9586 - acc: 0.5806 - val_loss: 1.0014 - val_acc: 0.5506\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 713us/step - loss: 0.9302 - acc: 0.5746 - val_loss: 0.9950 - val_acc: 0.5476\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 0.9038 - acc: 0.6179 - val_loss: 0.9907 - val_acc: 0.5446\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 708us/step - loss: 0.8789 - acc: 0.6239 - val_loss: 0.9883 - val_acc: 0.5327\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.8785 - acc: 0.6351 - val_loss: 0.9880 - val_acc: 0.5298\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 701us/step - loss: 0.8583 - acc: 0.6284 - val_loss: 0.9909 - val_acc: 0.5476\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.8242 - acc: 0.6381 - val_loss: 0.9921 - val_acc: 0.5595\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 711us/step - loss: 0.7869 - acc: 0.6485 - val_loss: 0.9930 - val_acc: 0.5833\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 739us/step - loss: 0.7805 - acc: 0.6739 - val_loss: 0.9879 - val_acc: 0.5893\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.7073 - acc: 0.6948 - val_loss: 0.9791 - val_acc: 0.5833\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 0.7376 - acc: 0.6851 - val_loss: 0.9705 - val_acc: 0.5833\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 712us/step - loss: 0.7124 - acc: 0.6821 - val_loss: 0.9633 - val_acc: 0.5833\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.7050 - acc: 0.6993 - val_loss: 0.9660 - val_acc: 0.5685\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 712us/step - loss: 0.6942 - acc: 0.7082 - val_loss: 0.9679 - val_acc: 0.5625\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 700us/step - loss: 0.6721 - acc: 0.7209 - val_loss: 0.9697 - val_acc: 0.5714\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 0.6370 - acc: 0.7276 - val_loss: 0.9640 - val_acc: 0.5714\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 1s 755us/step - loss: 0.6131 - acc: 0.7373 - val_loss: 0.9615 - val_acc: 0.5655\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 0.6043 - acc: 0.7500 - val_loss: 0.9581 - val_acc: 0.5685\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 1s 778us/step - loss: 0.5826 - acc: 0.7590 - val_loss: 0.9483 - val_acc: 0.5863\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 1s 749us/step - loss: 0.5398 - acc: 0.7821 - val_loss: 0.9339 - val_acc: 0.6161\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 1s 735us/step - loss: 0.5335 - acc: 0.7843 - val_loss: 0.9227 - val_acc: 0.6369\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.4865 - acc: 0.7866 - val_loss: 0.9129 - val_acc: 0.6280\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 1s 741us/step - loss: 0.4791 - acc: 0.8179 - val_loss: 0.9021 - val_acc: 0.6310\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 1s 807us/step - loss: 0.4785 - acc: 0.8060 - val_loss: 0.8988 - val_acc: 0.6310\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 1s 791us/step - loss: 0.4361 - acc: 0.8306 - val_loss: 0.9026 - val_acc: 0.6250\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.4300 - acc: 0.8388 - val_loss: 0.9106 - val_acc: 0.6071\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 1s 705us/step - loss: 0.4245 - acc: 0.8276 - val_loss: 0.9156 - val_acc: 0.6071\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 0.4659 - acc: 0.8239 - val_loss: 0.9180 - val_acc: 0.5923\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 1s 711us/step - loss: 0.4045 - acc: 0.8351 - val_loss: 0.9155 - val_acc: 0.6042\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 1s 707us/step - loss: 0.4045 - acc: 0.8470 - val_loss: 0.9080 - val_acc: 0.6131\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 1s 712us/step - loss: 0.3705 - acc: 0.8619 - val_loss: 0.9041 - val_acc: 0.6190\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 1s 711us/step - loss: 0.3789 - acc: 0.8545 - val_loss: 0.9006 - val_acc: 0.6220\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 1s 744us/step - loss: 0.3300 - acc: 0.8799 - val_loss: 0.8906 - val_acc: 0.6369\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 1s 705us/step - loss: 0.3768 - acc: 0.8642 - val_loss: 0.8849 - val_acc: 0.6339\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 1s 737us/step - loss: 0.3447 - acc: 0.8739 - val_loss: 0.8809 - val_acc: 0.6339\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 1s 739us/step - loss: 0.3329 - acc: 0.8769 - val_loss: 0.8789 - val_acc: 0.6726\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 1s 758us/step - loss: 0.3257 - acc: 0.8851 - val_loss: 0.8799 - val_acc: 0.6607\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.3413 - acc: 0.8657 - val_loss: 0.8802 - val_acc: 0.6607\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 1s 772us/step - loss: 0.3566 - acc: 0.8687 - val_loss: 0.8832 - val_acc: 0.6756\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 1s 773us/step - loss: 0.2937 - acc: 0.8896 - val_loss: 0.8846 - val_acc: 0.6845\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 0.2992 - acc: 0.8784 - val_loss: 0.8812 - val_acc: 0.6875\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.2900 - acc: 0.8993 - val_loss: 0.8769 - val_acc: 0.6726\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 1s 741us/step - loss: 0.2714 - acc: 0.8970 - val_loss: 0.8649 - val_acc: 0.6964\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 1s 717us/step - loss: 0.2785 - acc: 0.8963 - val_loss: 0.8514 - val_acc: 0.6964\n",
      "Epoch 83/100\n",
      "1340/1340 [==============================] - 1s 711us/step - loss: 0.2938 - acc: 0.8866 - val_loss: 0.8461 - val_acc: 0.7054\n",
      "Epoch 84/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.2531 - acc: 0.8993 - val_loss: 0.8457 - val_acc: 0.7054\n",
      "Epoch 85/100\n",
      "1340/1340 [==============================] - 1s 710us/step - loss: 0.2733 - acc: 0.9104 - val_loss: 0.8552 - val_acc: 0.6845\n",
      "Epoch 86/100\n",
      "1340/1340 [==============================] - 1s 743us/step - loss: 0.2520 - acc: 0.9090 - val_loss: 0.8681 - val_acc: 0.6667\n",
      "Epoch 87/100\n",
      "1340/1340 [==============================] - 1s 771us/step - loss: 0.2511 - acc: 0.9119 - val_loss: 0.8760 - val_acc: 0.6607\n",
      "Epoch 88/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.2288 - acc: 0.9157 - val_loss: 0.8848 - val_acc: 0.6548\n",
      "Epoch 89/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.2642 - acc: 0.9134 - val_loss: 0.8883 - val_acc: 0.6518\n",
      "Epoch 90/100\n",
      "1340/1340 [==============================] - 1s 764us/step - loss: 0.2413 - acc: 0.9201 - val_loss: 0.8877 - val_acc: 0.6310\n",
      "Epoch 91/100\n",
      "1340/1340 [==============================] - 1s 765us/step - loss: 0.2361 - acc: 0.9276 - val_loss: 0.8873 - val_acc: 0.6399\n",
      "Epoch 92/100\n",
      "1340/1340 [==============================] - 1s 717us/step - loss: 0.2248 - acc: 0.9216 - val_loss: 0.8863 - val_acc: 0.6399\n",
      "Epoch 93/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.2174 - acc: 0.9194 - val_loss: 0.8816 - val_acc: 0.6399\n",
      "Epoch 94/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.2120 - acc: 0.9254 - val_loss: 0.8748 - val_acc: 0.6488\n",
      "Epoch 95/100\n",
      "1340/1340 [==============================] - 1s 700us/step - loss: 0.2059 - acc: 0.9164 - val_loss: 0.8829 - val_acc: 0.6548\n",
      "Epoch 96/100\n",
      "1340/1340 [==============================] - 1s 702us/step - loss: 0.2110 - acc: 0.9254 - val_loss: 0.8880 - val_acc: 0.6815\n",
      "Epoch 97/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.2090 - acc: 0.9313 - val_loss: 0.8992 - val_acc: 0.6935\n",
      "Epoch 98/100\n",
      "1340/1340 [==============================] - 1s 703us/step - loss: 0.1983 - acc: 0.9299 - val_loss: 0.9124 - val_acc: 0.6875\n",
      "Epoch 99/100\n",
      "1340/1340 [==============================] - 1s 712us/step - loss: 0.1984 - acc: 0.9291 - val_loss: 0.9215 - val_acc: 0.6815\n",
      "Epoch 100/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 0.1997 - acc: 0.9299 - val_loss: 0.9127 - val_acc: 0.6845\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD65_pos.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD35_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 5ms/step - loss: 2.0594 - acc: 0.3324 - val_loss: 1.2999 - val_acc: 0.4362\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 204us/step - loss: 1.8601 - acc: 0.2976 - val_loss: 1.2854 - val_acc: 0.4362\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 243us/step - loss: 1.8735 - acc: 0.2842 - val_loss: 1.3202 - val_acc: 0.4574\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 1.9252 - acc: 0.3003 - val_loss: 1.3558 - val_acc: 0.4574\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 218us/step - loss: 1.6347 - acc: 0.3566 - val_loss: 1.3598 - val_acc: 0.4681\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 1.6729 - acc: 0.3753 - val_loss: 1.3463 - val_acc: 0.4894\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 207us/step - loss: 1.7338 - acc: 0.3592 - val_loss: 1.3003 - val_acc: 0.5106\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 258us/step - loss: 1.5831 - acc: 0.4155 - val_loss: 1.2484 - val_acc: 0.5106\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 235us/step - loss: 1.6465 - acc: 0.3834 - val_loss: 1.1961 - val_acc: 0.5213\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 233us/step - loss: 1.5384 - acc: 0.3646 - val_loss: 1.1534 - val_acc: 0.5213\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 242us/step - loss: 1.4140 - acc: 0.4504 - val_loss: 1.1033 - val_acc: 0.5213\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 247us/step - loss: 1.3977 - acc: 0.4182 - val_loss: 1.0593 - val_acc: 0.5319\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 240us/step - loss: 1.4827 - acc: 0.3941 - val_loss: 1.0293 - val_acc: 0.5532\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 219us/step - loss: 1.3318 - acc: 0.4182 - val_loss: 1.0084 - val_acc: 0.5532\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 246us/step - loss: 1.4643 - acc: 0.4129 - val_loss: 0.9913 - val_acc: 0.5638\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 227us/step - loss: 1.2729 - acc: 0.4236 - val_loss: 0.9834 - val_acc: 0.5638\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 200us/step - loss: 1.2336 - acc: 0.4906 - val_loss: 0.9773 - val_acc: 0.5638\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 233us/step - loss: 1.2096 - acc: 0.4799 - val_loss: 0.9766 - val_acc: 0.5851\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 218us/step - loss: 1.2346 - acc: 0.4853 - val_loss: 0.9870 - val_acc: 0.5851\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 1.2769 - acc: 0.4665 - val_loss: 0.9959 - val_acc: 0.5957\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 208us/step - loss: 1.1759 - acc: 0.5121 - val_loss: 1.0022 - val_acc: 0.5851\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 1.1479 - acc: 0.4960 - val_loss: 1.0039 - val_acc: 0.5957\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 207us/step - loss: 1.0641 - acc: 0.5442 - val_loss: 1.0094 - val_acc: 0.5851\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 1.0645 - acc: 0.5308 - val_loss: 1.0093 - val_acc: 0.5957\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 215us/step - loss: 1.0467 - acc: 0.5362 - val_loss: 1.0056 - val_acc: 0.5957\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 219us/step - loss: 1.0931 - acc: 0.5496 - val_loss: 0.9964 - val_acc: 0.6064\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 216us/step - loss: 0.9988 - acc: 0.5791 - val_loss: 0.9860 - val_acc: 0.6170\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 229us/step - loss: 0.9880 - acc: 0.5523 - val_loss: 0.9779 - val_acc: 0.6277\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 1.0049 - acc: 0.5576 - val_loss: 0.9721 - val_acc: 0.6383\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 206us/step - loss: 0.9903 - acc: 0.5764 - val_loss: 0.9625 - val_acc: 0.6383\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 244us/step - loss: 0.9638 - acc: 0.5764 - val_loss: 0.9477 - val_acc: 0.6383\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 0.9366 - acc: 0.5764 - val_loss: 0.9332 - val_acc: 0.6489\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 0.8876 - acc: 0.6247 - val_loss: 0.9176 - val_acc: 0.6489\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 0.9449 - acc: 0.5657 - val_loss: 0.9024 - val_acc: 0.6596\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 210us/step - loss: 0.8881 - acc: 0.6247 - val_loss: 0.8911 - val_acc: 0.6489\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 217us/step - loss: 0.8627 - acc: 0.6327 - val_loss: 0.8866 - val_acc: 0.6489\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 0.9499 - acc: 0.5737 - val_loss: 0.8889 - val_acc: 0.6383\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 229us/step - loss: 0.7963 - acc: 0.6729 - val_loss: 0.8887 - val_acc: 0.6383\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 212us/step - loss: 0.8161 - acc: 0.6381 - val_loss: 0.8891 - val_acc: 0.6383\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 224us/step - loss: 0.8344 - acc: 0.6515 - val_loss: 0.8867 - val_acc: 0.6277\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 219us/step - loss: 0.8231 - acc: 0.6568 - val_loss: 0.8792 - val_acc: 0.6170\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 0.7857 - acc: 0.6702 - val_loss: 0.8678 - val_acc: 0.6277\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 222us/step - loss: 0.7935 - acc: 0.6783 - val_loss: 0.8535 - val_acc: 0.6277\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 253us/step - loss: 0.7722 - acc: 0.6702 - val_loss: 0.8463 - val_acc: 0.6277\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 249us/step - loss: 0.7542 - acc: 0.7051 - val_loss: 0.8374 - val_acc: 0.6277\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 237us/step - loss: 0.7598 - acc: 0.6595 - val_loss: 0.8299 - val_acc: 0.6277\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 269us/step - loss: 0.6657 - acc: 0.7131 - val_loss: 0.8247 - val_acc: 0.6277\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 232us/step - loss: 0.6573 - acc: 0.7346 - val_loss: 0.8230 - val_acc: 0.6277\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 0.7137 - acc: 0.7024 - val_loss: 0.8222 - val_acc: 0.6277\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 212us/step - loss: 0.6915 - acc: 0.7105 - val_loss: 0.8287 - val_acc: 0.6277\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 218us/step - loss: 0.6964 - acc: 0.7078 - val_loss: 0.8316 - val_acc: 0.6277\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 209us/step - loss: 0.6639 - acc: 0.7185 - val_loss: 0.8425 - val_acc: 0.6277\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 0.7149 - acc: 0.6997 - val_loss: 0.8561 - val_acc: 0.6383\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 0.6408 - acc: 0.7319 - val_loss: 0.8740 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 227us/step - loss: 0.6807 - acc: 0.7105 - val_loss: 0.8911 - val_acc: 0.6383\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 229us/step - loss: 0.6602 - acc: 0.7292 - val_loss: 0.9069 - val_acc: 0.6383\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 240us/step - loss: 0.6362 - acc: 0.7560 - val_loss: 0.9144 - val_acc: 0.6489\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 212us/step - loss: 0.6068 - acc: 0.7480 - val_loss: 0.9164 - val_acc: 0.6489\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 213us/step - loss: 0.6097 - acc: 0.7534 - val_loss: 0.9184 - val_acc: 0.6489\n",
      "Epoch 60/100\n",
      "373/373 [==============================] - 0s 221us/step - loss: 0.6168 - acc: 0.7641 - val_loss: 0.9186 - val_acc: 0.6489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 0.6577 - acc: 0.7534 - val_loss: 0.9166 - val_acc: 0.6596\n",
      "Epoch 62/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 0.6735 - acc: 0.7239 - val_loss: 0.9088 - val_acc: 0.6596\n",
      "Epoch 63/100\n",
      "373/373 [==============================] - 0s 207us/step - loss: 0.5967 - acc: 0.7426 - val_loss: 0.9057 - val_acc: 0.6596\n",
      "Epoch 64/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 0.6025 - acc: 0.7373 - val_loss: 0.9103 - val_acc: 0.6596\n",
      "Epoch 65/100\n",
      "373/373 [==============================] - 0s 227us/step - loss: 0.5916 - acc: 0.7587 - val_loss: 0.9154 - val_acc: 0.6489\n",
      "Epoch 66/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 0.6246 - acc: 0.7507 - val_loss: 0.9190 - val_acc: 0.6489\n",
      "Epoch 67/100\n",
      "373/373 [==============================] - 0s 221us/step - loss: 0.5594 - acc: 0.7802 - val_loss: 0.9223 - val_acc: 0.6489\n",
      "Epoch 68/100\n",
      "373/373 [==============================] - 0s 209us/step - loss: 0.5568 - acc: 0.7775 - val_loss: 0.9255 - val_acc: 0.6489\n",
      "Epoch 69/100\n",
      "373/373 [==============================] - 0s 237us/step - loss: 0.5479 - acc: 0.7802 - val_loss: 0.9251 - val_acc: 0.6489\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD35_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD45_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 6ms/step - loss: 2.0211 - acc: 0.2815 - val_loss: 1.3210 - val_acc: 0.4255\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 310us/step - loss: 1.8936 - acc: 0.3190 - val_loss: 1.2780 - val_acc: 0.4468\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 283us/step - loss: 1.8786 - acc: 0.2949 - val_loss: 1.3458 - val_acc: 0.4362\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 285us/step - loss: 1.7519 - acc: 0.3646 - val_loss: 1.3964 - val_acc: 0.4574\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 312us/step - loss: 1.6608 - acc: 0.3753 - val_loss: 1.4154 - val_acc: 0.4574\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 301us/step - loss: 1.5765 - acc: 0.3941 - val_loss: 1.3900 - val_acc: 0.4574\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 290us/step - loss: 1.6477 - acc: 0.3592 - val_loss: 1.3546 - val_acc: 0.4574\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 292us/step - loss: 1.5509 - acc: 0.4290 - val_loss: 1.2971 - val_acc: 0.4787\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 286us/step - loss: 1.5945 - acc: 0.3727 - val_loss: 1.2325 - val_acc: 0.4787\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 277us/step - loss: 1.6423 - acc: 0.3834 - val_loss: 1.1744 - val_acc: 0.5319\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 290us/step - loss: 1.4199 - acc: 0.4155 - val_loss: 1.1263 - val_acc: 0.5426\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 330us/step - loss: 1.4249 - acc: 0.4504 - val_loss: 1.0885 - val_acc: 0.5638\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 329us/step - loss: 1.3979 - acc: 0.4290 - val_loss: 1.0586 - val_acc: 0.5638\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 344us/step - loss: 1.3053 - acc: 0.4558 - val_loss: 1.0410 - val_acc: 0.5638\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 345us/step - loss: 1.4096 - acc: 0.3914 - val_loss: 1.0286 - val_acc: 0.5532\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 340us/step - loss: 1.3048 - acc: 0.4665 - val_loss: 1.0194 - val_acc: 0.5532\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 311us/step - loss: 1.2993 - acc: 0.4638 - val_loss: 1.0060 - val_acc: 0.5638\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 322us/step - loss: 1.3295 - acc: 0.4504 - val_loss: 0.9937 - val_acc: 0.5745\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 335us/step - loss: 1.2565 - acc: 0.4504 - val_loss: 0.9834 - val_acc: 0.5745\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 321us/step - loss: 1.2046 - acc: 0.5067 - val_loss: 0.9740 - val_acc: 0.5851\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 357us/step - loss: 1.1014 - acc: 0.5308 - val_loss: 0.9654 - val_acc: 0.5851\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 312us/step - loss: 1.1304 - acc: 0.5174 - val_loss: 0.9626 - val_acc: 0.5745\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 302us/step - loss: 1.1086 - acc: 0.5013 - val_loss: 0.9615 - val_acc: 0.5745\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 326us/step - loss: 1.1114 - acc: 0.5094 - val_loss: 0.9595 - val_acc: 0.5745\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 323us/step - loss: 1.0632 - acc: 0.5550 - val_loss: 0.9611 - val_acc: 0.5745\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 296us/step - loss: 1.0378 - acc: 0.5523 - val_loss: 0.9633 - val_acc: 0.5745\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 293us/step - loss: 1.0228 - acc: 0.5496 - val_loss: 0.9662 - val_acc: 0.5745\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 319us/step - loss: 1.0483 - acc: 0.5416 - val_loss: 0.9690 - val_acc: 0.5745\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 299us/step - loss: 0.9758 - acc: 0.5710 - val_loss: 0.9718 - val_acc: 0.5745\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 338us/step - loss: 1.0791 - acc: 0.5737 - val_loss: 0.9685 - val_acc: 0.5745\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 318us/step - loss: 0.9902 - acc: 0.5362 - val_loss: 0.9622 - val_acc: 0.5745\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 357us/step - loss: 0.9417 - acc: 0.6032 - val_loss: 0.9557 - val_acc: 0.5851\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 368us/step - loss: 1.0151 - acc: 0.5871 - val_loss: 0.9456 - val_acc: 0.5851\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 317us/step - loss: 0.9697 - acc: 0.5657 - val_loss: 0.9349 - val_acc: 0.5957\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 321us/step - loss: 0.8922 - acc: 0.6113 - val_loss: 0.9251 - val_acc: 0.6277\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 316us/step - loss: 0.8352 - acc: 0.6273 - val_loss: 0.9184 - val_acc: 0.6489\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 319us/step - loss: 0.9085 - acc: 0.6005 - val_loss: 0.9121 - val_acc: 0.6489\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 309us/step - loss: 0.8268 - acc: 0.6300 - val_loss: 0.9065 - val_acc: 0.6383\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 312us/step - loss: 0.8343 - acc: 0.6408 - val_loss: 0.9024 - val_acc: 0.6383\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 325us/step - loss: 0.8674 - acc: 0.6381 - val_loss: 0.8952 - val_acc: 0.6489\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 308us/step - loss: 0.8425 - acc: 0.6381 - val_loss: 0.8877 - val_acc: 0.6383\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 288us/step - loss: 0.8699 - acc: 0.6247 - val_loss: 0.8809 - val_acc: 0.6383\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 290us/step - loss: 0.8126 - acc: 0.6649 - val_loss: 0.8808 - val_acc: 0.6383\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 283us/step - loss: 0.7926 - acc: 0.6542 - val_loss: 0.8824 - val_acc: 0.6596\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 303us/step - loss: 0.8100 - acc: 0.6676 - val_loss: 0.8884 - val_acc: 0.6596\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 319us/step - loss: 0.7679 - acc: 0.6836 - val_loss: 0.8937 - val_acc: 0.6596\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 280us/step - loss: 0.6995 - acc: 0.7212 - val_loss: 0.9011 - val_acc: 0.6596\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 301us/step - loss: 0.7851 - acc: 0.6863 - val_loss: 0.9118 - val_acc: 0.6596\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 282us/step - loss: 0.7377 - acc: 0.6729 - val_loss: 0.9223 - val_acc: 0.6596\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 287us/step - loss: 0.7203 - acc: 0.6971 - val_loss: 0.9315 - val_acc: 0.6596\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 332us/step - loss: 0.7307 - acc: 0.6944 - val_loss: 0.9382 - val_acc: 0.6596\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 295us/step - loss: 0.7040 - acc: 0.6783 - val_loss: 0.9478 - val_acc: 0.6489\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 288us/step - loss: 0.7320 - acc: 0.6810 - val_loss: 0.9566 - val_acc: 0.6489\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 286us/step - loss: 0.6720 - acc: 0.7024 - val_loss: 0.9627 - val_acc: 0.6489\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 293us/step - loss: 0.7232 - acc: 0.6783 - val_loss: 0.9679 - val_acc: 0.6383\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 296us/step - loss: 0.6626 - acc: 0.7051 - val_loss: 0.9740 - val_acc: 0.6489\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 278us/step - loss: 0.7042 - acc: 0.7131 - val_loss: 0.9791 - val_acc: 0.6489\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 297us/step - loss: 0.6140 - acc: 0.7426 - val_loss: 0.9870 - val_acc: 0.6596\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 277us/step - loss: 0.6481 - acc: 0.7426 - val_loss: 0.9928 - val_acc: 0.6702\n",
      "Epoch 60/100\n",
      "373/373 [==============================] - 0s 299us/step - loss: 0.6741 - acc: 0.7024 - val_loss: 0.9989 - val_acc: 0.6596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "373/373 [==============================] - 0s 300us/step - loss: 0.6705 - acc: 0.7051 - val_loss: 1.0051 - val_acc: 0.6596\n",
      "Epoch 62/100\n",
      "373/373 [==============================] - 0s 292us/step - loss: 0.6531 - acc: 0.7265 - val_loss: 1.0123 - val_acc: 0.6596\n",
      "Epoch 63/100\n",
      "373/373 [==============================] - 0s 275us/step - loss: 0.6296 - acc: 0.7373 - val_loss: 1.0195 - val_acc: 0.6702\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD45_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD65_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 6ms/step - loss: 2.0835 - acc: 0.2895 - val_loss: 1.3423 - val_acc: 0.4149\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 1.9243 - acc: 0.2869 - val_loss: 1.2595 - val_acc: 0.4362\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 408us/step - loss: 1.9408 - acc: 0.2842 - val_loss: 1.2734 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 386us/step - loss: 1.8170 - acc: 0.3271 - val_loss: 1.3196 - val_acc: 0.5106\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 1.7376 - acc: 0.3458 - val_loss: 1.3318 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 389us/step - loss: 1.6870 - acc: 0.3432 - val_loss: 1.3131 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 398us/step - loss: 1.6855 - acc: 0.3592 - val_loss: 1.2804 - val_acc: 0.5106\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 385us/step - loss: 1.6266 - acc: 0.3753 - val_loss: 1.2402 - val_acc: 0.5106\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 1.6717 - acc: 0.3646 - val_loss: 1.1937 - val_acc: 0.5106\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 399us/step - loss: 1.5400 - acc: 0.4129 - val_loss: 1.1514 - val_acc: 0.5213\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 378us/step - loss: 1.4374 - acc: 0.3914 - val_loss: 1.1139 - val_acc: 0.5319\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 1.4226 - acc: 0.3914 - val_loss: 1.0849 - val_acc: 0.5426\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 401us/step - loss: 1.4519 - acc: 0.3727 - val_loss: 1.0672 - val_acc: 0.5319\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 430us/step - loss: 1.3845 - acc: 0.4182 - val_loss: 1.0547 - val_acc: 0.5319\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 383us/step - loss: 1.4910 - acc: 0.4075 - val_loss: 1.0461 - val_acc: 0.5319\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 422us/step - loss: 1.3900 - acc: 0.4048 - val_loss: 1.0396 - val_acc: 0.5426\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 395us/step - loss: 1.2952 - acc: 0.4584 - val_loss: 1.0317 - val_acc: 0.5319\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 1.3093 - acc: 0.4531 - val_loss: 1.0231 - val_acc: 0.5532\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 1.3769 - acc: 0.4424 - val_loss: 1.0157 - val_acc: 0.5638\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 395us/step - loss: 1.2996 - acc: 0.4424 - val_loss: 1.0082 - val_acc: 0.5745\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 447us/step - loss: 1.3032 - acc: 0.4558 - val_loss: 1.0016 - val_acc: 0.5851\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 391us/step - loss: 1.2786 - acc: 0.4450 - val_loss: 0.9970 - val_acc: 0.5745\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 406us/step - loss: 1.1795 - acc: 0.4692 - val_loss: 0.9937 - val_acc: 0.5745\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 1.1193 - acc: 0.5094 - val_loss: 0.9931 - val_acc: 0.5638\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 406us/step - loss: 1.1173 - acc: 0.5013 - val_loss: 0.9912 - val_acc: 0.5638\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 440us/step - loss: 1.1928 - acc: 0.4853 - val_loss: 0.9875 - val_acc: 0.5638\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 1.1184 - acc: 0.5201 - val_loss: 0.9827 - val_acc: 0.5638\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 425us/step - loss: 1.1833 - acc: 0.4933 - val_loss: 0.9779 - val_acc: 0.5638\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 383us/step - loss: 1.1092 - acc: 0.5094 - val_loss: 0.9726 - val_acc: 0.5745\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 425us/step - loss: 1.1443 - acc: 0.4933 - val_loss: 0.9691 - val_acc: 0.5745\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 400us/step - loss: 1.1129 - acc: 0.5362 - val_loss: 0.9662 - val_acc: 0.5851\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 451us/step - loss: 1.0498 - acc: 0.5603 - val_loss: 0.9608 - val_acc: 0.5851\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 409us/step - loss: 1.0206 - acc: 0.5791 - val_loss: 0.9533 - val_acc: 0.5957\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 436us/step - loss: 1.0439 - acc: 0.5201 - val_loss: 0.9451 - val_acc: 0.5957\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 423us/step - loss: 1.0567 - acc: 0.5228 - val_loss: 0.9386 - val_acc: 0.5957\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 394us/step - loss: 1.0348 - acc: 0.5389 - val_loss: 0.9315 - val_acc: 0.6064\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 398us/step - loss: 1.0531 - acc: 0.5710 - val_loss: 0.9239 - val_acc: 0.6064\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 381us/step - loss: 1.0502 - acc: 0.5174 - val_loss: 0.9171 - val_acc: 0.6170\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 0.9661 - acc: 0.5576 - val_loss: 0.9119 - val_acc: 0.6170\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 396us/step - loss: 1.0154 - acc: 0.5684 - val_loss: 0.9077 - val_acc: 0.6170\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 0.9660 - acc: 0.5871 - val_loss: 0.9034 - val_acc: 0.6277\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 424us/step - loss: 0.9212 - acc: 0.6193 - val_loss: 0.8968 - val_acc: 0.6489\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 399us/step - loss: 0.9275 - acc: 0.6220 - val_loss: 0.8902 - val_acc: 0.6489\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 0.9640 - acc: 0.6059 - val_loss: 0.8850 - val_acc: 0.6489\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 399us/step - loss: 0.8968 - acc: 0.6059 - val_loss: 0.8798 - val_acc: 0.6383\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 0.8836 - acc: 0.6300 - val_loss: 0.8764 - val_acc: 0.6489\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 413us/step - loss: 0.8547 - acc: 0.6193 - val_loss: 0.8744 - val_acc: 0.6489\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 0.8505 - acc: 0.6273 - val_loss: 0.8726 - val_acc: 0.6596\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 398us/step - loss: 0.8811 - acc: 0.6542 - val_loss: 0.8718 - val_acc: 0.6596\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 434us/step - loss: 0.8866 - acc: 0.6354 - val_loss: 0.8721 - val_acc: 0.6702\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 420us/step - loss: 0.8072 - acc: 0.6354 - val_loss: 0.8741 - val_acc: 0.6702\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 0.7947 - acc: 0.6729 - val_loss: 0.8767 - val_acc: 0.6596\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 411us/step - loss: 0.8288 - acc: 0.6273 - val_loss: 0.8804 - val_acc: 0.6596\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 447us/step - loss: 0.7707 - acc: 0.6756 - val_loss: 0.8820 - val_acc: 0.6596\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 399us/step - loss: 0.7631 - acc: 0.6676 - val_loss: 0.8812 - val_acc: 0.6702\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 395us/step - loss: 0.7382 - acc: 0.6702 - val_loss: 0.8810 - val_acc: 0.6702\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 388us/step - loss: 0.7638 - acc: 0.6863 - val_loss: 0.8791 - val_acc: 0.6702\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 400us/step - loss: 0.7493 - acc: 0.6783 - val_loss: 0.8793 - val_acc: 0.6702\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 380us/step - loss: 0.7108 - acc: 0.6917 - val_loss: 0.8795 - val_acc: 0.6702\n",
      "Epoch 60/100\n",
      "373/373 [==============================] - 0s 412us/step - loss: 0.7088 - acc: 0.6890 - val_loss: 0.8806 - val_acc: 0.6809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 0.6835 - acc: 0.7239 - val_loss: 0.8811 - val_acc: 0.6809\n",
      "Epoch 62/100\n",
      "373/373 [==============================] - 0s 391us/step - loss: 0.7822 - acc: 0.6702 - val_loss: 0.8850 - val_acc: 0.7128\n",
      "Epoch 63/100\n",
      "373/373 [==============================] - 0s 403us/step - loss: 0.6572 - acc: 0.6971 - val_loss: 0.8898 - val_acc: 0.7128\n",
      "Epoch 64/100\n",
      "373/373 [==============================] - 0s 398us/step - loss: 0.7126 - acc: 0.6917 - val_loss: 0.8960 - val_acc: 0.7234\n",
      "Epoch 65/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 0.7050 - acc: 0.6944 - val_loss: 0.9014 - val_acc: 0.7234\n",
      "Epoch 66/100\n",
      "373/373 [==============================] - 0s 414us/step - loss: 0.6848 - acc: 0.7078 - val_loss: 0.9075 - val_acc: 0.7234\n",
      "Epoch 67/100\n",
      "373/373 [==============================] - 0s 422us/step - loss: 0.6508 - acc: 0.7480 - val_loss: 0.9140 - val_acc: 0.7128\n",
      "Epoch 68/100\n",
      "373/373 [==============================] - 0s 408us/step - loss: 0.6446 - acc: 0.7641 - val_loss: 0.9198 - val_acc: 0.6809\n",
      "Epoch 69/100\n",
      "373/373 [==============================] - 0s 398us/step - loss: 0.6888 - acc: 0.7399 - val_loss: 0.9248 - val_acc: 0.6809\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD65_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [f, j], \n",
    "    index=['Accuracy', 'Time'],\n",
    "    columns = [\n",
    "        'HCD35_Positive','HCD45_Positive','HCD65_Positive',\n",
    "        'HCD35_Negative','HCD45_Negative','HCD65_Negative'\n",
    "    ]\n",
    ").T.to_csv('../result/Keras.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
