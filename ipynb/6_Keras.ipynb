{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, GaussianNoise, GaussianDropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from  keras.regularizers import l1, l2\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"0\", \n",
    "        allow_growth=True,\n",
    "#         per_process_gpu_memory_fraction=0.5\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD35_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.9805 - acc: 0.2694 - val_loss: 1.4347 - val_acc: 0.2827\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 638us/step - loss: 1.8146 - acc: 0.2687 - val_loss: 1.4782 - val_acc: 0.3244\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 635us/step - loss: 1.7504 - acc: 0.3030 - val_loss: 1.4241 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 644us/step - loss: 1.6849 - acc: 0.3104 - val_loss: 1.3657 - val_acc: 0.3512\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 649us/step - loss: 1.7023 - acc: 0.3172 - val_loss: 1.2952 - val_acc: 0.3899\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 655us/step - loss: 1.5395 - acc: 0.3343 - val_loss: 1.2399 - val_acc: 0.4137\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 670us/step - loss: 1.5224 - acc: 0.3478 - val_loss: 1.2341 - val_acc: 0.4583\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 669us/step - loss: 1.5516 - acc: 0.3567 - val_loss: 1.2292 - val_acc: 0.4345\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 640us/step - loss: 1.5135 - acc: 0.3664 - val_loss: 1.2202 - val_acc: 0.4345\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 1.4608 - acc: 0.3716 - val_loss: 1.2056 - val_acc: 0.4405\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 638us/step - loss: 1.4308 - acc: 0.4090 - val_loss: 1.1870 - val_acc: 0.5179\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 630us/step - loss: 1.3389 - acc: 0.4134 - val_loss: 1.1805 - val_acc: 0.4464\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 626us/step - loss: 1.3543 - acc: 0.4224 - val_loss: 1.1733 - val_acc: 0.4256\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 624us/step - loss: 1.2665 - acc: 0.4634 - val_loss: 1.1586 - val_acc: 0.4286\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 652us/step - loss: 1.2154 - acc: 0.4582 - val_loss: 1.1360 - val_acc: 0.4435\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 636us/step - loss: 1.2019 - acc: 0.4418 - val_loss: 1.1105 - val_acc: 0.4673\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 660us/step - loss: 1.2130 - acc: 0.5007 - val_loss: 1.0912 - val_acc: 0.5060\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 639us/step - loss: 1.1234 - acc: 0.5112 - val_loss: 1.0733 - val_acc: 0.5536\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 654us/step - loss: 1.1025 - acc: 0.5269 - val_loss: 1.0563 - val_acc: 0.5893\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 1.0950 - acc: 0.5351 - val_loss: 1.0467 - val_acc: 0.5655\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 1.0746 - acc: 0.5470 - val_loss: 1.0454 - val_acc: 0.5238\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 635us/step - loss: 1.0073 - acc: 0.5664 - val_loss: 1.0397 - val_acc: 0.5208\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 676us/step - loss: 1.0296 - acc: 0.5776 - val_loss: 1.0244 - val_acc: 0.5655\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 659us/step - loss: 0.9540 - acc: 0.5978 - val_loss: 1.0100 - val_acc: 0.6071\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 658us/step - loss: 0.9190 - acc: 0.6022 - val_loss: 0.9985 - val_acc: 0.6042\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 640us/step - loss: 0.8758 - acc: 0.6373 - val_loss: 0.9904 - val_acc: 0.6220\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 0.8810 - acc: 0.6209 - val_loss: 0.9851 - val_acc: 0.6250\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 645us/step - loss: 0.8719 - acc: 0.6336 - val_loss: 0.9756 - val_acc: 0.6280\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.8213 - acc: 0.6664 - val_loss: 0.9694 - val_acc: 0.6429\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 640us/step - loss: 0.8057 - acc: 0.6694 - val_loss: 0.9638 - val_acc: 0.6339\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 623us/step - loss: 0.7490 - acc: 0.6851 - val_loss: 0.9567 - val_acc: 0.6310\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.7606 - acc: 0.6746 - val_loss: 0.9512 - val_acc: 0.6369\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 644us/step - loss: 0.7553 - acc: 0.7000 - val_loss: 0.9453 - val_acc: 0.6190\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 625us/step - loss: 0.7180 - acc: 0.6985 - val_loss: 0.9389 - val_acc: 0.6369\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 666us/step - loss: 0.7133 - acc: 0.6955 - val_loss: 0.9359 - val_acc: 0.6369\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 0.6920 - acc: 0.7269 - val_loss: 0.9333 - val_acc: 0.6488\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 0.6263 - acc: 0.7448 - val_loss: 0.9289 - val_acc: 0.6696\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 639us/step - loss: 0.6123 - acc: 0.7552 - val_loss: 0.9261 - val_acc: 0.6667\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 637us/step - loss: 0.6006 - acc: 0.7530 - val_loss: 0.9229 - val_acc: 0.6845\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 624us/step - loss: 0.5926 - acc: 0.7679 - val_loss: 0.9253 - val_acc: 0.6667\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 649us/step - loss: 0.5784 - acc: 0.7701 - val_loss: 0.9268 - val_acc: 0.6696\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 677us/step - loss: 0.4909 - acc: 0.8030 - val_loss: 0.9302 - val_acc: 0.6786\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 640us/step - loss: 0.4875 - acc: 0.8104 - val_loss: 0.9335 - val_acc: 0.6845\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 654us/step - loss: 0.4937 - acc: 0.8269 - val_loss: 0.9370 - val_acc: 0.6815\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 651us/step - loss: 0.4775 - acc: 0.8187 - val_loss: 0.9356 - val_acc: 0.6815\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 666us/step - loss: 0.4458 - acc: 0.8343 - val_loss: 0.9282 - val_acc: 0.6905\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 671us/step - loss: 0.4162 - acc: 0.8358 - val_loss: 0.9268 - val_acc: 0.7113\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 644us/step - loss: 0.3660 - acc: 0.8687 - val_loss: 0.9354 - val_acc: 0.7083\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 644us/step - loss: 0.3925 - acc: 0.8493 - val_loss: 0.9506 - val_acc: 0.7083\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 658us/step - loss: 0.3738 - acc: 0.8530 - val_loss: 0.9769 - val_acc: 0.6994\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 685us/step - loss: 0.3254 - acc: 0.8813 - val_loss: 0.9986 - val_acc: 0.6964\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 699us/step - loss: 0.3403 - acc: 0.8813 - val_loss: 1.0087 - val_acc: 0.6875\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 672us/step - loss: 0.3198 - acc: 0.8791 - val_loss: 1.0099 - val_acc: 0.6756\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 1s 674us/step - loss: 0.3007 - acc: 0.8858 - val_loss: 1.0158 - val_acc: 0.6577\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 0.3140 - acc: 0.8881 - val_loss: 1.0308 - val_acc: 0.6518\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 1s 649us/step - loss: 0.2791 - acc: 0.9030 - val_loss: 1.0406 - val_acc: 0.6548\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 1s 623us/step - loss: 0.2861 - acc: 0.8940 - val_loss: 1.0411 - val_acc: 0.6607\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 1s 641us/step - loss: 0.2716 - acc: 0.9015 - val_loss: 1.0402 - val_acc: 0.6667\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 1s 666us/step - loss: 0.2393 - acc: 0.9082 - val_loss: 1.0416 - val_acc: 0.6756\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD35_pos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "j = []\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f = []\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6755952380952381"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD45_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 4s 3ms/step - loss: 1.9418 - acc: 0.2560 - val_loss: 1.4291 - val_acc: 0.2917\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 1.8003 - acc: 0.2642 - val_loss: 1.4512 - val_acc: 0.3393\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 990us/step - loss: 1.7191 - acc: 0.2978 - val_loss: 1.4419 - val_acc: 0.3571\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 995us/step - loss: 1.6577 - acc: 0.2754 - val_loss: 1.3741 - val_acc: 0.3601\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 1.6417 - acc: 0.3067 - val_loss: 1.3110 - val_acc: 0.3631\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 988us/step - loss: 1.5214 - acc: 0.3284 - val_loss: 1.2601 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 967us/step - loss: 1.5267 - acc: 0.3627 - val_loss: 1.2241 - val_acc: 0.4256\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 966us/step - loss: 1.5502 - acc: 0.3769 - val_loss: 1.2223 - val_acc: 0.4137\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 977us/step - loss: 1.4555 - acc: 0.3828 - val_loss: 1.2266 - val_acc: 0.4256\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 971us/step - loss: 1.4339 - acc: 0.3769 - val_loss: 1.2343 - val_acc: 0.4762\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 975us/step - loss: 1.3746 - acc: 0.4030 - val_loss: 1.2373 - val_acc: 0.4196\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 994us/step - loss: 1.3198 - acc: 0.4052 - val_loss: 1.2262 - val_acc: 0.4435\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 1.3081 - acc: 0.4321 - val_loss: 1.1971 - val_acc: 0.5030\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 1.3009 - acc: 0.4313 - val_loss: 1.1828 - val_acc: 0.4494\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 971us/step - loss: 1.2755 - acc: 0.4381 - val_loss: 1.1679 - val_acc: 0.4673\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 978us/step - loss: 1.2462 - acc: 0.4575 - val_loss: 1.1538 - val_acc: 0.4762\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 995us/step - loss: 1.2164 - acc: 0.4560 - val_loss: 1.1435 - val_acc: 0.5149\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 988us/step - loss: 1.1584 - acc: 0.4761 - val_loss: 1.1346 - val_acc: 0.5655\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 979us/step - loss: 1.1578 - acc: 0.5067 - val_loss: 1.1254 - val_acc: 0.5238\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 978us/step - loss: 1.1354 - acc: 0.4918 - val_loss: 1.1150 - val_acc: 0.5298\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 969us/step - loss: 1.1753 - acc: 0.5007 - val_loss: 1.1012 - val_acc: 0.5536\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 965us/step - loss: 1.0913 - acc: 0.5067 - val_loss: 1.0865 - val_acc: 0.5714\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 995us/step - loss: 1.0832 - acc: 0.5261 - val_loss: 1.0676 - val_acc: 0.5893\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 963us/step - loss: 1.0600 - acc: 0.5328 - val_loss: 1.0545 - val_acc: 0.5714\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 965us/step - loss: 1.0356 - acc: 0.5373 - val_loss: 1.0450 - val_acc: 0.5565\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 956us/step - loss: 1.0186 - acc: 0.5769 - val_loss: 1.0352 - val_acc: 0.5476\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 967us/step - loss: 0.9620 - acc: 0.5746 - val_loss: 1.0269 - val_acc: 0.5417\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 966us/step - loss: 0.9584 - acc: 0.5612 - val_loss: 1.0204 - val_acc: 0.5387\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 983us/step - loss: 0.9507 - acc: 0.5918 - val_loss: 1.0103 - val_acc: 0.5357\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 949us/step - loss: 0.9301 - acc: 0.5963 - val_loss: 0.9995 - val_acc: 0.5387\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 966us/step - loss: 0.9155 - acc: 0.5918 - val_loss: 0.9884 - val_acc: 0.5536\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 960us/step - loss: 0.8856 - acc: 0.6358 - val_loss: 0.9785 - val_acc: 0.5595\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 962us/step - loss: 0.8843 - acc: 0.6201 - val_loss: 0.9716 - val_acc: 0.5923\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 960us/step - loss: 0.8374 - acc: 0.6239 - val_loss: 0.9664 - val_acc: 0.5982\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 969us/step - loss: 0.8676 - acc: 0.6291 - val_loss: 0.9595 - val_acc: 0.6161\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 955us/step - loss: 0.8250 - acc: 0.6582 - val_loss: 0.9543 - val_acc: 0.6220\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 947us/step - loss: 0.7944 - acc: 0.6679 - val_loss: 0.9512 - val_acc: 0.6042\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 963us/step - loss: 0.8045 - acc: 0.6619 - val_loss: 0.9446 - val_acc: 0.5923\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 969us/step - loss: 0.7958 - acc: 0.6731 - val_loss: 0.9328 - val_acc: 0.6190\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 977us/step - loss: 0.7514 - acc: 0.6821 - val_loss: 0.9227 - val_acc: 0.6518\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 969us/step - loss: 0.7115 - acc: 0.7075 - val_loss: 0.9179 - val_acc: 0.6339\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 964us/step - loss: 0.6666 - acc: 0.7172 - val_loss: 0.9167 - val_acc: 0.6280\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 981us/step - loss: 0.6564 - acc: 0.7313 - val_loss: 0.9142 - val_acc: 0.6310\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 990us/step - loss: 0.6387 - acc: 0.7269 - val_loss: 0.9159 - val_acc: 0.5982\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 973us/step - loss: 0.5933 - acc: 0.7619 - val_loss: 0.9190 - val_acc: 0.5923\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 992us/step - loss: 0.5795 - acc: 0.7627 - val_loss: 0.9099 - val_acc: 0.6101\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 972us/step - loss: 0.5660 - acc: 0.7858 - val_loss: 0.8943 - val_acc: 0.6399\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 959us/step - loss: 0.4977 - acc: 0.7970 - val_loss: 0.8846 - val_acc: 0.6369\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 0.4998 - acc: 0.7925 - val_loss: 0.8796 - val_acc: 0.6369\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 1ms/step - loss: 0.4984 - acc: 0.7993 - val_loss: 0.8817 - val_acc: 0.6369\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 947us/step - loss: 0.4531 - acc: 0.8157 - val_loss: 0.8905 - val_acc: 0.6220\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 968us/step - loss: 0.4213 - acc: 0.8410 - val_loss: 0.8969 - val_acc: 0.6131\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 923us/step - loss: 0.3882 - acc: 0.8500 - val_loss: 0.9027 - val_acc: 0.6131\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.3618 - acc: 0.8694 - val_loss: 0.9084 - val_acc: 0.6012\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3645 - acc: 0.8649 - val_loss: 0.9125 - val_acc: 0.6101\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.3501 - acc: 0.8761 - val_loss: 0.9258 - val_acc: 0.6161\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.3357 - acc: 0.8776 - val_loss: 0.9275 - val_acc: 0.6220\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2843 - acc: 0.9082 - val_loss: 0.9222 - val_acc: 0.6369\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2862 - acc: 0.8933 - val_loss: 0.9070 - val_acc: 0.6518\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2662 - acc: 0.9007 - val_loss: 0.8928 - val_acc: 0.6577\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2616 - acc: 0.9194 - val_loss: 0.8822 - val_acc: 0.6667\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2481 - acc: 0.9037 - val_loss: 0.8698 - val_acc: 0.6696\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2560 - acc: 0.9090 - val_loss: 0.8715 - val_acc: 0.6667\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2442 - acc: 0.9179 - val_loss: 0.8715 - val_acc: 0.6756\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2380 - acc: 0.9194 - val_loss: 0.8648 - val_acc: 0.6815\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2210 - acc: 0.9231 - val_loss: 0.8528 - val_acc: 0.7083\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1903 - acc: 0.9269 - val_loss: 0.8389 - val_acc: 0.7292\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2237 - acc: 0.9276 - val_loss: 0.8342 - val_acc: 0.7470\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1930 - acc: 0.9336 - val_loss: 0.8372 - val_acc: 0.7262\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1992 - acc: 0.9261 - val_loss: 0.8455 - val_acc: 0.7024\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1754 - acc: 0.9455 - val_loss: 0.8639 - val_acc: 0.6845\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1911 - acc: 0.9306 - val_loss: 0.8885 - val_acc: 0.6637\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1829 - acc: 0.9373 - val_loss: 0.9129 - val_acc: 0.6607\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.2053 - acc: 0.9366 - val_loss: 0.9318 - val_acc: 0.6488\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1617 - acc: 0.9433 - val_loss: 0.9339 - val_acc: 0.6518\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1836 - acc: 0.9343 - val_loss: 0.9314 - val_acc: 0.6667\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1490 - acc: 0.9463 - val_loss: 0.9343 - val_acc: 0.6696\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1528 - acc: 0.9463 - val_loss: 0.9302 - val_acc: 0.6815\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1498 - acc: 0.9478 - val_loss: 0.9150 - val_acc: 0.6935\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.1753 - acc: 0.9485 - val_loss: 0.9016 - val_acc: 0.7024\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1368 - acc: 0.9612 - val_loss: 0.8907 - val_acc: 0.7292\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1390 - acc: 0.9493 - val_loss: 0.8850 - val_acc: 0.7381\n",
      "Epoch 83/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1388 - acc: 0.9493 - val_loss: 0.8869 - val_acc: 0.7351\n",
      "Epoch 84/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1386 - acc: 0.9582 - val_loss: 0.8964 - val_acc: 0.7232\n",
      "Epoch 85/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1514 - acc: 0.9500 - val_loss: 0.9134 - val_acc: 0.6935\n",
      "Epoch 86/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1334 - acc: 0.9567 - val_loss: 0.9367 - val_acc: 0.6815\n",
      "Epoch 87/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1457 - acc: 0.9455 - val_loss: 0.9596 - val_acc: 0.6786\n",
      "Epoch 88/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.1341 - acc: 0.9537 - val_loss: 0.9736 - val_acc: 0.6607\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD45_pos.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD65_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.9229 - acc: 0.2701 - val_loss: 1.4263 - val_acc: 0.2798\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 794us/step - loss: 1.7823 - acc: 0.2634 - val_loss: 1.4422 - val_acc: 0.3185\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 761us/step - loss: 1.7569 - acc: 0.2903 - val_loss: 1.4050 - val_acc: 0.3304\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 758us/step - loss: 1.6661 - acc: 0.2769 - val_loss: 1.3725 - val_acc: 0.3423\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 818us/step - loss: 1.6190 - acc: 0.3104 - val_loss: 1.3171 - val_acc: 0.3571\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 829us/step - loss: 1.5514 - acc: 0.3142 - val_loss: 1.2756 - val_acc: 0.3690\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 824us/step - loss: 1.5300 - acc: 0.3396 - val_loss: 1.2414 - val_acc: 0.4554\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 803us/step - loss: 1.5409 - acc: 0.3560 - val_loss: 1.2302 - val_acc: 0.4048\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 776us/step - loss: 1.4781 - acc: 0.3388 - val_loss: 1.2369 - val_acc: 0.4137\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 767us/step - loss: 1.4454 - acc: 0.3590 - val_loss: 1.2461 - val_acc: 0.4167\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 789us/step - loss: 1.4147 - acc: 0.3806 - val_loss: 1.2490 - val_acc: 0.4107\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 777us/step - loss: 1.3761 - acc: 0.3873 - val_loss: 1.2420 - val_acc: 0.4107\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 786us/step - loss: 1.4052 - acc: 0.3799 - val_loss: 1.2263 - val_acc: 0.4137\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 794us/step - loss: 1.3503 - acc: 0.3813 - val_loss: 1.2084 - val_acc: 0.4256\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 770us/step - loss: 1.3439 - acc: 0.3836 - val_loss: 1.1941 - val_acc: 0.4375\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 792us/step - loss: 1.3019 - acc: 0.4052 - val_loss: 1.1825 - val_acc: 0.4821\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 762us/step - loss: 1.3067 - acc: 0.4239 - val_loss: 1.1759 - val_acc: 0.5685\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 810us/step - loss: 1.2653 - acc: 0.4201 - val_loss: 1.1729 - val_acc: 0.5119\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 802us/step - loss: 1.2604 - acc: 0.4396 - val_loss: 1.1690 - val_acc: 0.5060\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 777us/step - loss: 1.2860 - acc: 0.4231 - val_loss: 1.1619 - val_acc: 0.4881\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 806us/step - loss: 1.2601 - acc: 0.4164 - val_loss: 1.1522 - val_acc: 0.4643\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 804us/step - loss: 1.2396 - acc: 0.4269 - val_loss: 1.1418 - val_acc: 0.4613\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2116 - acc: 0.4709 - val_loss: 1.1291 - val_acc: 0.4702\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 890us/step - loss: 1.1653 - acc: 0.4642 - val_loss: 1.1184 - val_acc: 0.4821\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 788us/step - loss: 1.1765 - acc: 0.4791 - val_loss: 1.1105 - val_acc: 0.5030\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 861us/step - loss: 1.1822 - acc: 0.4694 - val_loss: 1.1049 - val_acc: 0.5476\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 807us/step - loss: 1.1772 - acc: 0.4687 - val_loss: 1.1004 - val_acc: 0.5327\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 762us/step - loss: 1.1257 - acc: 0.4910 - val_loss: 1.0961 - val_acc: 0.5327\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 766us/step - loss: 1.0870 - acc: 0.5097 - val_loss: 1.0910 - val_acc: 0.5327\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 760us/step - loss: 1.1080 - acc: 0.5075 - val_loss: 1.0857 - val_acc: 0.5417\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 766us/step - loss: 1.0621 - acc: 0.5194 - val_loss: 1.0800 - val_acc: 0.5417\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 802us/step - loss: 1.0920 - acc: 0.5284 - val_loss: 1.0737 - val_acc: 0.4970\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 827us/step - loss: 1.0483 - acc: 0.5246 - val_loss: 1.0680 - val_acc: 0.4970\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 809us/step - loss: 1.0485 - acc: 0.5403 - val_loss: 1.0621 - val_acc: 0.4970\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 780us/step - loss: 1.0818 - acc: 0.5299 - val_loss: 1.0532 - val_acc: 0.4940\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 798us/step - loss: 1.0572 - acc: 0.5157 - val_loss: 1.0444 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 792us/step - loss: 1.0083 - acc: 0.5679 - val_loss: 1.0365 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 827us/step - loss: 0.9604 - acc: 0.5709 - val_loss: 1.0294 - val_acc: 0.5119\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 853us/step - loss: 0.9528 - acc: 0.5851 - val_loss: 1.0216 - val_acc: 0.5238\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 865us/step - loss: 0.9608 - acc: 0.5993 - val_loss: 1.0121 - val_acc: 0.5298\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 899us/step - loss: 0.9041 - acc: 0.5985 - val_loss: 1.0023 - val_acc: 0.5387\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 829us/step - loss: 0.8669 - acc: 0.6463 - val_loss: 0.9950 - val_acc: 0.5952\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 838us/step - loss: 0.8315 - acc: 0.6478 - val_loss: 0.9923 - val_acc: 0.5893\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 845us/step - loss: 0.8238 - acc: 0.6567 - val_loss: 0.9925 - val_acc: 0.5625\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 804us/step - loss: 0.8248 - acc: 0.6500 - val_loss: 0.9944 - val_acc: 0.5536\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 879us/step - loss: 0.7941 - acc: 0.6694 - val_loss: 0.9903 - val_acc: 0.5506\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 873us/step - loss: 0.7776 - acc: 0.6709 - val_loss: 0.9788 - val_acc: 0.5595\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.7363 - acc: 0.7037 - val_loss: 0.9655 - val_acc: 0.5804\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.7423 - acc: 0.6821 - val_loss: 0.9546 - val_acc: 0.6042\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.7197 - acc: 0.7127 - val_loss: 0.9479 - val_acc: 0.6548\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.6841 - acc: 0.7082 - val_loss: 0.9410 - val_acc: 0.6310\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.6649 - acc: 0.7336 - val_loss: 0.9353 - val_acc: 0.6399\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.6391 - acc: 0.7388 - val_loss: 0.9341 - val_acc: 0.6607\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.6248 - acc: 0.7552 - val_loss: 0.9361 - val_acc: 0.6339\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5995 - acc: 0.7321 - val_loss: 0.9422 - val_acc: 0.6131\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5846 - acc: 0.7567 - val_loss: 0.9489 - val_acc: 0.5893\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5848 - acc: 0.7500 - val_loss: 0.9535 - val_acc: 0.5804\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5510 - acc: 0.7701 - val_loss: 0.9469 - val_acc: 0.5952\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5666 - acc: 0.7694 - val_loss: 0.9394 - val_acc: 0.6548\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5285 - acc: 0.7851 - val_loss: 0.9313 - val_acc: 0.6696\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.5117 - acc: 0.8075 - val_loss: 0.9198 - val_acc: 0.6577\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 0.4774 - acc: 0.8090 - val_loss: 0.9059 - val_acc: 0.6696\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.4638 - acc: 0.8284 - val_loss: 0.8948 - val_acc: 0.6786\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4791 - acc: 0.8201 - val_loss: 0.8855 - val_acc: 0.6964\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4670 - acc: 0.8090 - val_loss: 0.8807 - val_acc: 0.7083\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4757 - acc: 0.8097 - val_loss: 0.8830 - val_acc: 0.6756\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4339 - acc: 0.8366 - val_loss: 0.8879 - val_acc: 0.6548\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.4187 - acc: 0.8403 - val_loss: 0.8922 - val_acc: 0.6339\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3847 - acc: 0.8478 - val_loss: 0.8936 - val_acc: 0.6399\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3913 - acc: 0.8470 - val_loss: 0.8948 - val_acc: 0.6429\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3668 - acc: 0.8657 - val_loss: 0.9032 - val_acc: 0.6399\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3977 - acc: 0.8470 - val_loss: 0.9200 - val_acc: 0.6161\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3409 - acc: 0.8687 - val_loss: 0.9445 - val_acc: 0.6042\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3326 - acc: 0.8724 - val_loss: 0.9623 - val_acc: 0.5893\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3148 - acc: 0.8799 - val_loss: 0.9428 - val_acc: 0.6012\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3374 - acc: 0.8642 - val_loss: 0.9196 - val_acc: 0.6369\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3320 - acc: 0.8873 - val_loss: 0.9100 - val_acc: 0.6369\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3306 - acc: 0.8791 - val_loss: 0.9016 - val_acc: 0.6369\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3070 - acc: 0.8873 - val_loss: 0.8887 - val_acc: 0.6369\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.3301 - acc: 0.8903 - val_loss: 0.8800 - val_acc: 0.6399\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2629 - acc: 0.8970 - val_loss: 0.8691 - val_acc: 0.6667\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2813 - acc: 0.9037 - val_loss: 0.8625 - val_acc: 0.6964\n",
      "Epoch 83/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2931 - acc: 0.8858 - val_loss: 0.8657 - val_acc: 0.7113\n",
      "Epoch 84/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2769 - acc: 0.9090 - val_loss: 0.8780 - val_acc: 0.6964\n",
      "Epoch 85/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2587 - acc: 0.9104 - val_loss: 0.9038 - val_acc: 0.6786\n",
      "Epoch 86/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2374 - acc: 0.9134 - val_loss: 0.9364 - val_acc: 0.6518\n",
      "Epoch 87/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2498 - acc: 0.9075 - val_loss: 0.9501 - val_acc: 0.6399\n",
      "Epoch 88/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2383 - acc: 0.9231 - val_loss: 0.9521 - val_acc: 0.6399\n",
      "Epoch 89/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2379 - acc: 0.9112 - val_loss: 0.9424 - val_acc: 0.6429\n",
      "Epoch 90/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2422 - acc: 0.9179 - val_loss: 0.9181 - val_acc: 0.6548\n",
      "Epoch 91/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2591 - acc: 0.9179 - val_loss: 0.8890 - val_acc: 0.6726\n",
      "Epoch 92/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.1966 - acc: 0.9299 - val_loss: 0.8684 - val_acc: 0.6845\n",
      "Epoch 93/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2281 - acc: 0.9179 - val_loss: 0.8546 - val_acc: 0.7173\n",
      "Epoch 94/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2157 - acc: 0.9343 - val_loss: 0.8574 - val_acc: 0.7262\n",
      "Epoch 95/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2064 - acc: 0.9276 - val_loss: 0.8760 - val_acc: 0.7083\n",
      "Epoch 96/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2012 - acc: 0.9284 - val_loss: 0.8887 - val_acc: 0.6935\n",
      "Epoch 97/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2140 - acc: 0.9246 - val_loss: 0.9009 - val_acc: 0.6786\n",
      "Epoch 98/100\n",
      "1340/1340 [==============================] - 2s 2ms/step - loss: 0.2128 - acc: 0.9261 - val_loss: 0.9031 - val_acc: 0.6786\n",
      "Epoch 99/100\n",
      "1340/1340 [==============================] - 1s 822us/step - loss: 0.1930 - acc: 0.9306 - val_loss: 0.9015 - val_acc: 0.6845\n",
      "Epoch 100/100\n",
      "1340/1340 [==============================] - 1s 796us/step - loss: 0.2104 - acc: 0.9291 - val_loss: 0.8986 - val_acc: 0.6905\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD65_pos.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD35_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 6ms/step - loss: 2.0533 - acc: 0.3351 - val_loss: 1.2986 - val_acc: 0.4362\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 235us/step - loss: 1.8480 - acc: 0.3029 - val_loss: 1.2835 - val_acc: 0.4362\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 1.8657 - acc: 0.2895 - val_loss: 1.3194 - val_acc: 0.4574\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 229us/step - loss: 1.9364 - acc: 0.3003 - val_loss: 1.3557 - val_acc: 0.4574\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 238us/step - loss: 1.6219 - acc: 0.3512 - val_loss: 1.3658 - val_acc: 0.4468\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 243us/step - loss: 1.6639 - acc: 0.3834 - val_loss: 1.3645 - val_acc: 0.4574\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 233us/step - loss: 1.7337 - acc: 0.3780 - val_loss: 1.3318 - val_acc: 0.4894\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 1.6004 - acc: 0.3995 - val_loss: 1.2851 - val_acc: 0.4894\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 248us/step - loss: 1.6495 - acc: 0.3995 - val_loss: 1.2404 - val_acc: 0.4894\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 244us/step - loss: 1.5223 - acc: 0.3753 - val_loss: 1.1909 - val_acc: 0.5106\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 235us/step - loss: 1.4015 - acc: 0.4450 - val_loss: 1.1336 - val_acc: 0.5319\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 229us/step - loss: 1.3890 - acc: 0.4209 - val_loss: 1.0891 - val_acc: 0.5319\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 231us/step - loss: 1.4892 - acc: 0.3834 - val_loss: 1.0532 - val_acc: 0.5426\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 1.2998 - acc: 0.4343 - val_loss: 1.0268 - val_acc: 0.5638\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 1.4375 - acc: 0.4182 - val_loss: 1.0071 - val_acc: 0.5745\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 227us/step - loss: 1.3077 - acc: 0.4424 - val_loss: 0.9948 - val_acc: 0.5745\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 235us/step - loss: 1.2504 - acc: 0.5308 - val_loss: 0.9805 - val_acc: 0.5745\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 1.1683 - acc: 0.4692 - val_loss: 0.9701 - val_acc: 0.6064\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 251us/step - loss: 1.2321 - acc: 0.4853 - val_loss: 0.9697 - val_acc: 0.5851\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 237us/step - loss: 1.2445 - acc: 0.4853 - val_loss: 0.9626 - val_acc: 0.5851\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 239us/step - loss: 1.1943 - acc: 0.4772 - val_loss: 0.9618 - val_acc: 0.5745\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 1.1382 - acc: 0.4960 - val_loss: 0.9573 - val_acc: 0.5851\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 239us/step - loss: 1.0770 - acc: 0.5228 - val_loss: 0.9574 - val_acc: 0.6170\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 262us/step - loss: 1.0448 - acc: 0.5362 - val_loss: 0.9551 - val_acc: 0.6277\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 226us/step - loss: 1.0523 - acc: 0.5067 - val_loss: 0.9554 - val_acc: 0.6170\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 1.0941 - acc: 0.5550 - val_loss: 0.9528 - val_acc: 0.6170\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 0.9955 - acc: 0.5684 - val_loss: 0.9481 - val_acc: 0.6064\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 231us/step - loss: 1.0009 - acc: 0.5657 - val_loss: 0.9453 - val_acc: 0.6064\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 253us/step - loss: 1.0589 - acc: 0.5228 - val_loss: 0.9369 - val_acc: 0.6277\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 235us/step - loss: 0.9969 - acc: 0.5845 - val_loss: 0.9228 - val_acc: 0.6277\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 248us/step - loss: 0.9509 - acc: 0.5791 - val_loss: 0.9089 - val_acc: 0.6383\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 239us/step - loss: 0.9091 - acc: 0.5925 - val_loss: 0.8884 - val_acc: 0.6383\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 229us/step - loss: 0.9004 - acc: 0.5925 - val_loss: 0.8695 - val_acc: 0.6383\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 231us/step - loss: 0.9232 - acc: 0.6086 - val_loss: 0.8502 - val_acc: 0.6489\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 0.9127 - acc: 0.6059 - val_loss: 0.8347 - val_acc: 0.6489\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 232us/step - loss: 0.8641 - acc: 0.6166 - val_loss: 0.8199 - val_acc: 0.6489\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 0.9484 - acc: 0.5791 - val_loss: 0.8129 - val_acc: 0.6489\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 238us/step - loss: 0.8415 - acc: 0.6649 - val_loss: 0.8070 - val_acc: 0.6277\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 250us/step - loss: 0.8249 - acc: 0.6193 - val_loss: 0.8054 - val_acc: 0.6277\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 234us/step - loss: 0.8353 - acc: 0.6488 - val_loss: 0.8061 - val_acc: 0.6277\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 257us/step - loss: 0.8175 - acc: 0.6622 - val_loss: 0.8069 - val_acc: 0.6277\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 238us/step - loss: 0.7701 - acc: 0.6729 - val_loss: 0.8078 - val_acc: 0.6277\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 0.8023 - acc: 0.6649 - val_loss: 0.8071 - val_acc: 0.6277\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 237us/step - loss: 0.7734 - acc: 0.6676 - val_loss: 0.8132 - val_acc: 0.6277\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 0.7402 - acc: 0.6836 - val_loss: 0.8186 - val_acc: 0.6383\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 237us/step - loss: 0.7303 - acc: 0.6890 - val_loss: 0.8239 - val_acc: 0.6383\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 0.6835 - acc: 0.7239 - val_loss: 0.8254 - val_acc: 0.6383\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 232us/step - loss: 0.6613 - acc: 0.7212 - val_loss: 0.8319 - val_acc: 0.6383\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 240us/step - loss: 0.7307 - acc: 0.6971 - val_loss: 0.8374 - val_acc: 0.6489\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 239us/step - loss: 0.7214 - acc: 0.6971 - val_loss: 0.8447 - val_acc: 0.6383\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 235us/step - loss: 0.6976 - acc: 0.7024 - val_loss: 0.8517 - val_acc: 0.6383\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 0.6444 - acc: 0.7265 - val_loss: 0.8622 - val_acc: 0.6383\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 232us/step - loss: 0.7347 - acc: 0.6997 - val_loss: 0.8750 - val_acc: 0.6383\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 0.6237 - acc: 0.7426 - val_loss: 0.8895 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 241us/step - loss: 0.6752 - acc: 0.7212 - val_loss: 0.9075 - val_acc: 0.6383\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 0.6590 - acc: 0.7319 - val_loss: 0.9217 - val_acc: 0.6383\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 234us/step - loss: 0.6771 - acc: 0.7239 - val_loss: 0.9269 - val_acc: 0.6383\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 224us/step - loss: 0.6016 - acc: 0.7560 - val_loss: 0.9304 - val_acc: 0.6596\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 244us/step - loss: 0.6096 - acc: 0.7534 - val_loss: 0.9388 - val_acc: 0.6596\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD35_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD45_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 3s 7ms/step - loss: 2.0206 - acc: 0.2869 - val_loss: 1.3158 - val_acc: 0.4362\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 273us/step - loss: 1.8925 - acc: 0.3056 - val_loss: 1.2813 - val_acc: 0.4468\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 265us/step - loss: 1.8854 - acc: 0.2949 - val_loss: 1.3499 - val_acc: 0.4362\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 264us/step - loss: 1.7426 - acc: 0.3566 - val_loss: 1.3973 - val_acc: 0.4574\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 283us/step - loss: 1.6474 - acc: 0.3727 - val_loss: 1.4106 - val_acc: 0.4574\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 272us/step - loss: 1.5675 - acc: 0.3834 - val_loss: 1.3840 - val_acc: 0.4574\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 268us/step - loss: 1.6529 - acc: 0.3646 - val_loss: 1.3524 - val_acc: 0.4574\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 260us/step - loss: 1.5853 - acc: 0.4209 - val_loss: 1.3101 - val_acc: 0.4681\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 279us/step - loss: 1.6059 - acc: 0.3458 - val_loss: 1.2548 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 266us/step - loss: 1.6598 - acc: 0.3566 - val_loss: 1.2045 - val_acc: 0.5319\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 266us/step - loss: 1.4284 - acc: 0.4129 - val_loss: 1.1569 - val_acc: 0.5319\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 272us/step - loss: 1.3824 - acc: 0.4611 - val_loss: 1.1146 - val_acc: 0.5426\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 271us/step - loss: 1.3966 - acc: 0.4397 - val_loss: 1.0770 - val_acc: 0.5532\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 268us/step - loss: 1.3077 - acc: 0.4477 - val_loss: 1.0471 - val_acc: 0.5745\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 275us/step - loss: 1.4486 - acc: 0.4048 - val_loss: 1.0210 - val_acc: 0.5745\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 265us/step - loss: 1.3181 - acc: 0.4611 - val_loss: 1.0034 - val_acc: 0.5851\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 267us/step - loss: 1.2680 - acc: 0.4853 - val_loss: 0.9896 - val_acc: 0.5851\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 280us/step - loss: 1.2530 - acc: 0.4638 - val_loss: 0.9789 - val_acc: 0.5851\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 294us/step - loss: 1.2659 - acc: 0.4450 - val_loss: 0.9712 - val_acc: 0.5851\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 310us/step - loss: 1.1785 - acc: 0.5174 - val_loss: 0.9675 - val_acc: 0.5851\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 283us/step - loss: 1.1161 - acc: 0.5496 - val_loss: 0.9615 - val_acc: 0.5851\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 283us/step - loss: 1.0871 - acc: 0.5255 - val_loss: 0.9578 - val_acc: 0.5851\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 290us/step - loss: 1.0893 - acc: 0.5228 - val_loss: 0.9565 - val_acc: 0.5851\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 269us/step - loss: 1.0353 - acc: 0.5684 - val_loss: 0.9523 - val_acc: 0.5851\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 276us/step - loss: 1.0416 - acc: 0.5603 - val_loss: 0.9521 - val_acc: 0.5851\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 270us/step - loss: 1.0382 - acc: 0.5523 - val_loss: 0.9489 - val_acc: 0.5851\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 267us/step - loss: 0.9786 - acc: 0.5684 - val_loss: 0.9414 - val_acc: 0.5851\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 271us/step - loss: 1.0256 - acc: 0.5791 - val_loss: 0.9332 - val_acc: 0.5851\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 285us/step - loss: 0.9617 - acc: 0.5684 - val_loss: 0.9256 - val_acc: 0.5957\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 282us/step - loss: 1.0550 - acc: 0.5710 - val_loss: 0.9156 - val_acc: 0.5957\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 276us/step - loss: 0.9685 - acc: 0.5684 - val_loss: 0.9075 - val_acc: 0.6170\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 270us/step - loss: 0.9786 - acc: 0.5737 - val_loss: 0.9030 - val_acc: 0.6277\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 276us/step - loss: 1.0151 - acc: 0.5845 - val_loss: 0.8968 - val_acc: 0.6277\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 268us/step - loss: 0.9358 - acc: 0.5657 - val_loss: 0.8931 - val_acc: 0.6277\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 279us/step - loss: 0.8657 - acc: 0.6354 - val_loss: 0.8904 - val_acc: 0.6383\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 266us/step - loss: 0.8248 - acc: 0.6434 - val_loss: 0.8909 - val_acc: 0.6383\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 268us/step - loss: 0.8994 - acc: 0.6139 - val_loss: 0.8905 - val_acc: 0.6489\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 266us/step - loss: 0.8403 - acc: 0.6247 - val_loss: 0.8902 - val_acc: 0.6596\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 290us/step - loss: 0.8595 - acc: 0.6461 - val_loss: 0.8914 - val_acc: 0.6596\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 264us/step - loss: 0.8268 - acc: 0.6354 - val_loss: 0.8919 - val_acc: 0.6383\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 272us/step - loss: 0.8099 - acc: 0.6676 - val_loss: 0.8927 - val_acc: 0.6489\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 276us/step - loss: 0.8000 - acc: 0.6381 - val_loss: 0.8949 - val_acc: 0.6489\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 278us/step - loss: 0.7805 - acc: 0.6676 - val_loss: 0.8969 - val_acc: 0.6489\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 263us/step - loss: 0.8057 - acc: 0.6381 - val_loss: 0.8991 - val_acc: 0.6383\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 277us/step - loss: 0.8285 - acc: 0.6702 - val_loss: 0.9019 - val_acc: 0.6383\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 273us/step - loss: 0.7487 - acc: 0.7131 - val_loss: 0.9040 - val_acc: 0.6489\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 269us/step - loss: 0.6987 - acc: 0.7239 - val_loss: 0.9088 - val_acc: 0.6489\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 270us/step - loss: 0.7540 - acc: 0.6756 - val_loss: 0.9164 - val_acc: 0.6596\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 284us/step - loss: 0.7482 - acc: 0.6944 - val_loss: 0.9224 - val_acc: 0.6596\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 269us/step - loss: 0.7080 - acc: 0.6997 - val_loss: 0.9269 - val_acc: 0.6596\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 265us/step - loss: 0.7094 - acc: 0.6971 - val_loss: 0.9304 - val_acc: 0.6596\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 280us/step - loss: 0.7066 - acc: 0.7131 - val_loss: 0.9361 - val_acc: 0.6489\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 281us/step - loss: 0.7240 - acc: 0.6944 - val_loss: 0.9428 - val_acc: 0.6596\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 270us/step - loss: 0.6715 - acc: 0.7158 - val_loss: 0.9524 - val_acc: 0.6596\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 281us/step - loss: 0.7420 - acc: 0.6863 - val_loss: 0.9635 - val_acc: 0.6596\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 266us/step - loss: 0.6583 - acc: 0.7319 - val_loss: 0.9765 - val_acc: 0.6489\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 300us/step - loss: 0.6959 - acc: 0.7212 - val_loss: 0.9885 - val_acc: 0.6489\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 277us/step - loss: 0.6057 - acc: 0.7373 - val_loss: 1.0022 - val_acc: 0.6489\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD45_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD65_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 3s 8ms/step - loss: 2.0837 - acc: 0.2869 - val_loss: 1.3364 - val_acc: 0.4043\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 427us/step - loss: 1.9090 - acc: 0.2976 - val_loss: 1.2452 - val_acc: 0.4255\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 425us/step - loss: 1.9388 - acc: 0.2976 - val_loss: 1.2644 - val_acc: 0.5106\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 1.8523 - acc: 0.3190 - val_loss: 1.3075 - val_acc: 0.5106\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 430us/step - loss: 1.7209 - acc: 0.3485 - val_loss: 1.3087 - val_acc: 0.5106\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 419us/step - loss: 1.6821 - acc: 0.3512 - val_loss: 1.2787 - val_acc: 0.5106\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 415us/step - loss: 1.6443 - acc: 0.3592 - val_loss: 1.2445 - val_acc: 0.5106\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 427us/step - loss: 1.6083 - acc: 0.4021 - val_loss: 1.2066 - val_acc: 0.5106\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 416us/step - loss: 1.6956 - acc: 0.3458 - val_loss: 1.1669 - val_acc: 0.5106\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 484us/step - loss: 1.5086 - acc: 0.3914 - val_loss: 1.1338 - val_acc: 0.5106\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 431us/step - loss: 1.4918 - acc: 0.3780 - val_loss: 1.1024 - val_acc: 0.5213\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 420us/step - loss: 1.4130 - acc: 0.3968 - val_loss: 1.0747 - val_acc: 0.5532\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 430us/step - loss: 1.4579 - acc: 0.3780 - val_loss: 1.0574 - val_acc: 0.5532\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 424us/step - loss: 1.4227 - acc: 0.4075 - val_loss: 1.0428 - val_acc: 0.5532\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 419us/step - loss: 1.4699 - acc: 0.3995 - val_loss: 1.0312 - val_acc: 0.5532\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 1.3890 - acc: 0.4209 - val_loss: 1.0240 - val_acc: 0.5638\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 423us/step - loss: 1.2604 - acc: 0.4397 - val_loss: 1.0165 - val_acc: 0.5638\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 436us/step - loss: 1.3184 - acc: 0.4316 - val_loss: 1.0099 - val_acc: 0.5532\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 422us/step - loss: 1.3730 - acc: 0.4263 - val_loss: 1.0046 - val_acc: 0.5638\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 448us/step - loss: 1.3128 - acc: 0.4236 - val_loss: 0.9995 - val_acc: 0.5638\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 423us/step - loss: 1.2931 - acc: 0.4584 - val_loss: 0.9944 - val_acc: 0.5638\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 416us/step - loss: 1.2582 - acc: 0.4370 - val_loss: 0.9914 - val_acc: 0.5745\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 438us/step - loss: 1.2114 - acc: 0.4477 - val_loss: 0.9892 - val_acc: 0.5638\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 430us/step - loss: 1.1397 - acc: 0.4987 - val_loss: 0.9908 - val_acc: 0.5638\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 1.1275 - acc: 0.5067 - val_loss: 0.9904 - val_acc: 0.5532\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 438us/step - loss: 1.2170 - acc: 0.4906 - val_loss: 0.9880 - val_acc: 0.5532\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 426us/step - loss: 1.1426 - acc: 0.5094 - val_loss: 0.9840 - val_acc: 0.5532\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 409us/step - loss: 1.1300 - acc: 0.5067 - val_loss: 0.9797 - val_acc: 0.5532\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 433us/step - loss: 1.1030 - acc: 0.5147 - val_loss: 0.9735 - val_acc: 0.5638\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 416us/step - loss: 1.1446 - acc: 0.4960 - val_loss: 0.9684 - val_acc: 0.5638\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 434us/step - loss: 1.1340 - acc: 0.5201 - val_loss: 0.9625 - val_acc: 0.5851\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 414us/step - loss: 1.1004 - acc: 0.5308 - val_loss: 0.9574 - val_acc: 0.5957\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 416us/step - loss: 0.9910 - acc: 0.5603 - val_loss: 0.9536 - val_acc: 0.5957\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 432us/step - loss: 1.0684 - acc: 0.5201 - val_loss: 0.9524 - val_acc: 0.5957\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 431us/step - loss: 1.0925 - acc: 0.5040 - val_loss: 0.9533 - val_acc: 0.5957\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 420us/step - loss: 1.0631 - acc: 0.5523 - val_loss: 0.9551 - val_acc: 0.5957\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 414us/step - loss: 1.0098 - acc: 0.5818 - val_loss: 0.9570 - val_acc: 0.5957\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 436us/step - loss: 1.0388 - acc: 0.5255 - val_loss: 0.9606 - val_acc: 0.5957\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 417us/step - loss: 0.9780 - acc: 0.5684 - val_loss: 0.9675 - val_acc: 0.5957\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 415us/step - loss: 0.9703 - acc: 0.5952 - val_loss: 0.9738 - val_acc: 0.5957\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 0.9574 - acc: 0.6247 - val_loss: 0.9773 - val_acc: 0.5957\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 427us/step - loss: 0.9236 - acc: 0.5979 - val_loss: 0.9773 - val_acc: 0.6064\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 422us/step - loss: 0.9190 - acc: 0.6086 - val_loss: 0.9744 - val_acc: 0.6064\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 425us/step - loss: 0.9711 - acc: 0.5818 - val_loss: 0.9683 - val_acc: 0.6170\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 423us/step - loss: 0.8450 - acc: 0.6354 - val_loss: 0.9613 - val_acc: 0.6170\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 417us/step - loss: 0.9028 - acc: 0.6113 - val_loss: 0.9555 - val_acc: 0.6383\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 0.9090 - acc: 0.6247 - val_loss: 0.9486 - val_acc: 0.6383\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 442us/step - loss: 0.8425 - acc: 0.6515 - val_loss: 0.9434 - val_acc: 0.6489\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 433us/step - loss: 0.8537 - acc: 0.6408 - val_loss: 0.9414 - val_acc: 0.6489\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 434us/step - loss: 0.8736 - acc: 0.6247 - val_loss: 0.9392 - val_acc: 0.6277\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 422us/step - loss: 0.8273 - acc: 0.6622 - val_loss: 0.9386 - val_acc: 0.6277\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 432us/step - loss: 0.8300 - acc: 0.6488 - val_loss: 0.9371 - val_acc: 0.6277\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 427us/step - loss: 0.8151 - acc: 0.6649 - val_loss: 0.9370 - val_acc: 0.6383\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 429us/step - loss: 0.7778 - acc: 0.6568 - val_loss: 0.9364 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 425us/step - loss: 0.7875 - acc: 0.6622 - val_loss: 0.9353 - val_acc: 0.6383\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 425us/step - loss: 0.7729 - acc: 0.6783 - val_loss: 0.9349 - val_acc: 0.6383\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 422us/step - loss: 0.7529 - acc: 0.6890 - val_loss: 0.9328 - val_acc: 0.6383\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 419us/step - loss: 0.7310 - acc: 0.7024 - val_loss: 0.9317 - val_acc: 0.6383\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 417us/step - loss: 0.7578 - acc: 0.6890 - val_loss: 0.9308 - val_acc: 0.6383\n",
      "Epoch 60/100\n",
      "373/373 [==============================] - 0s 438us/step - loss: 0.7462 - acc: 0.6890 - val_loss: 0.9317 - val_acc: 0.6383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "373/373 [==============================] - 0s 420us/step - loss: 0.7082 - acc: 0.6917 - val_loss: 0.9319 - val_acc: 0.6383\n",
      "Epoch 62/100\n",
      "373/373 [==============================] - 0s 425us/step - loss: 0.7825 - acc: 0.6756 - val_loss: 0.9322 - val_acc: 0.6383\n",
      "Epoch 63/100\n",
      "373/373 [==============================] - 0s 413us/step - loss: 0.6933 - acc: 0.6756 - val_loss: 0.9341 - val_acc: 0.6383\n",
      "Epoch 64/100\n",
      "373/373 [==============================] - 0s 420us/step - loss: 0.7223 - acc: 0.7024 - val_loss: 0.9366 - val_acc: 0.6489\n",
      "Epoch 65/100\n",
      "373/373 [==============================] - 0s 418us/step - loss: 0.6697 - acc: 0.7239 - val_loss: 0.9395 - val_acc: 0.6489\n",
      "Epoch 66/100\n",
      "373/373 [==============================] - 0s 418us/step - loss: 0.6740 - acc: 0.7131 - val_loss: 0.9437 - val_acc: 0.6489\n",
      "Epoch 67/100\n",
      "373/373 [==============================] - 0s 416us/step - loss: 0.6614 - acc: 0.7265 - val_loss: 0.9486 - val_acc: 0.6596\n",
      "Epoch 68/100\n",
      "373/373 [==============================] - 0s 426us/step - loss: 0.6380 - acc: 0.7346 - val_loss: 0.9525 - val_acc: 0.6596\n",
      "Epoch 69/100\n",
      "373/373 [==============================] - 0s 424us/step - loss: 0.6412 - acc: 0.7480 - val_loss: 0.9568 - val_acc: 0.6702\n",
      "Epoch 70/100\n",
      "373/373 [==============================] - 0s 437us/step - loss: 0.6415 - acc: 0.7319 - val_loss: 0.9630 - val_acc: 0.6596\n",
      "Epoch 71/100\n",
      "373/373 [==============================] - 0s 433us/step - loss: 0.5963 - acc: 0.7426 - val_loss: 0.9731 - val_acc: 0.6596\n",
      "Epoch 72/100\n",
      "373/373 [==============================] - 0s 424us/step - loss: 0.5989 - acc: 0.7587 - val_loss: 0.9843 - val_acc: 0.6596\n",
      "Epoch 73/100\n",
      "373/373 [==============================] - 0s 419us/step - loss: 0.6476 - acc: 0.7185 - val_loss: 0.9948 - val_acc: 0.6489\n",
      "Epoch 74/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 0.6327 - acc: 0.7399 - val_loss: 1.0043 - val_acc: 0.6596\n",
      "Epoch 75/100\n",
      "373/373 [==============================] - 0s 418us/step - loss: 0.6595 - acc: 0.7399 - val_loss: 1.0101 - val_acc: 0.6596\n",
      "Epoch 76/100\n",
      "373/373 [==============================] - 0s 420us/step - loss: 0.6208 - acc: 0.7614 - val_loss: 1.0163 - val_acc: 0.6702\n",
      "Epoch 77/100\n",
      "373/373 [==============================] - 0s 417us/step - loss: 0.5334 - acc: 0.7909 - val_loss: 1.0233 - val_acc: 0.6383\n",
      "Epoch 78/100\n",
      "373/373 [==============================] - 0s 429us/step - loss: 0.5413 - acc: 0.7802 - val_loss: 1.0320 - val_acc: 0.6596\n",
      "Epoch 79/100\n",
      "373/373 [==============================] - 0s 425us/step - loss: 0.5660 - acc: 0.7721 - val_loss: 1.0422 - val_acc: 0.6596\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD65_neg.h5')\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [f, j], \n",
    "    index=['Accuracy', 'Time'],\n",
    "    columns = [\n",
    "        'HCD35_Positive','HCD45_Positive','HCD65_Positive',\n",
    "        'HCD35_Negative','HCD45_Negative','HCD65_Negative'\n",
    "    ]\n",
    ").T.to_csv('../result/Keras.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
