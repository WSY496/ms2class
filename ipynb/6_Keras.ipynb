{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, GaussianNoise, GaussianDropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from  keras.regularizers import l1, l2\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\", \n",
    "        allow_growth=True,\n",
    "#         per_process_gpu_memory_fraction=0.5\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD35_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.9805 - acc: 0.2694 - val_loss: 1.4347 - val_acc: 0.2827\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 644us/step - loss: 1.8146 - acc: 0.2687 - val_loss: 1.4782 - val_acc: 0.3244\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 630us/step - loss: 1.7504 - acc: 0.3030 - val_loss: 1.4241 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 1.6849 - acc: 0.3104 - val_loss: 1.3657 - val_acc: 0.3512\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 629us/step - loss: 1.7023 - acc: 0.3172 - val_loss: 1.2952 - val_acc: 0.3899\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 625us/step - loss: 1.5395 - acc: 0.3343 - val_loss: 1.2399 - val_acc: 0.4137\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 630us/step - loss: 1.5223 - acc: 0.3478 - val_loss: 1.2339 - val_acc: 0.4583\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 638us/step - loss: 1.5516 - acc: 0.3567 - val_loss: 1.2283 - val_acc: 0.4345\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 1.5128 - acc: 0.3642 - val_loss: 1.2178 - val_acc: 0.4345\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 1.4607 - acc: 0.3754 - val_loss: 1.2021 - val_acc: 0.4464\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 645us/step - loss: 1.4348 - acc: 0.4075 - val_loss: 1.1833 - val_acc: 0.5119\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 639us/step - loss: 1.3429 - acc: 0.4172 - val_loss: 1.1770 - val_acc: 0.4464\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 642us/step - loss: 1.3490 - acc: 0.4209 - val_loss: 1.1696 - val_acc: 0.4226\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 1.2676 - acc: 0.4664 - val_loss: 1.1553 - val_acc: 0.4226\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 631us/step - loss: 1.2131 - acc: 0.4604 - val_loss: 1.1337 - val_acc: 0.4375\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 1.1952 - acc: 0.4470 - val_loss: 1.1098 - val_acc: 0.4464\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 642us/step - loss: 1.2115 - acc: 0.5030 - val_loss: 1.0912 - val_acc: 0.4762\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 631us/step - loss: 1.1263 - acc: 0.5142 - val_loss: 1.0741 - val_acc: 0.4970\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 630us/step - loss: 1.0949 - acc: 0.5373 - val_loss: 1.0541 - val_acc: 0.5595\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 623us/step - loss: 1.0975 - acc: 0.5254 - val_loss: 1.0413 - val_acc: 0.5952\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 631us/step - loss: 1.0759 - acc: 0.5485 - val_loss: 1.0352 - val_acc: 0.5417\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 1.0206 - acc: 0.5604 - val_loss: 1.0285 - val_acc: 0.5446\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 638us/step - loss: 1.0176 - acc: 0.5739 - val_loss: 1.0164 - val_acc: 0.6012\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 635us/step - loss: 0.9669 - acc: 0.6000 - val_loss: 1.0044 - val_acc: 0.6220\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 630us/step - loss: 0.8984 - acc: 0.6045 - val_loss: 0.9945 - val_acc: 0.6488\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 0.8704 - acc: 0.6328 - val_loss: 0.9860 - val_acc: 0.6399\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 0.9211 - acc: 0.6149 - val_loss: 0.9805 - val_acc: 0.6458\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 630us/step - loss: 0.8589 - acc: 0.6396 - val_loss: 0.9727 - val_acc: 0.6280\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 627us/step - loss: 0.8276 - acc: 0.6567 - val_loss: 0.9672 - val_acc: 0.6399\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 629us/step - loss: 0.8127 - acc: 0.6687 - val_loss: 0.9622 - val_acc: 0.6369\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.7534 - acc: 0.6866 - val_loss: 0.9565 - val_acc: 0.6280\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 644us/step - loss: 0.7695 - acc: 0.6821 - val_loss: 0.9528 - val_acc: 0.6161\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 635us/step - loss: 0.7529 - acc: 0.6933 - val_loss: 0.9492 - val_acc: 0.6131\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 629us/step - loss: 0.7241 - acc: 0.6955 - val_loss: 0.9453 - val_acc: 0.6339\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 646us/step - loss: 0.7194 - acc: 0.7000 - val_loss: 0.9424 - val_acc: 0.6369\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 629us/step - loss: 0.6902 - acc: 0.7201 - val_loss: 0.9368 - val_acc: 0.6399\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 641us/step - loss: 0.6295 - acc: 0.7507 - val_loss: 0.9288 - val_acc: 0.6637\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 0.6172 - acc: 0.7425 - val_loss: 0.9232 - val_acc: 0.6905\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 0.6148 - acc: 0.7493 - val_loss: 0.9174 - val_acc: 0.7083\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.6033 - acc: 0.7634 - val_loss: 0.9162 - val_acc: 0.7232\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 0.5963 - acc: 0.7619 - val_loss: 0.9173 - val_acc: 0.7381\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.5028 - acc: 0.7888 - val_loss: 0.9205 - val_acc: 0.7262\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 0.4963 - acc: 0.8022 - val_loss: 0.9237 - val_acc: 0.7173\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 650us/step - loss: 0.4762 - acc: 0.8119 - val_loss: 0.9273 - val_acc: 0.6845\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 0.4706 - acc: 0.8134 - val_loss: 0.9308 - val_acc: 0.6786\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.4284 - acc: 0.8291 - val_loss: 0.9298 - val_acc: 0.6845\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 636us/step - loss: 0.4308 - acc: 0.8351 - val_loss: 0.9260 - val_acc: 0.7054\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 626us/step - loss: 0.3536 - acc: 0.8709 - val_loss: 0.9265 - val_acc: 0.7173\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 0.3914 - acc: 0.8463 - val_loss: 0.9344 - val_acc: 0.7054\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 635us/step - loss: 0.3864 - acc: 0.8537 - val_loss: 0.9508 - val_acc: 0.7024\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.3305 - acc: 0.8791 - val_loss: 0.9682 - val_acc: 0.6964\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 628us/step - loss: 0.3472 - acc: 0.8858 - val_loss: 0.9791 - val_acc: 0.6935\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 634us/step - loss: 0.3161 - acc: 0.8866 - val_loss: 0.9815 - val_acc: 0.6845\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 1s 632us/step - loss: 0.3032 - acc: 0.8873 - val_loss: 0.9880 - val_acc: 0.6905\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 1s 626us/step - loss: 0.2964 - acc: 0.9000 - val_loss: 0.9965 - val_acc: 0.6905\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 1s 640us/step - loss: 0.2656 - acc: 0.9045 - val_loss: 0.9969 - val_acc: 0.6875\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 0.2717 - acc: 0.9037 - val_loss: 0.9953 - val_acc: 0.6905\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 1s 630us/step - loss: 0.2669 - acc: 0.9067 - val_loss: 0.9978 - val_acc: 0.6964\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 1s 633us/step - loss: 0.2418 - acc: 0.9134 - val_loss: 1.0030 - val_acc: 0.6964\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1340 [=====================>........] - ETA: 0s - loss: 0.2687 - acc: 0.9160\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1340/1340 [==============================] - 1s 630us/step - loss: 0.2526 - acc: 0.9194 - val_loss: 1.0075 - val_acc: 0.6845\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD35_pos.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "j = []\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f = []\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6845238095238095"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD45_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.8826 - acc: 0.2552 - val_loss: 1.3688 - val_acc: 0.3036\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 1.8066 - acc: 0.2597 - val_loss: 1.3868 - val_acc: 0.3601\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 1.7338 - acc: 0.2866 - val_loss: 1.3590 - val_acc: 0.3661\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 733us/step - loss: 1.6625 - acc: 0.2806 - val_loss: 1.2929 - val_acc: 0.3601\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 1.6393 - acc: 0.3157 - val_loss: 1.2651 - val_acc: 0.3720\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 726us/step - loss: 1.5121 - acc: 0.3231 - val_loss: 1.2535 - val_acc: 0.4435\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 1.5098 - acc: 0.3381 - val_loss: 1.2493 - val_acc: 0.3988\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 1.4553 - acc: 0.3597 - val_loss: 1.2476 - val_acc: 0.3958\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 1.3906 - acc: 0.3978 - val_loss: 1.2385 - val_acc: 0.4286\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 726us/step - loss: 1.4368 - acc: 0.3978 - val_loss: 1.2204 - val_acc: 0.4940\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 736us/step - loss: 1.3273 - acc: 0.4075 - val_loss: 1.1949 - val_acc: 0.4375\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 1.3460 - acc: 0.4045 - val_loss: 1.1714 - val_acc: 0.4464\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 726us/step - loss: 1.3395 - acc: 0.4231 - val_loss: 1.1526 - val_acc: 0.4524\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 1.2711 - acc: 0.4187 - val_loss: 1.1379 - val_acc: 0.4851\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 1.2522 - acc: 0.4291 - val_loss: 1.1256 - val_acc: 0.5238\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 1.2583 - acc: 0.4149 - val_loss: 1.1142 - val_acc: 0.5506\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 738us/step - loss: 1.2269 - acc: 0.4485 - val_loss: 1.1019 - val_acc: 0.5595\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 1.1912 - acc: 0.4649 - val_loss: 1.0872 - val_acc: 0.5446\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 1.2358 - acc: 0.4448 - val_loss: 1.0756 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 736us/step - loss: 1.1333 - acc: 0.4821 - val_loss: 1.0659 - val_acc: 0.4970\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 1.1262 - acc: 0.4828 - val_loss: 1.0550 - val_acc: 0.4911\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.1262 - acc: 0.5090 - val_loss: 1.0437 - val_acc: 0.4911\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 1.1115 - acc: 0.5134 - val_loss: 1.0324 - val_acc: 0.4970\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 733us/step - loss: 1.0855 - acc: 0.5366 - val_loss: 1.0176 - val_acc: 0.5089\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 737us/step - loss: 1.0247 - acc: 0.5418 - val_loss: 1.0003 - val_acc: 0.5417\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 751us/step - loss: 1.0099 - acc: 0.5701 - val_loss: 0.9873 - val_acc: 0.5833\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.9857 - acc: 0.5590 - val_loss: 0.9803 - val_acc: 0.5863\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 733us/step - loss: 0.9438 - acc: 0.5858 - val_loss: 0.9767 - val_acc: 0.5863\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 733us/step - loss: 0.9685 - acc: 0.5851 - val_loss: 0.9709 - val_acc: 0.5982\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 735us/step - loss: 0.9374 - acc: 0.6000 - val_loss: 0.9608 - val_acc: 0.5804\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 755us/step - loss: 0.9535 - acc: 0.6090 - val_loss: 0.9506 - val_acc: 0.5804\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.8602 - acc: 0.6179 - val_loss: 0.9394 - val_acc: 0.6042\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.8492 - acc: 0.6306 - val_loss: 0.9302 - val_acc: 0.6339\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.8707 - acc: 0.6157 - val_loss: 0.9211 - val_acc: 0.6339\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 730us/step - loss: 0.8661 - acc: 0.6112 - val_loss: 0.9167 - val_acc: 0.6101\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 738us/step - loss: 0.8124 - acc: 0.6530 - val_loss: 0.9143 - val_acc: 0.5804\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 738us/step - loss: 0.7789 - acc: 0.6619 - val_loss: 0.9060 - val_acc: 0.5863\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.7606 - acc: 0.6746 - val_loss: 0.8959 - val_acc: 0.6042\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 739us/step - loss: 0.7433 - acc: 0.6925 - val_loss: 0.8825 - val_acc: 0.6429\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 734us/step - loss: 0.7113 - acc: 0.6963 - val_loss: 0.8719 - val_acc: 0.6667\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.6579 - acc: 0.7172 - val_loss: 0.8645 - val_acc: 0.6935\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 744us/step - loss: 0.6736 - acc: 0.7067 - val_loss: 0.8574 - val_acc: 0.6935\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.6308 - acc: 0.7493 - val_loss: 0.8517 - val_acc: 0.6875\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.6102 - acc: 0.7507 - val_loss: 0.8483 - val_acc: 0.6637\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.5817 - acc: 0.7582 - val_loss: 0.8441 - val_acc: 0.6399\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.5265 - acc: 0.7776 - val_loss: 0.8447 - val_acc: 0.6458\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.5507 - acc: 0.7769 - val_loss: 0.8388 - val_acc: 0.6577\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.4801 - acc: 0.8119 - val_loss: 0.8300 - val_acc: 0.6696\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.4981 - acc: 0.8157 - val_loss: 0.8193 - val_acc: 0.6726\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 0.4757 - acc: 0.8201 - val_loss: 0.8104 - val_acc: 0.6815\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.4318 - acc: 0.8403 - val_loss: 0.8040 - val_acc: 0.7024\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 0.4320 - acc: 0.8358 - val_loss: 0.7989 - val_acc: 0.7083\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.4402 - acc: 0.8261 - val_loss: 0.7994 - val_acc: 0.6905\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.3956 - acc: 0.8657 - val_loss: 0.8017 - val_acc: 0.6786\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 1s 745us/step - loss: 0.3783 - acc: 0.8634 - val_loss: 0.7992 - val_acc: 0.6875\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.3952 - acc: 0.8552 - val_loss: 0.7985 - val_acc: 0.6845\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 0.3454 - acc: 0.8761 - val_loss: 0.7949 - val_acc: 0.6964\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 0.3466 - acc: 0.8672 - val_loss: 0.7952 - val_acc: 0.6994\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.2950 - acc: 0.8918 - val_loss: 0.7961 - val_acc: 0.7083\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 1s 729us/step - loss: 0.2828 - acc: 0.8933 - val_loss: 0.7943 - val_acc: 0.7173\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.2825 - acc: 0.8985 - val_loss: 0.7889 - val_acc: 0.7232\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.2639 - acc: 0.9022 - val_loss: 0.7853 - val_acc: 0.7292\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.2845 - acc: 0.9015 - val_loss: 0.7874 - val_acc: 0.7232\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.2460 - acc: 0.9209 - val_loss: 0.7953 - val_acc: 0.7143\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.2465 - acc: 0.9172 - val_loss: 0.8012 - val_acc: 0.7054\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 0.2399 - acc: 0.9149 - val_loss: 0.8052 - val_acc: 0.7113\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.2410 - acc: 0.9119 - val_loss: 0.8128 - val_acc: 0.7024\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 0.2261 - acc: 0.9194 - val_loss: 0.8118 - val_acc: 0.7024\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.2313 - acc: 0.9216 - val_loss: 0.8030 - val_acc: 0.7054\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.2177 - acc: 0.9276 - val_loss: 0.7965 - val_acc: 0.7083\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.2113 - acc: 0.9231 - val_loss: 0.7949 - val_acc: 0.7232\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.2060 - acc: 0.9388 - val_loss: 0.7971 - val_acc: 0.7173\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 1s 733us/step - loss: 0.2158 - acc: 0.9358 - val_loss: 0.8052 - val_acc: 0.7054\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.2101 - acc: 0.9366 - val_loss: 0.8124 - val_acc: 0.6994\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 1s 726us/step - loss: 0.2010 - acc: 0.9396 - val_loss: 0.8164 - val_acc: 0.7083\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 0.2002 - acc: 0.9328 - val_loss: 0.8196 - val_acc: 0.7143\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 1s 730us/step - loss: 0.1674 - acc: 0.9500 - val_loss: 0.8215 - val_acc: 0.7083\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 1s 741us/step - loss: 0.1832 - acc: 0.9410 - val_loss: 0.8190 - val_acc: 0.7113\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 0.1806 - acc: 0.9455 - val_loss: 0.8151 - val_acc: 0.7054\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 1s 735us/step - loss: 0.1945 - acc: 0.9366 - val_loss: 0.8166 - val_acc: 0.7083\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 1s 732us/step - loss: 0.1724 - acc: 0.9478 - val_loss: 0.8211 - val_acc: 0.7262\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 1s 730us/step - loss: 0.1562 - acc: 0.9410 - val_loss: 0.8271 - val_acc: 0.7321\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD45_pos.h5', include_optimizer=False)\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD65_pos.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 1.9229 - acc: 0.2701 - val_loss: 1.4263 - val_acc: 0.2798\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.7823 - acc: 0.2634 - val_loss: 1.4422 - val_acc: 0.3185\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 713us/step - loss: 1.7569 - acc: 0.2903 - val_loss: 1.4050 - val_acc: 0.3304\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 1.6661 - acc: 0.2769 - val_loss: 1.3725 - val_acc: 0.3423\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 1.6190 - acc: 0.3104 - val_loss: 1.3171 - val_acc: 0.3571\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 1.5514 - acc: 0.3142 - val_loss: 1.2756 - val_acc: 0.3690\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 1.5300 - acc: 0.3396 - val_loss: 1.2414 - val_acc: 0.4554\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.5409 - acc: 0.3552 - val_loss: 1.2303 - val_acc: 0.4048\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.4779 - acc: 0.3373 - val_loss: 1.2369 - val_acc: 0.4137\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 735us/step - loss: 1.4455 - acc: 0.3612 - val_loss: 1.2461 - val_acc: 0.4167\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 713us/step - loss: 1.4141 - acc: 0.3813 - val_loss: 1.2498 - val_acc: 0.4107\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 1.3738 - acc: 0.3806 - val_loss: 1.2426 - val_acc: 0.4167\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 1.4073 - acc: 0.3776 - val_loss: 1.2269 - val_acc: 0.4196\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 1.3505 - acc: 0.3843 - val_loss: 1.2091 - val_acc: 0.4256\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 1.3413 - acc: 0.3881 - val_loss: 1.1961 - val_acc: 0.4405\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 1.2990 - acc: 0.3978 - val_loss: 1.1859 - val_acc: 0.4821\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 1.3040 - acc: 0.4261 - val_loss: 1.1797 - val_acc: 0.5268\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 1.2726 - acc: 0.4142 - val_loss: 1.1752 - val_acc: 0.5327\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.2740 - acc: 0.4328 - val_loss: 1.1702 - val_acc: 0.5060\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 708us/step - loss: 1.2790 - acc: 0.4246 - val_loss: 1.1617 - val_acc: 0.4970\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 1.2634 - acc: 0.4216 - val_loss: 1.1522 - val_acc: 0.4851\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 1.2335 - acc: 0.4321 - val_loss: 1.1418 - val_acc: 0.4702\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 1.2091 - acc: 0.4716 - val_loss: 1.1300 - val_acc: 0.4792\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 717us/step - loss: 1.1781 - acc: 0.4687 - val_loss: 1.1197 - val_acc: 0.4881\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 1.1853 - acc: 0.4694 - val_loss: 1.1107 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 1.2037 - acc: 0.4597 - val_loss: 1.1031 - val_acc: 0.5179\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 1.1777 - acc: 0.4731 - val_loss: 1.0966 - val_acc: 0.5268\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 1.1186 - acc: 0.4948 - val_loss: 1.0904 - val_acc: 0.5238\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 1.0904 - acc: 0.5037 - val_loss: 1.0841 - val_acc: 0.5238\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 735us/step - loss: 1.0963 - acc: 0.5075 - val_loss: 1.0803 - val_acc: 0.5149\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 1.0773 - acc: 0.5291 - val_loss: 1.0770 - val_acc: 0.4970\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 717us/step - loss: 1.0772 - acc: 0.5254 - val_loss: 1.0729 - val_acc: 0.4881\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 1.0721 - acc: 0.5343 - val_loss: 1.0684 - val_acc: 0.4851\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 1.0372 - acc: 0.5455 - val_loss: 1.0614 - val_acc: 0.4911\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 1.0823 - acc: 0.5276 - val_loss: 1.0517 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 717us/step - loss: 1.0631 - acc: 0.5187 - val_loss: 1.0449 - val_acc: 0.4970\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 732us/step - loss: 1.0158 - acc: 0.5694 - val_loss: 1.0406 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 715us/step - loss: 0.9897 - acc: 0.5694 - val_loss: 1.0356 - val_acc: 0.5089\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.9587 - acc: 0.5694 - val_loss: 1.0301 - val_acc: 0.5089\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 1s 713us/step - loss: 0.9556 - acc: 0.5873 - val_loss: 1.0207 - val_acc: 0.5149\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 1s 715us/step - loss: 0.9388 - acc: 0.5933 - val_loss: 1.0077 - val_acc: 0.5357\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 1s 717us/step - loss: 0.8875 - acc: 0.6306 - val_loss: 0.9970 - val_acc: 0.5476\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.8681 - acc: 0.6284 - val_loss: 0.9902 - val_acc: 0.5744\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.8494 - acc: 0.6269 - val_loss: 0.9873 - val_acc: 0.6190\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 1s 717us/step - loss: 0.8529 - acc: 0.6358 - val_loss: 0.9880 - val_acc: 0.5744\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.8177 - acc: 0.6597 - val_loss: 0.9851 - val_acc: 0.5714\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.8159 - acc: 0.6567 - val_loss: 0.9758 - val_acc: 0.5863\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.7213 - acc: 0.6873 - val_loss: 0.9659 - val_acc: 0.6012\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 0.7353 - acc: 0.6881 - val_loss: 0.9559 - val_acc: 0.6220\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 0.7271 - acc: 0.6993 - val_loss: 0.9495 - val_acc: 0.6012\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 1s 738us/step - loss: 0.6950 - acc: 0.7030 - val_loss: 0.9442 - val_acc: 0.5982\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 0.7127 - acc: 0.7164 - val_loss: 0.9427 - val_acc: 0.6280\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 1s 708us/step - loss: 0.6673 - acc: 0.7261 - val_loss: 0.9508 - val_acc: 0.5863\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.6216 - acc: 0.7470 - val_loss: 0.9635 - val_acc: 0.5685\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 1s 721us/step - loss: 0.6269 - acc: 0.7388 - val_loss: 0.9780 - val_acc: 0.5387\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 0.5974 - acc: 0.7530 - val_loss: 0.9923 - val_acc: 0.5208\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 1s 717us/step - loss: 0.5932 - acc: 0.7433 - val_loss: 0.9988 - val_acc: 0.5238\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 1s 724us/step - loss: 0.5802 - acc: 0.7739 - val_loss: 0.9916 - val_acc: 0.5298\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.5309 - acc: 0.7709 - val_loss: 0.9746 - val_acc: 0.5476\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 1s 727us/step - loss: 0.5334 - acc: 0.7754 - val_loss: 0.9629 - val_acc: 0.5714\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.5350 - acc: 0.8045 - val_loss: 0.9519 - val_acc: 0.5804\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 1s 712us/step - loss: 0.4747 - acc: 0.8060 - val_loss: 0.9410 - val_acc: 0.5952\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.4287 - acc: 0.8269 - val_loss: 0.9351 - val_acc: 0.6042\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.4500 - acc: 0.8336 - val_loss: 0.9271 - val_acc: 0.6190\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.4511 - acc: 0.8276 - val_loss: 0.9221 - val_acc: 0.6250\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 1s 709us/step - loss: 0.4464 - acc: 0.8269 - val_loss: 0.9274 - val_acc: 0.6071\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 1s 735us/step - loss: 0.4028 - acc: 0.8351 - val_loss: 0.9322 - val_acc: 0.6042\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.4044 - acc: 0.8500 - val_loss: 0.9311 - val_acc: 0.6012\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.3536 - acc: 0.8642 - val_loss: 0.9257 - val_acc: 0.6161\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 0.3927 - acc: 0.8530 - val_loss: 0.9189 - val_acc: 0.6280\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.3710 - acc: 0.8634 - val_loss: 0.9251 - val_acc: 0.6101\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 1s 734us/step - loss: 0.3857 - acc: 0.8552 - val_loss: 0.9425 - val_acc: 0.5923\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 0.3257 - acc: 0.8716 - val_loss: 0.9600 - val_acc: 0.5744\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.3103 - acc: 0.8806 - val_loss: 0.9684 - val_acc: 0.5714\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 1s 742us/step - loss: 0.3075 - acc: 0.8799 - val_loss: 0.9550 - val_acc: 0.5893\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 0.3317 - acc: 0.8739 - val_loss: 0.9392 - val_acc: 0.5982\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.3400 - acc: 0.8881 - val_loss: 0.9329 - val_acc: 0.6131\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 1s 716us/step - loss: 0.3103 - acc: 0.8754 - val_loss: 0.9227 - val_acc: 0.6339\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.2954 - acc: 0.8866 - val_loss: 0.9118 - val_acc: 0.6429\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 1s 729us/step - loss: 0.3161 - acc: 0.8918 - val_loss: 0.9101 - val_acc: 0.6458\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.2955 - acc: 0.9007 - val_loss: 0.9116 - val_acc: 0.6458\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 1s 714us/step - loss: 0.2728 - acc: 0.9015 - val_loss: 0.9074 - val_acc: 0.6458\n",
      "Epoch 83/100\n",
      "1340/1340 [==============================] - 1s 723us/step - loss: 0.2670 - acc: 0.9030 - val_loss: 0.9001 - val_acc: 0.6458\n",
      "Epoch 84/100\n",
      "1340/1340 [==============================] - 1s 715us/step - loss: 0.2627 - acc: 0.9082 - val_loss: 0.9004 - val_acc: 0.6607\n",
      "Epoch 85/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.2481 - acc: 0.9097 - val_loss: 0.9103 - val_acc: 0.6429\n",
      "Epoch 86/100\n",
      "1340/1340 [==============================] - 1s 718us/step - loss: 0.2570 - acc: 0.9015 - val_loss: 0.9239 - val_acc: 0.6220\n",
      "Epoch 87/100\n",
      "1340/1340 [==============================] - 1s 722us/step - loss: 0.2297 - acc: 0.9164 - val_loss: 0.9277 - val_acc: 0.6131\n",
      "Epoch 88/100\n",
      "1340/1340 [==============================] - 1s 736us/step - loss: 0.2206 - acc: 0.9231 - val_loss: 0.9307 - val_acc: 0.6042\n",
      "Epoch 89/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.2197 - acc: 0.9187 - val_loss: 0.9307 - val_acc: 0.6161\n",
      "Epoch 90/100\n",
      "1340/1340 [==============================] - 1s 739us/step - loss: 0.2054 - acc: 0.9336 - val_loss: 0.9303 - val_acc: 0.6190\n",
      "Epoch 91/100\n",
      "1340/1340 [==============================] - 1s 710us/step - loss: 0.2346 - acc: 0.9201 - val_loss: 0.9336 - val_acc: 0.6190\n",
      "Epoch 92/100\n",
      "1340/1340 [==============================] - 1s 720us/step - loss: 0.1875 - acc: 0.9313 - val_loss: 0.9379 - val_acc: 0.6012\n",
      "Epoch 93/100\n",
      "1340/1340 [==============================] - 1s 731us/step - loss: 0.2092 - acc: 0.9306 - val_loss: 0.9346 - val_acc: 0.6042\n",
      "Epoch 94/100\n",
      "1340/1340 [==============================] - 1s 738us/step - loss: 0.2226 - acc: 0.9201 - val_loss: 0.9234 - val_acc: 0.6190\n",
      "Epoch 95/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 0.2068 - acc: 0.9276 - val_loss: 0.9226 - val_acc: 0.6250\n",
      "Epoch 96/100\n",
      "1340/1340 [==============================] - 1s 719us/step - loss: 0.1816 - acc: 0.9313 - val_loss: 0.9171 - val_acc: 0.6310\n",
      "Epoch 97/100\n",
      "1340/1340 [==============================] - 1s 750us/step - loss: 0.1858 - acc: 0.9321 - val_loss: 0.9036 - val_acc: 0.6458\n",
      "Epoch 98/100\n",
      "1340/1340 [==============================] - 1s 728us/step - loss: 0.1965 - acc: 0.9306 - val_loss: 0.8902 - val_acc: 0.6637\n",
      "Epoch 99/100\n",
      "1340/1340 [==============================] - 1s 725us/step - loss: 0.2075 - acc: 0.9306 - val_loss: 0.8750 - val_acc: 0.6696\n",
      "Epoch 100/100\n",
      "1340/1340 [==============================] - 1s 715us/step - loss: 0.1977 - acc: 0.9343 - val_loss: 0.8557 - val_acc: 0.6905\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD65_pos.h5', include_optimizer=False)\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD35_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 5ms/step - loss: 2.0533 - acc: 0.3351 - val_loss: 1.2986 - val_acc: 0.4362\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 1.8480 - acc: 0.3029 - val_loss: 1.2835 - val_acc: 0.4362\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 1.8657 - acc: 0.2895 - val_loss: 1.3194 - val_acc: 0.4574\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 203us/step - loss: 1.9364 - acc: 0.3003 - val_loss: 1.3557 - val_acc: 0.4574\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 219us/step - loss: 1.6219 - acc: 0.3512 - val_loss: 1.3658 - val_acc: 0.4468\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 1.6639 - acc: 0.3834 - val_loss: 1.3645 - val_acc: 0.4574\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 1.7337 - acc: 0.3780 - val_loss: 1.3318 - val_acc: 0.4894\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 221us/step - loss: 1.6004 - acc: 0.3995 - val_loss: 1.2851 - val_acc: 0.4894\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 207us/step - loss: 1.6495 - acc: 0.3995 - val_loss: 1.2404 - val_acc: 0.4894\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 212us/step - loss: 1.5223 - acc: 0.3753 - val_loss: 1.1909 - val_acc: 0.5106\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 1.4015 - acc: 0.4450 - val_loss: 1.1336 - val_acc: 0.5319\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 1.3890 - acc: 0.4209 - val_loss: 1.0891 - val_acc: 0.5319\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 1.4892 - acc: 0.3834 - val_loss: 1.0532 - val_acc: 0.5426\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 213us/step - loss: 1.2998 - acc: 0.4343 - val_loss: 1.0268 - val_acc: 0.5638\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 1.4375 - acc: 0.4182 - val_loss: 1.0071 - val_acc: 0.5745\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 1.3077 - acc: 0.4424 - val_loss: 0.9948 - val_acc: 0.5745\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 1.2504 - acc: 0.5308 - val_loss: 0.9805 - val_acc: 0.5745\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 1.1683 - acc: 0.4692 - val_loss: 0.9701 - val_acc: 0.6064\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 210us/step - loss: 1.2321 - acc: 0.4853 - val_loss: 0.9697 - val_acc: 0.5851\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 210us/step - loss: 1.2445 - acc: 0.4853 - val_loss: 0.9626 - val_acc: 0.5851\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 219us/step - loss: 1.1943 - acc: 0.4772 - val_loss: 0.9618 - val_acc: 0.5745\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 216us/step - loss: 1.1382 - acc: 0.4960 - val_loss: 0.9573 - val_acc: 0.5851\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 1.0770 - acc: 0.5228 - val_loss: 0.9574 - val_acc: 0.6170\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 210us/step - loss: 1.0448 - acc: 0.5362 - val_loss: 0.9551 - val_acc: 0.6277\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 208us/step - loss: 1.0523 - acc: 0.5067 - val_loss: 0.9554 - val_acc: 0.6170\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 223us/step - loss: 1.0941 - acc: 0.5550 - val_loss: 0.9528 - val_acc: 0.6170\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 223us/step - loss: 0.9955 - acc: 0.5684 - val_loss: 0.9481 - val_acc: 0.6064\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 205us/step - loss: 1.0009 - acc: 0.5657 - val_loss: 0.9453 - val_acc: 0.6064\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 208us/step - loss: 1.0589 - acc: 0.5228 - val_loss: 0.9369 - val_acc: 0.6277\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 210us/step - loss: 0.9969 - acc: 0.5845 - val_loss: 0.9228 - val_acc: 0.6277\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 0.9509 - acc: 0.5791 - val_loss: 0.9089 - val_acc: 0.6383\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 210us/step - loss: 0.9091 - acc: 0.5925 - val_loss: 0.8884 - val_acc: 0.6383\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 224us/step - loss: 0.9004 - acc: 0.5925 - val_loss: 0.8695 - val_acc: 0.6383\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 212us/step - loss: 0.9232 - acc: 0.6086 - val_loss: 0.8502 - val_acc: 0.6489\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 213us/step - loss: 0.9127 - acc: 0.6059 - val_loss: 0.8347 - val_acc: 0.6489\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 215us/step - loss: 0.8641 - acc: 0.6166 - val_loss: 0.8199 - val_acc: 0.6489\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 227us/step - loss: 0.9484 - acc: 0.5791 - val_loss: 0.8129 - val_acc: 0.6489\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 0.8415 - acc: 0.6649 - val_loss: 0.8070 - val_acc: 0.6277\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 215us/step - loss: 0.8249 - acc: 0.6193 - val_loss: 0.8054 - val_acc: 0.6277\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 216us/step - loss: 0.8353 - acc: 0.6488 - val_loss: 0.8061 - val_acc: 0.6277\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 218us/step - loss: 0.8175 - acc: 0.6622 - val_loss: 0.8069 - val_acc: 0.6277\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 215us/step - loss: 0.7701 - acc: 0.6729 - val_loss: 0.8078 - val_acc: 0.6277\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 204us/step - loss: 0.8023 - acc: 0.6649 - val_loss: 0.8071 - val_acc: 0.6277\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 207us/step - loss: 0.7734 - acc: 0.6676 - val_loss: 0.8132 - val_acc: 0.6277\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 205us/step - loss: 0.7402 - acc: 0.6836 - val_loss: 0.8186 - val_acc: 0.6383\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 222us/step - loss: 0.7303 - acc: 0.6890 - val_loss: 0.8239 - val_acc: 0.6383\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 217us/step - loss: 0.6835 - acc: 0.7239 - val_loss: 0.8254 - val_acc: 0.6383\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 233us/step - loss: 0.6613 - acc: 0.7212 - val_loss: 0.8319 - val_acc: 0.6383\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 218us/step - loss: 0.7307 - acc: 0.6971 - val_loss: 0.8374 - val_acc: 0.6489\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 201us/step - loss: 0.7214 - acc: 0.6971 - val_loss: 0.8447 - val_acc: 0.6383\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 0.6976 - acc: 0.7024 - val_loss: 0.8517 - val_acc: 0.6383\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 0.6444 - acc: 0.7265 - val_loss: 0.8622 - val_acc: 0.6383\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 0.7347 - acc: 0.6997 - val_loss: 0.8750 - val_acc: 0.6383\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 0.6237 - acc: 0.7426 - val_loss: 0.8895 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 0.6752 - acc: 0.7212 - val_loss: 0.9075 - val_acc: 0.6383\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 258us/step - loss: 0.6590 - acc: 0.7319 - val_loss: 0.9217 - val_acc: 0.6383\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 213us/step - loss: 0.6771 - acc: 0.7239 - val_loss: 0.9269 - val_acc: 0.6383\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 222us/step - loss: 0.6016 - acc: 0.7560 - val_loss: 0.9304 - val_acc: 0.6596\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 209us/step - loss: 0.6096 - acc: 0.7534 - val_loss: 0.9388 - val_acc: 0.6596\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD35_neg.h5', include_optimizer=False)\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD45_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 6ms/step - loss: 2.0206 - acc: 0.2869 - val_loss: 1.3158 - val_acc: 0.4362\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 309us/step - loss: 1.8925 - acc: 0.3056 - val_loss: 1.2813 - val_acc: 0.4468\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 285us/step - loss: 1.8854 - acc: 0.2949 - val_loss: 1.3499 - val_acc: 0.4362\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 293us/step - loss: 1.7426 - acc: 0.3566 - val_loss: 1.3973 - val_acc: 0.4574\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 288us/step - loss: 1.6474 - acc: 0.3727 - val_loss: 1.4106 - val_acc: 0.4574\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 301us/step - loss: 1.5675 - acc: 0.3834 - val_loss: 1.3840 - val_acc: 0.4574\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 282us/step - loss: 1.6529 - acc: 0.3646 - val_loss: 1.3524 - val_acc: 0.4574\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 284us/step - loss: 1.5853 - acc: 0.4209 - val_loss: 1.3101 - val_acc: 0.4681\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 304us/step - loss: 1.6059 - acc: 0.3458 - val_loss: 1.2548 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 297us/step - loss: 1.6598 - acc: 0.3566 - val_loss: 1.2045 - val_acc: 0.5319\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 291us/step - loss: 1.4284 - acc: 0.4129 - val_loss: 1.1569 - val_acc: 0.5319\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 305us/step - loss: 1.3824 - acc: 0.4611 - val_loss: 1.1146 - val_acc: 0.5426\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 286us/step - loss: 1.3966 - acc: 0.4397 - val_loss: 1.0770 - val_acc: 0.5532\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 297us/step - loss: 1.3077 - acc: 0.4477 - val_loss: 1.0471 - val_acc: 0.5745\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 290us/step - loss: 1.4486 - acc: 0.4048 - val_loss: 1.0210 - val_acc: 0.5745\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 298us/step - loss: 1.3181 - acc: 0.4611 - val_loss: 1.0034 - val_acc: 0.5851\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 295us/step - loss: 1.2680 - acc: 0.4853 - val_loss: 0.9896 - val_acc: 0.5851\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 301us/step - loss: 1.2530 - acc: 0.4638 - val_loss: 0.9789 - val_acc: 0.5851\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 284us/step - loss: 1.2659 - acc: 0.4450 - val_loss: 0.9712 - val_acc: 0.5851\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 280us/step - loss: 1.1785 - acc: 0.5174 - val_loss: 0.9675 - val_acc: 0.5851\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 288us/step - loss: 1.1161 - acc: 0.5496 - val_loss: 0.9615 - val_acc: 0.5851\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 295us/step - loss: 1.0871 - acc: 0.5255 - val_loss: 0.9578 - val_acc: 0.5851\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 324us/step - loss: 1.0893 - acc: 0.5228 - val_loss: 0.9565 - val_acc: 0.5851\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 284us/step - loss: 1.0353 - acc: 0.5684 - val_loss: 0.9523 - val_acc: 0.5851\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 286us/step - loss: 1.0416 - acc: 0.5603 - val_loss: 0.9521 - val_acc: 0.5851\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 292us/step - loss: 1.0382 - acc: 0.5523 - val_loss: 0.9489 - val_acc: 0.5851\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 300us/step - loss: 0.9786 - acc: 0.5684 - val_loss: 0.9414 - val_acc: 0.5851\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 282us/step - loss: 1.0256 - acc: 0.5791 - val_loss: 0.9332 - val_acc: 0.5851\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 302us/step - loss: 0.9617 - acc: 0.5684 - val_loss: 0.9256 - val_acc: 0.5957\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 297us/step - loss: 1.0550 - acc: 0.5710 - val_loss: 0.9156 - val_acc: 0.5957\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 274us/step - loss: 0.9685 - acc: 0.5684 - val_loss: 0.9075 - val_acc: 0.6170\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 272us/step - loss: 0.9786 - acc: 0.5737 - val_loss: 0.9030 - val_acc: 0.6277\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 289us/step - loss: 1.0151 - acc: 0.5845 - val_loss: 0.8968 - val_acc: 0.6277\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 284us/step - loss: 0.9358 - acc: 0.5657 - val_loss: 0.8931 - val_acc: 0.6277\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 304us/step - loss: 0.8657 - acc: 0.6354 - val_loss: 0.8904 - val_acc: 0.6383\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 266us/step - loss: 0.8248 - acc: 0.6434 - val_loss: 0.8909 - val_acc: 0.6383\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 286us/step - loss: 0.8994 - acc: 0.6139 - val_loss: 0.8905 - val_acc: 0.6489\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 297us/step - loss: 0.8403 - acc: 0.6247 - val_loss: 0.8902 - val_acc: 0.6596\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 294us/step - loss: 0.8595 - acc: 0.6461 - val_loss: 0.8914 - val_acc: 0.6596\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 279us/step - loss: 0.8268 - acc: 0.6354 - val_loss: 0.8919 - val_acc: 0.6383\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 301us/step - loss: 0.8099 - acc: 0.6676 - val_loss: 0.8927 - val_acc: 0.6489\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 284us/step - loss: 0.8000 - acc: 0.6381 - val_loss: 0.8949 - val_acc: 0.6489\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 282us/step - loss: 0.7805 - acc: 0.6676 - val_loss: 0.8969 - val_acc: 0.6489\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 287us/step - loss: 0.8057 - acc: 0.6381 - val_loss: 0.8991 - val_acc: 0.6383\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 304us/step - loss: 0.8285 - acc: 0.6702 - val_loss: 0.9019 - val_acc: 0.6383\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 296us/step - loss: 0.7487 - acc: 0.7131 - val_loss: 0.9040 - val_acc: 0.6489\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 296us/step - loss: 0.6987 - acc: 0.7239 - val_loss: 0.9088 - val_acc: 0.6489\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 283us/step - loss: 0.7540 - acc: 0.6756 - val_loss: 0.9164 - val_acc: 0.6596\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 297us/step - loss: 0.7482 - acc: 0.6944 - val_loss: 0.9224 - val_acc: 0.6596\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 306us/step - loss: 0.7080 - acc: 0.6997 - val_loss: 0.9269 - val_acc: 0.6596\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 294us/step - loss: 0.7094 - acc: 0.6971 - val_loss: 0.9304 - val_acc: 0.6596\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 295us/step - loss: 0.7066 - acc: 0.7131 - val_loss: 0.9361 - val_acc: 0.6489\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 298us/step - loss: 0.7240 - acc: 0.6944 - val_loss: 0.9428 - val_acc: 0.6596\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 276us/step - loss: 0.6715 - acc: 0.7158 - val_loss: 0.9524 - val_acc: 0.6596\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 279us/step - loss: 0.7420 - acc: 0.6863 - val_loss: 0.9635 - val_acc: 0.6596\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 303us/step - loss: 0.6583 - acc: 0.7319 - val_loss: 0.9765 - val_acc: 0.6489\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 297us/step - loss: 0.6959 - acc: 0.7212 - val_loss: 0.9885 - val_acc: 0.6489\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 293us/step - loss: 0.6057 - acc: 0.7373 - val_loss: 1.0022 - val_acc: 0.6489\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD45_neg.h5', include_optimizer=False)\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "with open('../data/HCD65_neg.pickle', mode='rb') as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide target and features\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 6ms/step - loss: 2.0837 - acc: 0.2869 - val_loss: 1.3364 - val_acc: 0.4043\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 407us/step - loss: 1.9090 - acc: 0.2976 - val_loss: 1.2452 - val_acc: 0.4255\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 416us/step - loss: 1.9388 - acc: 0.2976 - val_loss: 1.2644 - val_acc: 0.5106\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 395us/step - loss: 1.8523 - acc: 0.3190 - val_loss: 1.3075 - val_acc: 0.5106\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 1.7209 - acc: 0.3485 - val_loss: 1.3087 - val_acc: 0.5106\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 383us/step - loss: 1.6821 - acc: 0.3512 - val_loss: 1.2787 - val_acc: 0.5106\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 387us/step - loss: 1.6443 - acc: 0.3592 - val_loss: 1.2445 - val_acc: 0.5106\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 1.6083 - acc: 0.4021 - val_loss: 1.2066 - val_acc: 0.5106\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 1.6956 - acc: 0.3458 - val_loss: 1.1669 - val_acc: 0.5106\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 398us/step - loss: 1.5086 - acc: 0.3914 - val_loss: 1.1338 - val_acc: 0.5106\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 406us/step - loss: 1.4918 - acc: 0.3780 - val_loss: 1.1024 - val_acc: 0.5213\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 1.4130 - acc: 0.3968 - val_loss: 1.0747 - val_acc: 0.5532\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 426us/step - loss: 1.4579 - acc: 0.3780 - val_loss: 1.0574 - val_acc: 0.5532\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 384us/step - loss: 1.4227 - acc: 0.4075 - val_loss: 1.0428 - val_acc: 0.5532\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 406us/step - loss: 1.4699 - acc: 0.3995 - val_loss: 1.0312 - val_acc: 0.5532\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 412us/step - loss: 1.3890 - acc: 0.4209 - val_loss: 1.0240 - val_acc: 0.5638\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 401us/step - loss: 1.2604 - acc: 0.4397 - val_loss: 1.0165 - val_acc: 0.5638\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 391us/step - loss: 1.3184 - acc: 0.4316 - val_loss: 1.0099 - val_acc: 0.5532\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 411us/step - loss: 1.3730 - acc: 0.4263 - val_loss: 1.0046 - val_acc: 0.5638\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 410us/step - loss: 1.3128 - acc: 0.4236 - val_loss: 0.9995 - val_acc: 0.5638\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 391us/step - loss: 1.2931 - acc: 0.4584 - val_loss: 0.9944 - val_acc: 0.5638\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 403us/step - loss: 1.2582 - acc: 0.4370 - val_loss: 0.9914 - val_acc: 0.5745\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 386us/step - loss: 1.2114 - acc: 0.4477 - val_loss: 0.9892 - val_acc: 0.5638\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 410us/step - loss: 1.1397 - acc: 0.4987 - val_loss: 0.9908 - val_acc: 0.5638\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 1.1275 - acc: 0.5067 - val_loss: 0.9904 - val_acc: 0.5532\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 399us/step - loss: 1.2170 - acc: 0.4906 - val_loss: 0.9880 - val_acc: 0.5532\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 409us/step - loss: 1.1426 - acc: 0.5094 - val_loss: 0.9840 - val_acc: 0.5532\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 398us/step - loss: 1.1300 - acc: 0.5067 - val_loss: 0.9797 - val_acc: 0.5532\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 397us/step - loss: 1.1030 - acc: 0.5147 - val_loss: 0.9735 - val_acc: 0.5638\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 414us/step - loss: 1.1446 - acc: 0.4960 - val_loss: 0.9684 - val_acc: 0.5638\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 383us/step - loss: 1.1340 - acc: 0.5201 - val_loss: 0.9625 - val_acc: 0.5851\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 1.1004 - acc: 0.5308 - val_loss: 0.9574 - val_acc: 0.5957\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 420us/step - loss: 0.9910 - acc: 0.5603 - val_loss: 0.9536 - val_acc: 0.5957\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 401us/step - loss: 1.0684 - acc: 0.5201 - val_loss: 0.9524 - val_acc: 0.5957\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 396us/step - loss: 1.0925 - acc: 0.5040 - val_loss: 0.9533 - val_acc: 0.5957\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 1.0631 - acc: 0.5523 - val_loss: 0.9551 - val_acc: 0.5957\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 400us/step - loss: 1.0098 - acc: 0.5818 - val_loss: 0.9570 - val_acc: 0.5957\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 1.0388 - acc: 0.5255 - val_loss: 0.9606 - val_acc: 0.5957\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 388us/step - loss: 0.9780 - acc: 0.5684 - val_loss: 0.9675 - val_acc: 0.5957\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 410us/step - loss: 0.9703 - acc: 0.5952 - val_loss: 0.9738 - val_acc: 0.5957\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 400us/step - loss: 0.9574 - acc: 0.6247 - val_loss: 0.9773 - val_acc: 0.5957\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 0.9236 - acc: 0.5979 - val_loss: 0.9773 - val_acc: 0.6064\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 387us/step - loss: 0.9190 - acc: 0.6086 - val_loss: 0.9744 - val_acc: 0.6064\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 411us/step - loss: 0.9711 - acc: 0.5818 - val_loss: 0.9683 - val_acc: 0.6170\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 410us/step - loss: 0.8450 - acc: 0.6354 - val_loss: 0.9613 - val_acc: 0.6170\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 389us/step - loss: 0.9028 - acc: 0.6113 - val_loss: 0.9555 - val_acc: 0.6383\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 0.9090 - acc: 0.6247 - val_loss: 0.9486 - val_acc: 0.6383\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 388us/step - loss: 0.8425 - acc: 0.6515 - val_loss: 0.9434 - val_acc: 0.6489\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 406us/step - loss: 0.8537 - acc: 0.6408 - val_loss: 0.9414 - val_acc: 0.6489\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 0.8736 - acc: 0.6247 - val_loss: 0.9392 - val_acc: 0.6277\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 398us/step - loss: 0.8273 - acc: 0.6622 - val_loss: 0.9386 - val_acc: 0.6277\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 413us/step - loss: 0.8300 - acc: 0.6488 - val_loss: 0.9371 - val_acc: 0.6277\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 407us/step - loss: 0.8151 - acc: 0.6649 - val_loss: 0.9370 - val_acc: 0.6383\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 400us/step - loss: 0.7778 - acc: 0.6568 - val_loss: 0.9364 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 421us/step - loss: 0.7875 - acc: 0.6622 - val_loss: 0.9353 - val_acc: 0.6383\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 388us/step - loss: 0.7729 - acc: 0.6783 - val_loss: 0.9349 - val_acc: 0.6383\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 400us/step - loss: 0.7529 - acc: 0.6890 - val_loss: 0.9328 - val_acc: 0.6383\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 0.7310 - acc: 0.7024 - val_loss: 0.9317 - val_acc: 0.6383\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 401us/step - loss: 0.7578 - acc: 0.6890 - val_loss: 0.9308 - val_acc: 0.6383\n",
      "Epoch 60/100\n",
      "373/373 [==============================] - 0s 403us/step - loss: 0.7462 - acc: 0.6890 - val_loss: 0.9317 - val_acc: 0.6383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 0.7082 - acc: 0.6917 - val_loss: 0.9319 - val_acc: 0.6383\n",
      "Epoch 62/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 0.7825 - acc: 0.6756 - val_loss: 0.9322 - val_acc: 0.6383\n",
      "Epoch 63/100\n",
      "373/373 [==============================] - 0s 407us/step - loss: 0.6933 - acc: 0.6756 - val_loss: 0.9341 - val_acc: 0.6383\n",
      "Epoch 64/100\n",
      "373/373 [==============================] - 0s 396us/step - loss: 0.7223 - acc: 0.7024 - val_loss: 0.9366 - val_acc: 0.6489\n",
      "Epoch 65/100\n",
      "373/373 [==============================] - 0s 397us/step - loss: 0.6697 - acc: 0.7239 - val_loss: 0.9395 - val_acc: 0.6489\n",
      "Epoch 66/100\n",
      "373/373 [==============================] - 0s 411us/step - loss: 0.6740 - acc: 0.7131 - val_loss: 0.9437 - val_acc: 0.6489\n",
      "Epoch 67/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 0.6614 - acc: 0.7265 - val_loss: 0.9486 - val_acc: 0.6596\n",
      "Epoch 68/100\n",
      "373/373 [==============================] - 0s 386us/step - loss: 0.6380 - acc: 0.7346 - val_loss: 0.9525 - val_acc: 0.6596\n",
      "Epoch 69/100\n",
      "373/373 [==============================] - 0s 409us/step - loss: 0.6412 - acc: 0.7480 - val_loss: 0.9568 - val_acc: 0.6702\n",
      "Epoch 70/100\n",
      "373/373 [==============================] - 0s 412us/step - loss: 0.6415 - acc: 0.7319 - val_loss: 0.9630 - val_acc: 0.6596\n",
      "Epoch 71/100\n",
      "373/373 [==============================] - 0s 397us/step - loss: 0.5963 - acc: 0.7426 - val_loss: 0.9731 - val_acc: 0.6596\n",
      "Epoch 72/100\n",
      "373/373 [==============================] - 0s 406us/step - loss: 0.5989 - acc: 0.7587 - val_loss: 0.9843 - val_acc: 0.6596\n",
      "Epoch 73/100\n",
      "373/373 [==============================] - 0s 391us/step - loss: 0.6476 - acc: 0.7185 - val_loss: 0.9948 - val_acc: 0.6489\n",
      "Epoch 74/100\n",
      "373/373 [==============================] - 0s 399us/step - loss: 0.6327 - acc: 0.7399 - val_loss: 1.0043 - val_acc: 0.6596\n",
      "Epoch 75/100\n",
      "373/373 [==============================] - 0s 405us/step - loss: 0.6595 - acc: 0.7399 - val_loss: 1.0101 - val_acc: 0.6596\n",
      "Epoch 76/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 0.6208 - acc: 0.7614 - val_loss: 1.0163 - val_acc: 0.6702\n",
      "Epoch 77/100\n",
      "373/373 [==============================] - 0s 413us/step - loss: 0.5334 - acc: 0.7909 - val_loss: 1.0233 - val_acc: 0.6383\n",
      "Epoch 78/100\n",
      "373/373 [==============================] - 0s 406us/step - loss: 0.5413 - acc: 0.7802 - val_loss: 1.0320 - val_acc: 0.6596\n",
      "Epoch 79/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 0.5660 - acc: 0.7721 - val_loss: 1.0422 - val_acc: 0.6596\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_HCD65_neg.h5', include_optimizer=False)\n",
    "\n",
    "#predict\n",
    "score = model.evaluate(X_test, y_test_for_keras, verbose=0)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "j.append(elapsed_time)\n",
    "\n",
    "f.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [f, j], \n",
    "    index=['Accuracy', 'Time'],\n",
    "    columns = [\n",
    "        'HCD35_Positive','HCD45_Positive','HCD65_Positive',\n",
    "        'HCD35_Negative','HCD45_Negative','HCD65_Negative'\n",
    "    ]\n",
    ").T.to_csv('../result/Keras.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
