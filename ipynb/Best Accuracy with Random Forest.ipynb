{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('../data/feature_importance_pos.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 20.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': [1, 5, 10, None], 'max_features': [1, 'auto', None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [5, 6, 7, 9, 11], 'criterion': ['gini'], 'n_estimators': [1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [1, 5, 10, None],\n",
    "    'max_features': [1, 'auto', None],\n",
    "    'min_samples_leaf': [1, 2, 4,],\n",
    "    'min_samples_split': [5, 6, 7, 9, 11],\n",
    "    'criterion' :['gini'],\n",
    "    'n_estimators': [1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = rf(), \n",
    "    param_grid = param_grid, \n",
    "    cv = 3, \n",
    "    n_jobs = -1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.8065476190476191\n"
     ]
    }
   ],
   "source": [
    "f = grid_search.best_estimator_\n",
    "\n",
    "f.fit(X_train, y_train)\n",
    "\n",
    "print('Train score: {}'.format(f.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(f.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('../data/feature_importance_neg.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': [1, 5, 10, None], 'max_features': [1, 'auto', None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [5, 6, 7, 9, 11], 'criterion': ['gini'], 'n_estimators': [1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [1, 5, 10, None],\n",
    "    'max_features': [1, 'auto', None],\n",
    "    'min_samples_leaf': [1, 2, 4,],\n",
    "    'min_samples_split': [5, 6, 7, 9, 11],\n",
    "    'criterion' :['gini'],\n",
    "    'n_estimators': [1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = rf(), \n",
    "    param_grid = param_grid, \n",
    "    cv = 3, \n",
    "    n_jobs = -1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8471849865951743\n",
      "Test score: 0.6702127659574468\n"
     ]
    }
   ],
   "source": [
    "f = grid_search.best_estimator_\n",
    "\n",
    "f.fit(X_train, y_train)\n",
    "\n",
    "print('Train score: {}'.format(f.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(f.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
