{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA, KernelPCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "with open('../../data/HCD35_pos.pickle', mode='rb') as fp:\n",
    "    df_3 = pickle.load(fp)\n",
    "    \n",
    "with open('../../data/HCD45_pos.pickle', mode='rb') as fp:\n",
    "    df_4 = pickle.load(fp)\n",
    "\n",
    "with open('../../data/HCD65_pos.pickle', mode='rb') as fp:\n",
    "    df_6 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1676, 39604)\n",
      "(1676, 45702)\n",
      "(1676, 45286)\n"
     ]
    }
   ],
   "source": [
    "print(df_3.shape)\n",
    "print(df_4.shape)\n",
    "print(df_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just data add to list\n",
    "features = [\n",
    "    df_3.drop('Subclass', axis=1),\n",
    "    df_4.drop('Subclass', axis=1),\n",
    "    df_6.drop('Subclass', axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tSVD: 2.81396222114563\n",
      "PCA: 3.8213000297546387\n",
      "ICA: 5.331389427185059\n",
      "GRP: 0.25925326347351074\n",
      "SRP: 0.07521915435791016\n",
      "KPCA: 1.0970468521118164\n",
      "TSNE: 348.7109673023224\n",
      "NMF: 11.610002279281616\n"
     ]
    }
   ],
   "source": [
    "t = pd.DataFrame()\n",
    "n = [] \n",
    "for i in features:\n",
    "    n_comp = 5\n",
    "    \n",
    "    # tSVD\n",
    "    start = time.time()\n",
    "    tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "    tsvd_results = tsvd.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('tSVD: '+str(elapsed_time))\n",
    "    n.append(['tSVD', elapsed_time])\n",
    "    \n",
    "    # PCA\n",
    "    start = time.time()\n",
    "    pca = PCA(n_components=n_comp, random_state=420)\n",
    "    pca_results = pca.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('PCA: '+str(elapsed_time))\n",
    "    n.append(['PCA', elapsed_time])\n",
    "    \n",
    "    # ICA\n",
    "    start = time.time()\n",
    "    ica = FastICA(n_components=n_comp, random_state=420)\n",
    "    ica_results = ica.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('ICA: '+str(elapsed_time))\n",
    "    n.append(['ICA', elapsed_time])\n",
    "    \n",
    "    # GRP\n",
    "    start = time.time()\n",
    "    grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "    grp_results = grp.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('GRP: '+str(elapsed_time))\n",
    "    n.append(['GRP', elapsed_time])\n",
    "    \n",
    "    # SRP\n",
    "    start = time.time()\n",
    "    srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "    srp_results = srp.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('SRP: '+str(elapsed_time))\n",
    "    n.append(['SRP', elapsed_time])\n",
    "    \n",
    "    # KPCA\n",
    "    start = time.time()\n",
    "    kpca = KernelPCA(n_components=n_comp, random_state=420)\n",
    "    kpca_results = kpca.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('KPCA: '+str(elapsed_time))\n",
    "    n.append(['KPCA', elapsed_time])\n",
    "    \n",
    "    # TSNE\n",
    "    start = time.time()\n",
    "    tsne = TSNE(n_components=3, random_state=420) # ValueError: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.\n",
    "    tsne_results = tsne.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('TSNE: '+str(elapsed_time))\n",
    "    n.append(['TSNE', elapsed_time])\n",
    "    \n",
    "    # NMF\n",
    "    start = time.time()\n",
    "    nmf = NMF(n_components=n_comp, random_state=420)\n",
    "    nmf_results = nmf.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('NMF: '+str(elapsed_time))\n",
    "    n.append(['NMF', elapsed_time])\n",
    "    \n",
    "    # RFAA (Recursive feature aggromeration algorithm)\n",
    "    start = time.time()\n",
    "    fag = FeatureAgglomeration(n_clusters=n_comp)\n",
    "    fag_results = fag.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('RFAA: '+str(elapsed_time))\n",
    "    print(': '+str(elapsed_time))\n",
    "    n.append(['RFAA', elapsed_time])\n",
    "    \n",
    "    # merge each data \n",
    "    t = pd.concat([\n",
    "        t, \n",
    "        pd.DataFrame(tsvd_results),\n",
    "        pd.DataFrame(pca_results),\n",
    "        pd.DataFrame(ica_results),\n",
    "        pd.DataFrame(grp_results),\n",
    "        pd.DataFrame(srp_results),\n",
    "        pd.DataFrame(kpca_results),\n",
    "        pd.DataFrame(tsne_results),\n",
    "        pd.DataFrame(nmf_results),\n",
    "        pd.DataFrame(fag_results),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = [\n",
    "    'tSVD', 'PCA', 'ICA','GRP',\n",
    "    'SRP', 'KPCA'\n",
    "]\n",
    "\n",
    "# make column's name\n",
    "v = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in f:\n",
    "        for l in range(n_comp):\n",
    "            v.append(i+'_'+str(l)+'_'+str(m))\n",
    "\n",
    "p=['NMF', 'FAG']\n",
    "q = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in p:\n",
    "        for l in range(n_comp):\n",
    "            q.append(i+'_'+str(l)+'_'+str(m))\n",
    "\n",
    "p=['TSNE']\n",
    "tsne = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in p:\n",
    "        for l in range(3):\n",
    "            tsne.append(i+'_'+str(l)+'_'+str(m))\n",
    "    \n",
    "    \n",
    "t.columns = v+ tsne +q\n",
    "\n",
    "# to csv\n",
    "f = pd.concat([ df_3.Subclass, t], axis=1)\n",
    "f.to_csv('../../data/decomp_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# f=f.drop(['UMAP_0_3', 'UMAP_0_4', 'UMAP_0_6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = f.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = f.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rf()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### X Num \n",
    "\n",
    "g = {\n",
    "    'n_comp':[1, 3, 5, 10, 20, 50, 100, 500,1000],\n",
    "    'Accuracy':[\n",
    "        0.7023809523809523, 0.7083333333333334, 0.7232142857142857, 0.7113095238095238, \n",
    "        0.7113095238095238, 0.6904761904761905, 0.6934523809523809, 0.6488095238095238, 0.6101190476190477\n",
    "    ]\n",
    "}\n",
    "# n_comp 1 0.7023809523809523\n",
    "# n_comp 3 0.7083333333333334\n",
    "# n_comp 5 0.7232142857142857\n",
    "# n_comp 10 0.7113095238095238\n",
    "# n_comp 20 0.7113095238095238\n",
    "# n_comp 50 0.6904761904761905\n",
    "# n_comp 100 0.6934523809523809\n",
    "# n_comp 500 0.6488095238095238\n",
    "# n_comp 1000 0.6101190476190477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/HCD35_neg.pickle', mode='rb') as fp:\n",
    "    df_3 = pickle.load(fp)\n",
    "    \n",
    "with open('../../data/HCD45_neg.pickle', mode='rb') as fp:\n",
    "    df_4 = pickle.load(fp)\n",
    "\n",
    "with open('../../data/HCD65_neg.pickle', mode='rb') as fp:\n",
    "    df_6 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3.shape)\n",
    "print(df_4.shape)\n",
    "print(df_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    df_3.drop('Subclass', axis=1),\n",
    "    df_4.drop('Subclass', axis=1),\n",
    "    df_6.drop('Subclass', axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = pd.DataFrame()\n",
    "n = [] \n",
    "for i in features:\n",
    "    n_comp = 5\n",
    "    \n",
    "    # tSVD\n",
    "    start = time.time()\n",
    "    tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "    tsvd_results = tsvd.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('tSVD: '+str(elapsed_time))\n",
    "    n.append(['tSVD', elapsed_time])\n",
    "    \n",
    "    # PCA\n",
    "    start = time.time()\n",
    "    pca = PCA(n_components=n_comp, random_state=420)\n",
    "    pca_results = pca.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('PCA: '+str(elapsed_time))\n",
    "    n.append(['PCA', elapsed_time])\n",
    "    \n",
    "    # ICA\n",
    "    start = time.time()\n",
    "    ica = FastICA(n_components=n_comp, random_state=420)\n",
    "    ica_results = ica.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('ICA: '+str(elapsed_time))\n",
    "    n.append(['ICA', elapsed_time])\n",
    "    \n",
    "    # GRP\n",
    "    start = time.time()\n",
    "    grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "    grp_results = grp.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('GRP: '+str(elapsed_time))\n",
    "    n.append(['GRP', elapsed_time])\n",
    "    \n",
    "    # SRP\n",
    "    start = time.time()\n",
    "    srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "    srp_results = srp.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('SRP: '+str(elapsed_time))\n",
    "    n.append(['SRP', elapsed_time])\n",
    "    \n",
    "    # KPCA\n",
    "    start = time.time()\n",
    "    kpca = KernelPCA(n_components=n_comp, random_state=420)\n",
    "    kpca_results = kpca.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('KPCA: '+str(elapsed_time))\n",
    "    n.append(['KPCA', elapsed_time])\n",
    "    \n",
    "    # TSNE\n",
    "    start = time.time()\n",
    "    tsne = TSNE(n_components=3, random_state=420) # ValueError: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.\n",
    "    tsne_results = tsne.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('TSNE: '+str(elapsed_time))\n",
    "    n.append(['TSNE', elapsed_time])\n",
    "    \n",
    "    # NMF\n",
    "    start = time.time()\n",
    "    nmf = NMF(n_components=n_comp, random_state=420)\n",
    "    nmf_results = nmf.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('NMF: '+str(elapsed_time))\n",
    "    n.append(['NMF', elapsed_time])\n",
    "    \n",
    "    # FAG\n",
    "    start = time.time()\n",
    "    fag = FeatureAgglomeration(n_clusters=n_comp)\n",
    "    fag_results = fag.fit_transform(i)\n",
    "    elapsed_time = time.time() - start\n",
    "    print('FAG: '+str(elapsed_time))\n",
    "    n.append(['FAG', elapsed_time])\n",
    "    \n",
    "    # merge each data \n",
    "    t = pd.concat([\n",
    "        t, \n",
    "        pd.DataFrame(tsvd_results),\n",
    "        pd.DataFrame(pca_results),\n",
    "        pd.DataFrame(ica_results),\n",
    "        pd.DataFrame(grp_results),\n",
    "        pd.DataFrame(srp_results),\n",
    "        pd.DataFrame(kpca_results),\n",
    "        pd.DataFrame(tsne_results),\n",
    "        pd.DataFrame(nmf_results),\n",
    "        pd.DataFrame(fag_results),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [\n",
    "    'tSVD', 'PCA', 'ICA','GRP',\n",
    "    'SRP', 'KPCA'\n",
    "]\n",
    "\n",
    "# make column's name\n",
    "v = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in f:\n",
    "        for l in range(n_comp):\n",
    "            v.append(i+'_'+str(l)+'_'+str(m))\n",
    "\n",
    "p=['NMF', 'FAG']\n",
    "q = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in p:\n",
    "        for l in range(n_comp):\n",
    "            q.append(i+'_'+str(l)+'_'+str(m))\n",
    "\n",
    "p=['TSNE']\n",
    "tsne = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in p:\n",
    "        for l in range(3):\n",
    "            tsne.append(i+'_'+str(l)+'_'+str(m))\n",
    "    \n",
    "    \n",
    "t.columns = v+ tsne +q\n",
    "\n",
    "# to csv\n",
    "f = pd.concat([ df_3.Subclass, t], axis=1)\n",
    "f.to_csv('../../data/decomp_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
