{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(7)\n",
    "rn.seed(7)\n",
    "\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1,\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\", \n",
    "        allow_growth=True,\n",
    "#         per_process_gpu_memory_fraction=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(7)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, GaussianNoise, GaussianDropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from  keras.regularizers import l1, l2\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.concat([\n",
    "    pd.read_csv('../data/feature_selection_positive.csv', index_col=0),\n",
    "    pd.read_csv('../data/decomp_pos.csv', index_col=0).drop('Subclass', axis=1)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.9267 - acc: 0.2463 - val_loss: 1.4126 - val_acc: 0.2946\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 1.7804 - acc: 0.2582 - val_loss: 1.3865 - val_acc: 0.3065\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 1.6781 - acc: 0.2836 - val_loss: 1.4126 - val_acc: 0.3036\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 1.7383 - acc: 0.3045 - val_loss: 1.3942 - val_acc: 0.3274\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 1.6503 - acc: 0.3037 - val_loss: 1.3520 - val_acc: 0.3542\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 1.6012 - acc: 0.3216 - val_loss: 1.3262 - val_acc: 0.4048\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 1.5698 - acc: 0.3127 - val_loss: 1.3165 - val_acc: 0.4048\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 1.5201 - acc: 0.3410 - val_loss: 1.3191 - val_acc: 0.3363\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 1.5072 - acc: 0.3291 - val_loss: 1.3239 - val_acc: 0.3274\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.5179 - acc: 0.3194 - val_loss: 1.3348 - val_acc: 0.3333\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.4898 - acc: 0.3343 - val_loss: 1.3249 - val_acc: 0.3482\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 0s 78us/step - loss: 1.4266 - acc: 0.3672 - val_loss: 1.3214 - val_acc: 0.3482\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 0s 68us/step - loss: 1.4012 - acc: 0.3657 - val_loss: 1.3138 - val_acc: 0.3631\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 1.4294 - acc: 0.3709 - val_loss: 1.3116 - val_acc: 0.3929\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 1.3715 - acc: 0.3687 - val_loss: 1.2995 - val_acc: 0.4970\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 1.3470 - acc: 0.3746 - val_loss: 1.2734 - val_acc: 0.4226\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 1.3550 - acc: 0.3828 - val_loss: 1.2454 - val_acc: 0.4137\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 1.3146 - acc: 0.4097 - val_loss: 1.2352 - val_acc: 0.4077\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 1.2837 - acc: 0.4142 - val_loss: 1.2344 - val_acc: 0.3988\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 1.2449 - acc: 0.4239 - val_loss: 1.2294 - val_acc: 0.4077\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 1.2870 - acc: 0.4209 - val_loss: 1.2237 - val_acc: 0.4167\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 0s 82us/step - loss: 1.2334 - acc: 0.4299 - val_loss: 1.2051 - val_acc: 0.4196\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 1.2727 - acc: 0.4142 - val_loss: 1.1919 - val_acc: 0.4375\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 1.2732 - acc: 0.4209 - val_loss: 1.1799 - val_acc: 0.4524\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 1.2086 - acc: 0.4537 - val_loss: 1.1709 - val_acc: 0.4583\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 1.2210 - acc: 0.4351 - val_loss: 1.1614 - val_acc: 0.4732\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 1.2152 - acc: 0.4537 - val_loss: 1.1489 - val_acc: 0.4613\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 1.1979 - acc: 0.4821 - val_loss: 1.1374 - val_acc: 0.4970\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 1.1687 - acc: 0.4664 - val_loss: 1.1296 - val_acc: 0.4821\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 1.1359 - acc: 0.4866 - val_loss: 1.1194 - val_acc: 0.4702\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.1347 - acc: 0.5037 - val_loss: 1.1073 - val_acc: 0.4702\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 0s 68us/step - loss: 1.1043 - acc: 0.5075 - val_loss: 1.0943 - val_acc: 0.4881\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 1.0396 - acc: 0.5261 - val_loss: 1.0779 - val_acc: 0.5089\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.0554 - acc: 0.5157 - val_loss: 1.0613 - val_acc: 0.4940\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 1.0381 - acc: 0.5493 - val_loss: 1.0497 - val_acc: 0.4821\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.0149 - acc: 0.5284 - val_loss: 1.0392 - val_acc: 0.4821\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 1.0001 - acc: 0.5455 - val_loss: 1.0276 - val_acc: 0.4821\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.9834 - acc: 0.5597 - val_loss: 1.0102 - val_acc: 0.4970\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.9809 - acc: 0.5799 - val_loss: 0.9917 - val_acc: 0.5208\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.9734 - acc: 0.5604 - val_loss: 0.9758 - val_acc: 0.5446\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.9303 - acc: 0.5739 - val_loss: 0.9580 - val_acc: 0.5625\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 0s 78us/step - loss: 0.9129 - acc: 0.6052 - val_loss: 0.9476 - val_acc: 0.5565\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.8839 - acc: 0.5993 - val_loss: 0.9406 - val_acc: 0.5476\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.9002 - acc: 0.6015 - val_loss: 0.9290 - val_acc: 0.5565\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 0.8291 - acc: 0.6231 - val_loss: 0.9192 - val_acc: 0.5774\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.8152 - acc: 0.6388 - val_loss: 0.9130 - val_acc: 0.5952\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.8086 - acc: 0.6425 - val_loss: 0.9180 - val_acc: 0.5804\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.7971 - acc: 0.6507 - val_loss: 0.9346 - val_acc: 0.5536\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.7934 - acc: 0.6612 - val_loss: 0.9341 - val_acc: 0.5655\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.7606 - acc: 0.6716 - val_loss: 0.9199 - val_acc: 0.5863\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.7741 - acc: 0.6530 - val_loss: 0.9148 - val_acc: 0.5923\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.7403 - acc: 0.6701 - val_loss: 0.9029 - val_acc: 0.5774\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.7215 - acc: 0.6978 - val_loss: 0.9037 - val_acc: 0.5714\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.7400 - acc: 0.6754 - val_loss: 0.8929 - val_acc: 0.5774\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 0.6902 - acc: 0.6940 - val_loss: 0.8760 - val_acc: 0.6071\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.7183 - acc: 0.6858 - val_loss: 0.8861 - val_acc: 0.5804\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.6757 - acc: 0.7142 - val_loss: 0.9301 - val_acc: 0.5625\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.6719 - acc: 0.7201 - val_loss: 0.9567 - val_acc: 0.5565\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.6490 - acc: 0.7194 - val_loss: 0.9434 - val_acc: 0.5833\n",
      "Epoch 60/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.6447 - acc: 0.7351 - val_loss: 0.9192 - val_acc: 0.6071\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 0.6436 - acc: 0.7216 - val_loss: 0.9015 - val_acc: 0.6042\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.6219 - acc: 0.7418 - val_loss: 0.9179 - val_acc: 0.6071\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.6558 - acc: 0.7201 - val_loss: 0.9189 - val_acc: 0.6161\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.5769 - acc: 0.7373 - val_loss: 0.8910 - val_acc: 0.6250\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 0.5817 - acc: 0.7522 - val_loss: 0.8823 - val_acc: 0.6280\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.5672 - acc: 0.7515 - val_loss: 0.9129 - val_acc: 0.6220\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.5691 - acc: 0.7522 - val_loss: 0.9403 - val_acc: 0.6161\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.5478 - acc: 0.7784 - val_loss: 0.9301 - val_acc: 0.6101\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.5634 - acc: 0.7731 - val_loss: 0.8759 - val_acc: 0.6220\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.5847 - acc: 0.7657 - val_loss: 0.8473 - val_acc: 0.6399\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 0.5613 - acc: 0.7724 - val_loss: 0.8695 - val_acc: 0.6399\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.5316 - acc: 0.7709 - val_loss: 0.8627 - val_acc: 0.6458\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.5056 - acc: 0.7970 - val_loss: 0.8117 - val_acc: 0.6667\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.5455 - acc: 0.7836 - val_loss: 0.7916 - val_acc: 0.6815\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.5379 - acc: 0.7836 - val_loss: 0.8253 - val_acc: 0.6518\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.5305 - acc: 0.7828 - val_loss: 0.8624 - val_acc: 0.6220\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.5186 - acc: 0.7978 - val_loss: 0.9130 - val_acc: 0.6369\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.4820 - acc: 0.7985 - val_loss: 0.9175 - val_acc: 0.6310\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.5177 - acc: 0.7925 - val_loss: 0.8844 - val_acc: 0.6131\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 0.4837 - acc: 0.8000 - val_loss: 0.9203 - val_acc: 0.6131\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.4527 - acc: 0.8172 - val_loss: 1.0013 - val_acc: 0.6339\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.4627 - acc: 0.8239 - val_loss: 0.9561 - val_acc: 0.6310\n",
      "Epoch 83/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.4852 - acc: 0.8090 - val_loss: 0.8563 - val_acc: 0.6488\n",
      "Epoch 84/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.4609 - acc: 0.8231 - val_loss: 0.8047 - val_acc: 0.6726\n",
      "Epoch 85/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.4391 - acc: 0.8321 - val_loss: 0.8365 - val_acc: 0.6548\n",
      "Epoch 86/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.4403 - acc: 0.8172 - val_loss: 0.9010 - val_acc: 0.6458\n",
      "Epoch 87/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.4157 - acc: 0.8321 - val_loss: 0.9796 - val_acc: 0.6369\n",
      "Epoch 88/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.4008 - acc: 0.8455 - val_loss: 1.0041 - val_acc: 0.6339\n",
      "Epoch 89/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 0.3944 - acc: 0.8604 - val_loss: 0.9523 - val_acc: 0.6518\n",
      "Epoch 90/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.3787 - acc: 0.8619 - val_loss: 0.8884 - val_acc: 0.6548\n",
      "Epoch 91/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.3758 - acc: 0.8358 - val_loss: 0.8732 - val_acc: 0.6786\n",
      "Epoch 92/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 0.3641 - acc: 0.8530 - val_loss: 0.8881 - val_acc: 0.6577\n",
      "Epoch 93/100\n",
      "1340/1340 [==============================] - 0s 68us/step - loss: 0.3594 - acc: 0.8597 - val_loss: 0.9376 - val_acc: 0.6726\n",
      "Epoch 94/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.4014 - acc: 0.8493 - val_loss: 0.9288 - val_acc: 0.6488\n"
     ]
    }
   ],
   "source": [
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_pos_fs+decomp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.concat([\n",
    "    pd.read_csv('../data/feature_selection_negative.csv', index_col=0),\n",
    "    pd.read_csv('../data/decomp_neg.csv', index_col=0).drop('Subclass', axis=1)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = df.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 1s 4ms/step - loss: 2.1786 - acc: 0.2279 - val_loss: 1.3114 - val_acc: 0.4149\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 59us/step - loss: 2.0531 - acc: 0.2547 - val_loss: 1.3457 - val_acc: 0.4574\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 54us/step - loss: 1.8356 - acc: 0.2493 - val_loss: 1.4574 - val_acc: 0.4468\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 45us/step - loss: 1.7167 - acc: 0.3217 - val_loss: 1.5464 - val_acc: 0.4681\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 48us/step - loss: 1.8528 - acc: 0.3324 - val_loss: 1.5606 - val_acc: 0.4681\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 54us/step - loss: 1.6720 - acc: 0.3485 - val_loss: 1.5361 - val_acc: 0.4681\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 60us/step - loss: 1.8475 - acc: 0.3566 - val_loss: 1.4950 - val_acc: 0.4681\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 48us/step - loss: 1.5629 - acc: 0.3995 - val_loss: 1.4411 - val_acc: 0.4681\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 50us/step - loss: 1.7222 - acc: 0.3592 - val_loss: 1.3805 - val_acc: 0.4787\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 53us/step - loss: 1.5434 - acc: 0.3780 - val_loss: 1.3248 - val_acc: 0.5106\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 48us/step - loss: 1.4916 - acc: 0.3914 - val_loss: 1.2791 - val_acc: 0.5532\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 45us/step - loss: 1.5051 - acc: 0.4209 - val_loss: 1.2488 - val_acc: 0.5426\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 45us/step - loss: 1.4704 - acc: 0.3914 - val_loss: 1.2359 - val_acc: 0.5106\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 48us/step - loss: 1.4583 - acc: 0.4129 - val_loss: 1.2276 - val_acc: 0.4894\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 50us/step - loss: 1.4074 - acc: 0.3887 - val_loss: 1.2000 - val_acc: 0.4681\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 44us/step - loss: 1.3536 - acc: 0.3914 - val_loss: 1.1682 - val_acc: 0.4787\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 46us/step - loss: 1.4063 - acc: 0.3700 - val_loss: 1.1365 - val_acc: 0.5106\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 54us/step - loss: 1.3492 - acc: 0.4290 - val_loss: 1.1050 - val_acc: 0.5745\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 61us/step - loss: 1.3608 - acc: 0.3968 - val_loss: 1.0797 - val_acc: 0.5426\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 52us/step - loss: 1.3772 - acc: 0.4075 - val_loss: 1.0488 - val_acc: 0.5532\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 51us/step - loss: 1.2054 - acc: 0.4879 - val_loss: 1.0260 - val_acc: 0.5532\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 1.2940 - acc: 0.4370 - val_loss: 1.0083 - val_acc: 0.5745\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 1.1365 - acc: 0.4718 - val_loss: 0.9947 - val_acc: 0.5638\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 1.2275 - acc: 0.4450 - val_loss: 0.9846 - val_acc: 0.5638\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 50us/step - loss: 1.1894 - acc: 0.4799 - val_loss: 0.9803 - val_acc: 0.5745\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 46us/step - loss: 1.2652 - acc: 0.4558 - val_loss: 0.9759 - val_acc: 0.5638\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 48us/step - loss: 1.1924 - acc: 0.5040 - val_loss: 0.9719 - val_acc: 0.5638\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 47us/step - loss: 1.1090 - acc: 0.5040 - val_loss: 0.9761 - val_acc: 0.5638\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 53us/step - loss: 1.1644 - acc: 0.4638 - val_loss: 0.9792 - val_acc: 0.5638\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 44us/step - loss: 1.1482 - acc: 0.5094 - val_loss: 0.9767 - val_acc: 0.5638\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 44us/step - loss: 1.1308 - acc: 0.5094 - val_loss: 0.9723 - val_acc: 0.5638\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 1.1215 - acc: 0.5362 - val_loss: 0.9684 - val_acc: 0.5638\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 1.0734 - acc: 0.5094 - val_loss: 0.9648 - val_acc: 0.5745\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 56us/step - loss: 1.0307 - acc: 0.5630 - val_loss: 0.9544 - val_acc: 0.5745\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 54us/step - loss: 0.9749 - acc: 0.5523 - val_loss: 0.9460 - val_acc: 0.5745\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 52us/step - loss: 0.9711 - acc: 0.5952 - val_loss: 0.9401 - val_acc: 0.5745\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 48us/step - loss: 0.9913 - acc: 0.5282 - val_loss: 0.9317 - val_acc: 0.5851\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 46us/step - loss: 1.0097 - acc: 0.5389 - val_loss: 0.9250 - val_acc: 0.5851\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 47us/step - loss: 0.9481 - acc: 0.5791 - val_loss: 0.9187 - val_acc: 0.5851\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 50us/step - loss: 0.9260 - acc: 0.5845 - val_loss: 0.9113 - val_acc: 0.5957\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 51us/step - loss: 0.9601 - acc: 0.5630 - val_loss: 0.9007 - val_acc: 0.6170\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 53us/step - loss: 0.9623 - acc: 0.6086 - val_loss: 0.8893 - val_acc: 0.6170\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 47us/step - loss: 0.9524 - acc: 0.5925 - val_loss: 0.8790 - val_acc: 0.6170\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 0.8930 - acc: 0.5845 - val_loss: 0.8715 - val_acc: 0.6170\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 48us/step - loss: 0.8716 - acc: 0.6354 - val_loss: 0.8687 - val_acc: 0.6064\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 54us/step - loss: 0.8513 - acc: 0.6166 - val_loss: 0.8662 - val_acc: 0.6064\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 47us/step - loss: 0.8618 - acc: 0.5898 - val_loss: 0.8678 - val_acc: 0.6064\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 46us/step - loss: 0.7876 - acc: 0.6542 - val_loss: 0.8744 - val_acc: 0.6064\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 56us/step - loss: 0.9162 - acc: 0.6032 - val_loss: 0.8827 - val_acc: 0.6277\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 57us/step - loss: 0.8496 - acc: 0.6542 - val_loss: 0.8888 - val_acc: 0.6277\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 56us/step - loss: 0.7899 - acc: 0.6649 - val_loss: 0.9055 - val_acc: 0.6277\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 52us/step - loss: 0.8525 - acc: 0.6327 - val_loss: 0.9237 - val_acc: 0.6064\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 0s 50us/step - loss: 0.7740 - acc: 0.6542 - val_loss: 0.9433 - val_acc: 0.6170\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 0.7957 - acc: 0.6515 - val_loss: 0.9643 - val_acc: 0.6170\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 53us/step - loss: 0.7368 - acc: 0.6622 - val_loss: 0.9845 - val_acc: 0.6064\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 51us/step - loss: 0.7793 - acc: 0.6810 - val_loss: 0.9915 - val_acc: 0.6064\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 50us/step - loss: 0.8330 - acc: 0.6542 - val_loss: 0.9995 - val_acc: 0.6064\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 50us/step - loss: 0.7511 - acc: 0.6810 - val_loss: 1.0107 - val_acc: 0.6064\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 0.7724 - acc: 0.6756 - val_loss: 1.0100 - val_acc: 0.5957\n",
      "Epoch 60/100\n",
      "373/373 [==============================] - 0s 50us/step - loss: 0.7308 - acc: 0.6863 - val_loss: 1.0025 - val_acc: 0.5957\n",
      "Epoch 61/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 0.6923 - acc: 0.7158 - val_loss: 0.9993 - val_acc: 0.5957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "373/373 [==============================] - 0s 49us/step - loss: 0.6919 - acc: 0.7158 - val_loss: 0.9997 - val_acc: 0.6064\n",
      "Epoch 63/100\n",
      "373/373 [==============================] - 0s 53us/step - loss: 0.6980 - acc: 0.6944 - val_loss: 0.9968 - val_acc: 0.6064\n",
      "Epoch 64/100\n",
      "373/373 [==============================] - 0s 51us/step - loss: 0.6963 - acc: 0.7105 - val_loss: 0.9956 - val_acc: 0.6064\n",
      "Epoch 65/100\n",
      "373/373 [==============================] - 0s 51us/step - loss: 0.7194 - acc: 0.6863 - val_loss: 0.9929 - val_acc: 0.5957\n",
      "Epoch 66/100\n",
      "373/373 [==============================] - 0s 52us/step - loss: 0.6535 - acc: 0.7105 - val_loss: 0.9926 - val_acc: 0.5957\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ce24d5147687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../model/Keras_ng_fs+decomp.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_for_keras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_ng_fs+decomp.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
