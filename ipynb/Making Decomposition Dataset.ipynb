{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA, KernelPCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "with open('../data/HCD35_pos.pickle', mode='rb') as fp:\n",
    "    df_3 = pickle.load(fp)\n",
    "    \n",
    "with open('../data/HCD45_pos.pickle', mode='rb') as fp:\n",
    "    df_4 = pickle.load(fp)\n",
    "\n",
    "with open('../data/HCD65_pos.pickle', mode='rb') as fp:\n",
    "    df_6 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1676, 39604)\n",
      "(1676, 45702)\n",
      "(1676, 45286)\n"
     ]
    }
   ],
   "source": [
    "print(df_3.shape)\n",
    "print(df_4.shape)\n",
    "print(df_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just data add to list\n",
    "features = [\n",
    "    df_3.drop('Subclass', axis=1),\n",
    "    df_4.drop('Subclass', axis=1),\n",
    "    df_6.drop('Subclass', axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame()\n",
    "for i in features:\n",
    "    n_comp = 5\n",
    "\n",
    "    # tSVD\n",
    "    tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "    tsvd_results = tsvd.fit_transform(i)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_comp, random_state=420)\n",
    "    pca_results = pca.fit_transform(i)\n",
    "    \n",
    "    # ICA\n",
    "    ica = FastICA(n_components=n_comp, random_state=420)\n",
    "    ica_results = ica.fit_transform(i)\n",
    "\n",
    "    # GRP\n",
    "    grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "    grp_results = grp.fit_transform(i)\n",
    "\n",
    "    # SRP\n",
    "    srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "    srp_results = srp.fit_transform(i)\n",
    "\n",
    "    # KPCA\n",
    "    kpca = KernelPCA(n_components=n_comp, random_state=420)\n",
    "    kpca_results = kpca.fit_transform(i)\n",
    "    \n",
    "    # TSNE\n",
    "    tsne = TSNE(n_components=3, random_state=420) # ValueError: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.\n",
    "    tsne_results = tsne.fit_transform(i)\n",
    "    \n",
    "    # NMF\n",
    "    nmf = NMF(n_components=n_comp, random_state=420)\n",
    "    nmf_results = nmf.fit_transform(i)\n",
    "\n",
    "    # FAG\n",
    "    fag = FeatureAgglomeration(n_clusters=n_comp)\n",
    "    fag_results = fag.fit_transform(i)\n",
    "    \n",
    "    \n",
    "    # merge each data \n",
    "    t = pd.concat([\n",
    "        t, \n",
    "        pd.DataFrame(tsvd_results),\n",
    "        pd.DataFrame(pca_results),\n",
    "        pd.DataFrame(ica_results),\n",
    "        pd.DataFrame(grp_results),\n",
    "        pd.DataFrame(srp_results),\n",
    "        pd.DataFrame(kpca_results),\n",
    "        pd.DataFrame(tsne_results),\n",
    "        pd.DataFrame(nmf_results),\n",
    "        pd.DataFrame(fag_results),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = [\n",
    "    'tSVD', 'PCA', 'ICA','GRP',\n",
    "    'SRP', 'KPCA'\n",
    "]\n",
    "\n",
    "# make column's name\n",
    "v = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in f:\n",
    "        for l in range(n_comp):\n",
    "            v.append(i+'_'+str(l)+'_'+str(m))\n",
    "\n",
    "p=['NMF', 'FAG']\n",
    "q = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in p:\n",
    "        for l in range(n_comp):\n",
    "            q.append(i+'_'+str(l)+'_'+str(m))\n",
    "\n",
    "p=['TSNE']\n",
    "tsne = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in p:\n",
    "        for l in range(3):\n",
    "            tsne.append(i+'_'+str(l)+'_'+str(m))\n",
    "    \n",
    "    \n",
    "t.columns = v+ tsne +q\n",
    "\n",
    "# to csv\n",
    "f = pd.concat([ df_3.Subclass, t], axis=1)\n",
    "f.to_csv('../data/decomp_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# f=f.drop(['UMAP_0_3', 'UMAP_0_4', 'UMAP_0_6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = f.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "\n",
    "features = f.drop('Subclass', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6101190476190477"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = rf()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### X Num \n",
    "\n",
    "g = {\n",
    "    'n_comp':[1, 3, 5, 10, 20, 50, 100, 500,1000],\n",
    "    'Accuracy':[\n",
    "        0.7023809523809523, 0.7083333333333334, 0.7232142857142857, 0.7113095238095238, \n",
    "        0.7113095238095238, 0.6904761904761905, 0.6934523809523809, 0.6488095238095238, 0.6101190476190477\n",
    "    ]\n",
    "}\n",
    "# n_comp 1 0.7023809523809523\n",
    "# n_comp 3 0.7083333333333334\n",
    "# n_comp 5 0.7232142857142857\n",
    "# n_comp 10 0.7113095238095238\n",
    "# n_comp 20 0.7113095238095238\n",
    "# n_comp 50 0.6904761904761905\n",
    "# n_comp 100 0.6934523809523809\n",
    "# n_comp 500 0.6488095238095238\n",
    "# n_comp 1000 0.6101190476190477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_comp</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.702381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.723214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.711310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.711310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.693452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>0.648810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.610119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_comp  Accuracy\n",
       "0       1  0.702381\n",
       "1       3  0.708333\n",
       "2       5  0.723214\n",
       "3      10  0.711310\n",
       "4      20  0.711310\n",
       "5      50  0.690476\n",
       "6     100  0.693452\n",
       "7     500  0.648810\n",
       "8    1000  0.610119"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/HCD35_neg.pickle', mode='rb') as fp:\n",
    "    df_3 = pickle.load(fp)\n",
    "    \n",
    "with open('../data/HCD45_neg.pickle', mode='rb') as fp:\n",
    "    df_4 = pickle.load(fp)\n",
    "\n",
    "with open('../data/HCD65_neg.pickle', mode='rb') as fp:\n",
    "    df_6 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467, 13781)\n",
      "(467, 18367)\n",
      "(467, 24953)\n"
     ]
    }
   ],
   "source": [
    "print(df_3.shape)\n",
    "print(df_4.shape)\n",
    "print(df_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    df_3.drop('Subclass', axis=1),\n",
    "    df_4.drop('Subclass', axis=1),\n",
    "    df_6.drop('Subclass', axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = pd.DataFrame()\n",
    "for i in features:\n",
    "    n_comp = 5\n",
    "\n",
    "    # tSVD\n",
    "    tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "    tsvd_results = tsvd.fit_transform(i)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_comp, random_state=420)\n",
    "    pca_results = pca.fit_transform(i)\n",
    "    \n",
    "    # ICA\n",
    "    ica = FastICA(n_components=n_comp, random_state=420)\n",
    "    ica_results = ica.fit_transform(i)\n",
    "\n",
    "    # GRP\n",
    "    grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "    grp_results = grp.fit_transform(i)\n",
    "\n",
    "    # SRP\n",
    "    srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "    srp_results = srp.fit_transform(i)\n",
    "\n",
    "    # KPCA\n",
    "    kpca = KernelPCA(n_components=n_comp, random_state=420)\n",
    "    kpca_results = kpca.fit_transform(i)\n",
    "    \n",
    "    # TSNE\n",
    "    tsne = TSNE(n_components=3, random_state=420) # ValueError: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.\n",
    "    tsne_results = tsne.fit_transform(i)\n",
    "    \n",
    "    # NMF\n",
    "    nmf = NMF(n_components=n_comp, random_state=420)\n",
    "    nmf_results = nmf.fit_transform(i)\n",
    "\n",
    "    # FAG\n",
    "    fag = FeatureAgglomeration(n_clusters=n_comp)\n",
    "    fag_results = fag.fit_transform(i)\n",
    "    \n",
    "    \n",
    "    # merge each data \n",
    "    t = pd.concat([\n",
    "        t, \n",
    "        pd.DataFrame(tsvd_results),\n",
    "        pd.DataFrame(pca_results),\n",
    "        pd.DataFrame(ica_results),\n",
    "        pd.DataFrame(grp_results),\n",
    "        pd.DataFrame(srp_results),\n",
    "        pd.DataFrame(kpca_results),\n",
    "        pd.DataFrame(tsne_results),\n",
    "        pd.DataFrame(nmf_results),\n",
    "        pd.DataFrame(fag_results),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [\n",
    "    'tSVD', 'PCA', 'ICA','GRP',\n",
    "    'SRP', 'KPCA'\n",
    "]\n",
    "\n",
    "# make column's name\n",
    "v = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in f:\n",
    "        for l in range(n_comp):\n",
    "            v.append(i+'_'+str(l)+'_'+str(m))\n",
    "\n",
    "p=['NMF', 'FAG']\n",
    "q = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in p:\n",
    "        for l in range(n_comp):\n",
    "            q.append(i+'_'+str(l)+'_'+str(m))\n",
    "\n",
    "p=['TSNE']\n",
    "tsne = []\n",
    "for m in [3, 4, 6]:\n",
    "    for i in p:\n",
    "        for l in range(3):\n",
    "            tsne.append(i+'_'+str(l)+'_'+str(m))\n",
    "    \n",
    "    \n",
    "t.columns = v+ tsne +q\n",
    "\n",
    "# to csv\n",
    "f = pd.concat([ df_3.Subclass, t], axis=1)\n",
    "f.to_csv('../data/decomp_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
