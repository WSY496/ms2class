{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, GaussianNoise, GaussianDropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from  keras.regularizers import l1, l2\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\", \n",
    "        allow_growth=True,\n",
    "#         per_process_gpu_memory_fraction=0.5\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load  data\n",
    "df = pd.read_csv('../data/HCD35_neg_norm.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit\n",
    "clf = rf()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# add result to list \n",
    "o = []\n",
    "o.append(round((clf.score(X_test, y_test))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.30137\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.22335\n",
      "[3]\tvalid_0's multi_logloss: 1.15893\n",
      "[4]\tvalid_0's multi_logloss: 1.09947\n",
      "[5]\tvalid_0's multi_logloss: 1.04987\n",
      "[6]\tvalid_0's multi_logloss: 1.01132\n",
      "[7]\tvalid_0's multi_logloss: 0.977166\n",
      "[8]\tvalid_0's multi_logloss: 0.949006\n",
      "[9]\tvalid_0's multi_logloss: 0.923959\n",
      "[10]\tvalid_0's multi_logloss: 0.902713\n",
      "[11]\tvalid_0's multi_logloss: 0.880888\n",
      "[12]\tvalid_0's multi_logloss: 0.861254\n",
      "[13]\tvalid_0's multi_logloss: 0.840925\n",
      "[14]\tvalid_0's multi_logloss: 0.82072\n",
      "[15]\tvalid_0's multi_logloss: 0.805376\n",
      "[16]\tvalid_0's multi_logloss: 0.788799\n",
      "[17]\tvalid_0's multi_logloss: 0.776449\n",
      "[18]\tvalid_0's multi_logloss: 0.765656\n",
      "[19]\tvalid_0's multi_logloss: 0.754441\n",
      "[20]\tvalid_0's multi_logloss: 0.740786\n",
      "[21]\tvalid_0's multi_logloss: 0.73216\n",
      "[22]\tvalid_0's multi_logloss: 0.725209\n",
      "[23]\tvalid_0's multi_logloss: 0.713766\n",
      "[24]\tvalid_0's multi_logloss: 0.706488\n",
      "[25]\tvalid_0's multi_logloss: 0.702186\n",
      "[26]\tvalid_0's multi_logloss: 0.697348\n",
      "[27]\tvalid_0's multi_logloss: 0.686052\n",
      "[28]\tvalid_0's multi_logloss: 0.682921\n",
      "[29]\tvalid_0's multi_logloss: 0.677781\n",
      "[30]\tvalid_0's multi_logloss: 0.668888\n",
      "[31]\tvalid_0's multi_logloss: 0.662747\n",
      "[32]\tvalid_0's multi_logloss: 0.65682\n",
      "[33]\tvalid_0's multi_logloss: 0.655481\n",
      "[34]\tvalid_0's multi_logloss: 0.652454\n",
      "[35]\tvalid_0's multi_logloss: 0.646255\n",
      "[36]\tvalid_0's multi_logloss: 0.640695\n",
      "[37]\tvalid_0's multi_logloss: 0.634575\n",
      "[38]\tvalid_0's multi_logloss: 0.637614\n",
      "[39]\tvalid_0's multi_logloss: 0.633035\n",
      "[40]\tvalid_0's multi_logloss: 0.628468\n",
      "[41]\tvalid_0's multi_logloss: 0.625704\n",
      "[42]\tvalid_0's multi_logloss: 0.622668\n",
      "[43]\tvalid_0's multi_logloss: 0.621638\n",
      "[44]\tvalid_0's multi_logloss: 0.618509\n",
      "[45]\tvalid_0's multi_logloss: 0.614485\n",
      "[46]\tvalid_0's multi_logloss: 0.613074\n",
      "[47]\tvalid_0's multi_logloss: 0.60635\n",
      "[48]\tvalid_0's multi_logloss: 0.607742\n",
      "[49]\tvalid_0's multi_logloss: 0.609908\n",
      "[50]\tvalid_0's multi_logloss: 0.606699\n",
      "[51]\tvalid_0's multi_logloss: 0.603571\n",
      "[52]\tvalid_0's multi_logloss: 0.602646\n",
      "[53]\tvalid_0's multi_logloss: 0.598641\n",
      "[54]\tvalid_0's multi_logloss: 0.596272\n",
      "[55]\tvalid_0's multi_logloss: 0.595102\n",
      "[56]\tvalid_0's multi_logloss: 0.59335\n",
      "[57]\tvalid_0's multi_logloss: 0.596536\n",
      "[58]\tvalid_0's multi_logloss: 0.59437\n",
      "[59]\tvalid_0's multi_logloss: 0.598683\n",
      "[60]\tvalid_0's multi_logloss: 0.600715\n",
      "[61]\tvalid_0's multi_logloss: 0.600064\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 0.59335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    device = 'gpu'\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "\n",
    "# result append to list\n",
    "o.append(round(gbm.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "params = {}\n",
    "params['device'] = 'gpu'\n",
    "params['gpu_id'] = 1\n",
    "params['updater'] = 'grow_gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "o.append(round(model.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 5ms/step - loss: 2.1360 - acc: 0.2413 - val_loss: 1.4381 - val_acc: 0.3511\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 221us/step - loss: 1.9896 - acc: 0.2708 - val_loss: 1.3772 - val_acc: 0.3617\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 222us/step - loss: 1.9666 - acc: 0.2842 - val_loss: 1.3276 - val_acc: 0.3723\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 213us/step - loss: 1.7529 - acc: 0.3485 - val_loss: 1.2927 - val_acc: 0.4255\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 206us/step - loss: 1.6890 - acc: 0.3137 - val_loss: 1.2828 - val_acc: 0.3617\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 220us/step - loss: 1.6320 - acc: 0.3271 - val_loss: 1.2864 - val_acc: 0.3830\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 204us/step - loss: 1.5200 - acc: 0.3861 - val_loss: 1.2804 - val_acc: 0.4043\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 222us/step - loss: 1.5408 - acc: 0.3566 - val_loss: 1.2614 - val_acc: 0.4468\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 219us/step - loss: 1.5418 - acc: 0.3914 - val_loss: 1.2494 - val_acc: 0.4574\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 215us/step - loss: 1.3872 - acc: 0.4290 - val_loss: 1.2396 - val_acc: 0.4574\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 221us/step - loss: 1.4139 - acc: 0.4611 - val_loss: 1.2258 - val_acc: 0.4894\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 239us/step - loss: 1.3967 - acc: 0.4290 - val_loss: 1.2029 - val_acc: 0.4894\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 1.2980 - acc: 0.4745 - val_loss: 1.1719 - val_acc: 0.5426\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 1.4031 - acc: 0.4745 - val_loss: 1.1401 - val_acc: 0.5851\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 212us/step - loss: 1.1303 - acc: 0.5389 - val_loss: 1.1111 - val_acc: 0.5957\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 233us/step - loss: 1.2114 - acc: 0.5228 - val_loss: 1.0675 - val_acc: 0.5957\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 233us/step - loss: 1.0990 - acc: 0.5764 - val_loss: 1.0138 - val_acc: 0.6064\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 0.9329 - acc: 0.5898 - val_loss: 0.9682 - val_acc: 0.6277\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 212us/step - loss: 0.9471 - acc: 0.6220 - val_loss: 0.9243 - val_acc: 0.6702\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 0.9039 - acc: 0.6354 - val_loss: 0.8897 - val_acc: 0.6702\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 228us/step - loss: 0.9210 - acc: 0.6836 - val_loss: 0.8602 - val_acc: 0.6915\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 0.8552 - acc: 0.7024 - val_loss: 0.8358 - val_acc: 0.6809\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 206us/step - loss: 0.7252 - acc: 0.7507 - val_loss: 0.8177 - val_acc: 0.6809\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.7614 - val_loss: 0.8052 - val_acc: 0.6809\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 230us/step - loss: 0.6401 - acc: 0.7507 - val_loss: 0.7944 - val_acc: 0.6915\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 219us/step - loss: 0.6211 - acc: 0.7855 - val_loss: 0.7829 - val_acc: 0.7021\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 210us/step - loss: 0.4903 - acc: 0.8123 - val_loss: 0.7778 - val_acc: 0.7128\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 237us/step - loss: 0.5008 - acc: 0.8231 - val_loss: 0.7770 - val_acc: 0.7021\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 215us/step - loss: 0.3574 - acc: 0.8901 - val_loss: 0.7795 - val_acc: 0.7021\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 208us/step - loss: 0.3579 - acc: 0.8740 - val_loss: 0.7838 - val_acc: 0.7234\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 236us/step - loss: 0.3767 - acc: 0.8954 - val_loss: 0.7914 - val_acc: 0.7234\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 235us/step - loss: 0.3405 - acc: 0.9008 - val_loss: 0.8026 - val_acc: 0.7128\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 221us/step - loss: 0.2540 - acc: 0.9196 - val_loss: 0.8161 - val_acc: 0.7128\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 229us/step - loss: 0.1829 - acc: 0.9410 - val_loss: 0.8316 - val_acc: 0.7128\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 225us/step - loss: 0.2309 - acc: 0.9142 - val_loss: 0.8487 - val_acc: 0.7021\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 237us/step - loss: 0.2722 - acc: 0.9169 - val_loss: 0.8663 - val_acc: 0.6809\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 235us/step - loss: 0.1743 - acc: 0.9517 - val_loss: 0.8812 - val_acc: 0.6809\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 232us/step - loss: 0.1683 - acc: 0.9571 - val_loss: 0.8970 - val_acc: 0.6915\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 0.1359 - acc: 0.9705 - val_loss: 0.9152 - val_acc: 0.7021\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 0.1229 - acc: 0.9625 - val_loss: 0.9329 - val_acc: 0.7021\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 216us/step - loss: 0.1053 - acc: 0.9678 - val_loss: 0.9556 - val_acc: 0.7021\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 213us/step - loss: 0.0901 - acc: 0.9839 - val_loss: 0.9767 - val_acc: 0.7021\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 216us/step - loss: 0.1346 - acc: 0.9651 - val_loss: 0.9972 - val_acc: 0.7128\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 0.1162 - acc: 0.9678 - val_loss: 1.0180 - val_acc: 0.7128\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 237us/step - loss: 0.0791 - acc: 0.9786 - val_loss: 1.0371 - val_acc: 0.7128\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 211us/step - loss: 0.0880 - acc: 0.9759 - val_loss: 1.0537 - val_acc: 0.7234\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 214us/step - loss: 0.0807 - acc: 0.9786 - val_loss: 1.0709 - val_acc: 0.7234\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 218us/step - loss: 0.0999 - acc: 0.9786 - val_loss: 1.0887 - val_acc: 0.7128\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "o.append(model.evaluate(X_test, y_test_for_keras, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = []\n",
    "g.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o['xgb+rf'] = [round((sum(np.argmax((xgb_result+rf_result) , axis=1) == y_test)/len(y_test))*100, 2)]\n",
    "# o['xgb+lgb'] = [round((sum(np.argmax((xgb_result+lgb_result) , axis=1) == y_test)/len(y_test))*100, 2)]\n",
    "# o['rf+lgb'] = [round((sum(np.argmax((rf_result+lgb_result) , axis=1) == y_test)/len(y_test))*100, 2)]\n",
    "# o['xgb+rf+lgb'] = [round((sum(np.argmax((xgb_result+rf_result+lgb_result) , axis=1) == y_test)/len(y_test))*100, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load  data\n",
    "df = pd.read_csv('../data/HCD45_neg_norm.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit\n",
    "clf = rf()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# add result to list \n",
    "o = []\n",
    "o.append(round((clf.score(X_test, y_test))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.30728\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.24428\n",
      "[3]\tvalid_0's multi_logloss: 1.19091\n",
      "[4]\tvalid_0's multi_logloss: 1.14783\n",
      "[5]\tvalid_0's multi_logloss: 1.1074\n",
      "[6]\tvalid_0's multi_logloss: 1.07527\n",
      "[7]\tvalid_0's multi_logloss: 1.04467\n",
      "[8]\tvalid_0's multi_logloss: 1.01698\n",
      "[9]\tvalid_0's multi_logloss: 0.996891\n",
      "[10]\tvalid_0's multi_logloss: 0.975222\n",
      "[11]\tvalid_0's multi_logloss: 0.948461\n",
      "[12]\tvalid_0's multi_logloss: 0.927557\n",
      "[13]\tvalid_0's multi_logloss: 0.908382\n",
      "[14]\tvalid_0's multi_logloss: 0.890571\n",
      "[15]\tvalid_0's multi_logloss: 0.874068\n",
      "[16]\tvalid_0's multi_logloss: 0.858673\n",
      "[17]\tvalid_0's multi_logloss: 0.842187\n",
      "[18]\tvalid_0's multi_logloss: 0.833464\n",
      "[19]\tvalid_0's multi_logloss: 0.822464\n",
      "[20]\tvalid_0's multi_logloss: 0.814508\n",
      "[21]\tvalid_0's multi_logloss: 0.804284\n",
      "[22]\tvalid_0's multi_logloss: 0.796206\n",
      "[23]\tvalid_0's multi_logloss: 0.787263\n",
      "[24]\tvalid_0's multi_logloss: 0.779908\n",
      "[25]\tvalid_0's multi_logloss: 0.774835\n",
      "[26]\tvalid_0's multi_logloss: 0.767054\n",
      "[27]\tvalid_0's multi_logloss: 0.760902\n",
      "[28]\tvalid_0's multi_logloss: 0.754367\n",
      "[29]\tvalid_0's multi_logloss: 0.746912\n",
      "[30]\tvalid_0's multi_logloss: 0.740209\n",
      "[31]\tvalid_0's multi_logloss: 0.73602\n",
      "[32]\tvalid_0's multi_logloss: 0.729159\n",
      "[33]\tvalid_0's multi_logloss: 0.725089\n",
      "[34]\tvalid_0's multi_logloss: 0.716272\n",
      "[35]\tvalid_0's multi_logloss: 0.711598\n",
      "[36]\tvalid_0's multi_logloss: 0.707977\n",
      "[37]\tvalid_0's multi_logloss: 0.702569\n",
      "[38]\tvalid_0's multi_logloss: 0.702577\n",
      "[39]\tvalid_0's multi_logloss: 0.697904\n",
      "[40]\tvalid_0's multi_logloss: 0.695165\n",
      "[41]\tvalid_0's multi_logloss: 0.691837\n",
      "[42]\tvalid_0's multi_logloss: 0.691471\n",
      "[43]\tvalid_0's multi_logloss: 0.687015\n",
      "[44]\tvalid_0's multi_logloss: 0.686941\n",
      "[45]\tvalid_0's multi_logloss: 0.68717\n",
      "[46]\tvalid_0's multi_logloss: 0.686034\n",
      "[47]\tvalid_0's multi_logloss: 0.683304\n",
      "[48]\tvalid_0's multi_logloss: 0.6775\n",
      "[49]\tvalid_0's multi_logloss: 0.675299\n",
      "[50]\tvalid_0's multi_logloss: 0.67405\n",
      "[51]\tvalid_0's multi_logloss: 0.672619\n",
      "[52]\tvalid_0's multi_logloss: 0.671765\n",
      "[53]\tvalid_0's multi_logloss: 0.670057\n",
      "[54]\tvalid_0's multi_logloss: 0.670282\n",
      "[55]\tvalid_0's multi_logloss: 0.671578\n",
      "[56]\tvalid_0's multi_logloss: 0.671116\n",
      "[57]\tvalid_0's multi_logloss: 0.672383\n",
      "[58]\tvalid_0's multi_logloss: 0.671923\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_logloss: 0.670057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    device = 'gpu'\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "\n",
    "# result append to list\n",
    "o.append(round(gbm.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "params = {}\n",
    "params['device'] = 'gpu'\n",
    "params['gpu_id'] = 1\n",
    "params['updater'] = 'grow_gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "o.append(round(model.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 5ms/step - loss: 2.3167 - acc: 0.2359 - val_loss: 1.6018 - val_acc: 0.3298\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 397us/step - loss: 1.8618 - acc: 0.3190 - val_loss: 1.5464 - val_acc: 0.3298\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 360us/step - loss: 1.8906 - acc: 0.3083 - val_loss: 1.5075 - val_acc: 0.3298\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 403us/step - loss: 1.8461 - acc: 0.3164 - val_loss: 1.4650 - val_acc: 0.3511\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 363us/step - loss: 1.8787 - acc: 0.3351 - val_loss: 1.4279 - val_acc: 0.3298\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 388us/step - loss: 1.7753 - acc: 0.3512 - val_loss: 1.3920 - val_acc: 0.3404\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 368us/step - loss: 1.5961 - acc: 0.3539 - val_loss: 1.3544 - val_acc: 0.3404\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 378us/step - loss: 1.6554 - acc: 0.3458 - val_loss: 1.3229 - val_acc: 0.3404\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 395us/step - loss: 1.6398 - acc: 0.3914 - val_loss: 1.2858 - val_acc: 0.3404\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 364us/step - loss: 1.4371 - acc: 0.4718 - val_loss: 1.2411 - val_acc: 0.3723\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 373us/step - loss: 1.3377 - acc: 0.4879 - val_loss: 1.2051 - val_acc: 0.4043\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 358us/step - loss: 1.4531 - acc: 0.4209 - val_loss: 1.1727 - val_acc: 0.4255\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 386us/step - loss: 1.4957 - acc: 0.4692 - val_loss: 1.1547 - val_acc: 0.4362\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 373us/step - loss: 1.3442 - acc: 0.4906 - val_loss: 1.1429 - val_acc: 0.4574\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 354us/step - loss: 1.2221 - acc: 0.4745 - val_loss: 1.1343 - val_acc: 0.4574\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 1.2537 - acc: 0.5335 - val_loss: 1.1289 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 376us/step - loss: 1.2080 - acc: 0.5389 - val_loss: 1.1179 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 386us/step - loss: 1.1025 - acc: 0.5523 - val_loss: 1.1125 - val_acc: 0.5213\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 382us/step - loss: 1.0901 - acc: 0.6032 - val_loss: 1.1074 - val_acc: 0.5319\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 1.1378 - acc: 0.5925 - val_loss: 1.0897 - val_acc: 0.5319\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 381us/step - loss: 0.9931 - acc: 0.6220 - val_loss: 1.0628 - val_acc: 0.5319\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 364us/step - loss: 0.9546 - acc: 0.6327 - val_loss: 1.0326 - val_acc: 0.5426\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 390us/step - loss: 0.9914 - acc: 0.6568 - val_loss: 1.0001 - val_acc: 0.5957\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 390us/step - loss: 0.9337 - acc: 0.6729 - val_loss: 0.9663 - val_acc: 0.5957\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 407us/step - loss: 0.8175 - acc: 0.6810 - val_loss: 0.9304 - val_acc: 0.6170\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 369us/step - loss: 0.6609 - acc: 0.7694 - val_loss: 0.8930 - val_acc: 0.6064\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 360us/step - loss: 0.6959 - acc: 0.7641 - val_loss: 0.8624 - val_acc: 0.6170\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 404us/step - loss: 0.5704 - acc: 0.7936 - val_loss: 0.8341 - val_acc: 0.6277\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 382us/step - loss: 0.4970 - acc: 0.8150 - val_loss: 0.8149 - val_acc: 0.6383\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 390us/step - loss: 0.5504 - acc: 0.8150 - val_loss: 0.8031 - val_acc: 0.6489\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 0.4656 - acc: 0.8472 - val_loss: 0.8018 - val_acc: 0.6489\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 363us/step - loss: 0.4079 - acc: 0.8686 - val_loss: 0.8014 - val_acc: 0.6702\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 375us/step - loss: 0.3557 - acc: 0.8660 - val_loss: 0.8086 - val_acc: 0.6702\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 400us/step - loss: 0.3622 - acc: 0.8794 - val_loss: 0.8138 - val_acc: 0.6915\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 365us/step - loss: 0.3541 - acc: 0.8928 - val_loss: 0.8209 - val_acc: 0.6915\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 363us/step - loss: 0.3403 - acc: 0.8847 - val_loss: 0.8347 - val_acc: 0.6915\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 376us/step - loss: 0.2563 - acc: 0.9088 - val_loss: 0.8494 - val_acc: 0.6915\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 371us/step - loss: 0.2181 - acc: 0.9169 - val_loss: 0.8661 - val_acc: 0.7021\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 355us/step - loss: 0.3132 - acc: 0.9196 - val_loss: 0.8834 - val_acc: 0.7021\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 383us/step - loss: 0.2401 - acc: 0.9062 - val_loss: 0.8993 - val_acc: 0.6809\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 367us/step - loss: 0.1837 - acc: 0.9464 - val_loss: 0.9124 - val_acc: 0.6915\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 379us/step - loss: 0.2006 - acc: 0.9491 - val_loss: 0.9216 - val_acc: 0.7021\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 391us/step - loss: 0.1434 - acc: 0.9544 - val_loss: 0.9282 - val_acc: 0.6915\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 342us/step - loss: 0.1933 - acc: 0.9383 - val_loss: 0.9397 - val_acc: 0.6915\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 392us/step - loss: 0.1283 - acc: 0.9598 - val_loss: 0.9496 - val_acc: 0.7021\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 382us/step - loss: 0.1207 - acc: 0.9491 - val_loss: 0.9633 - val_acc: 0.7021\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 413us/step - loss: 0.1413 - acc: 0.9598 - val_loss: 0.9799 - val_acc: 0.7021\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 358us/step - loss: 0.0975 - acc: 0.9705 - val_loss: 0.9982 - val_acc: 0.7021\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 352us/step - loss: 0.0824 - acc: 0.9705 - val_loss: 1.0183 - val_acc: 0.7021\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 403us/step - loss: 0.1282 - acc: 0.9544 - val_loss: 1.0400 - val_acc: 0.7128\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 396us/step - loss: 0.0755 - acc: 0.9786 - val_loss: 1.0624 - val_acc: 0.7128\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 0s 402us/step - loss: 0.0626 - acc: 0.9759 - val_loss: 1.0854 - val_acc: 0.7128\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "o.append(model.evaluate(X_test, y_test_for_keras, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load  data\n",
    "df = pd.read_csv('../data/HCD65_neg_norm.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit\n",
    "clf = rf()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# add result to list \n",
    "o = []\n",
    "o.append(round((clf.score(X_test, y_test))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.31383\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.25405\n",
      "[3]\tvalid_0's multi_logloss: 1.20084\n",
      "[4]\tvalid_0's multi_logloss: 1.15406\n",
      "[5]\tvalid_0's multi_logloss: 1.1178\n",
      "[6]\tvalid_0's multi_logloss: 1.0844\n",
      "[7]\tvalid_0's multi_logloss: 1.05432\n",
      "[8]\tvalid_0's multi_logloss: 1.02851\n",
      "[9]\tvalid_0's multi_logloss: 1.00402\n",
      "[10]\tvalid_0's multi_logloss: 0.980917\n",
      "[11]\tvalid_0's multi_logloss: 0.959213\n",
      "[12]\tvalid_0's multi_logloss: 0.947037\n",
      "[13]\tvalid_0's multi_logloss: 0.93271\n",
      "[14]\tvalid_0's multi_logloss: 0.92061\n",
      "[15]\tvalid_0's multi_logloss: 0.909448\n",
      "[16]\tvalid_0's multi_logloss: 0.895203\n",
      "[17]\tvalid_0's multi_logloss: 0.885169\n",
      "[18]\tvalid_0's multi_logloss: 0.87417\n",
      "[19]\tvalid_0's multi_logloss: 0.86671\n",
      "[20]\tvalid_0's multi_logloss: 0.86169\n",
      "[21]\tvalid_0's multi_logloss: 0.856482\n",
      "[22]\tvalid_0's multi_logloss: 0.849996\n",
      "[23]\tvalid_0's multi_logloss: 0.844023\n",
      "[24]\tvalid_0's multi_logloss: 0.83711\n",
      "[25]\tvalid_0's multi_logloss: 0.833033\n",
      "[26]\tvalid_0's multi_logloss: 0.828596\n",
      "[27]\tvalid_0's multi_logloss: 0.823432\n",
      "[28]\tvalid_0's multi_logloss: 0.818749\n",
      "[29]\tvalid_0's multi_logloss: 0.814332\n",
      "[30]\tvalid_0's multi_logloss: 0.81067\n",
      "[31]\tvalid_0's multi_logloss: 0.807429\n",
      "[32]\tvalid_0's multi_logloss: 0.803797\n",
      "[33]\tvalid_0's multi_logloss: 0.803622\n",
      "[34]\tvalid_0's multi_logloss: 0.798525\n",
      "[35]\tvalid_0's multi_logloss: 0.794464\n",
      "[36]\tvalid_0's multi_logloss: 0.792116\n",
      "[37]\tvalid_0's multi_logloss: 0.792545\n",
      "[38]\tvalid_0's multi_logloss: 0.790446\n",
      "[39]\tvalid_0's multi_logloss: 0.787282\n",
      "[40]\tvalid_0's multi_logloss: 0.786193\n",
      "[41]\tvalid_0's multi_logloss: 0.785058\n",
      "[42]\tvalid_0's multi_logloss: 0.781322\n",
      "[43]\tvalid_0's multi_logloss: 0.778424\n",
      "[44]\tvalid_0's multi_logloss: 0.779497\n",
      "[45]\tvalid_0's multi_logloss: 0.777278\n",
      "[46]\tvalid_0's multi_logloss: 0.776052\n",
      "[47]\tvalid_0's multi_logloss: 0.777304\n",
      "[48]\tvalid_0's multi_logloss: 0.774\n",
      "[49]\tvalid_0's multi_logloss: 0.773402\n",
      "[50]\tvalid_0's multi_logloss: 0.773347\n",
      "[51]\tvalid_0's multi_logloss: 0.771216\n",
      "[52]\tvalid_0's multi_logloss: 0.769942\n",
      "[53]\tvalid_0's multi_logloss: 0.772406\n",
      "[54]\tvalid_0's multi_logloss: 0.774304\n",
      "[55]\tvalid_0's multi_logloss: 0.772578\n",
      "[56]\tvalid_0's multi_logloss: 0.77444\n",
      "[57]\tvalid_0's multi_logloss: 0.776059\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 0.769942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    device = 'gpu'\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "\n",
    "# result append to list\n",
    "o.append(round(gbm.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "params = {}\n",
    "params['device'] = 'gpu'\n",
    "params['gpu_id'] = 1\n",
    "params['updater'] = 'grow_gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "o.append(round(model.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 5ms/step - loss: 2.3458 - acc: 0.2359 - val_loss: 1.6102 - val_acc: 0.3511\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 505us/step - loss: 1.8565 - acc: 0.3512 - val_loss: 1.6563 - val_acc: 0.3085\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 481us/step - loss: 1.9349 - acc: 0.3405 - val_loss: 1.7194 - val_acc: 0.2872\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 493us/step - loss: 1.6329 - acc: 0.3834 - val_loss: 1.7205 - val_acc: 0.2979\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 534us/step - loss: 1.9863 - acc: 0.3566 - val_loss: 1.7068 - val_acc: 0.2979\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 544us/step - loss: 1.7797 - acc: 0.3592 - val_loss: 1.6782 - val_acc: 0.2979\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 502us/step - loss: 1.6674 - acc: 0.3968 - val_loss: 1.6260 - val_acc: 0.2872\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 526us/step - loss: 1.6571 - acc: 0.4048 - val_loss: 1.5537 - val_acc: 0.2872\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 508us/step - loss: 1.5072 - acc: 0.4316 - val_loss: 1.4797 - val_acc: 0.3085\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 522us/step - loss: 1.4424 - acc: 0.4477 - val_loss: 1.3931 - val_acc: 0.3404\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 521us/step - loss: 1.4286 - acc: 0.4531 - val_loss: 1.3216 - val_acc: 0.3404\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 542us/step - loss: 1.4575 - acc: 0.3914 - val_loss: 1.2740 - val_acc: 0.3723\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 507us/step - loss: 1.4042 - acc: 0.4906 - val_loss: 1.2544 - val_acc: 0.3936\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 524us/step - loss: 1.4094 - acc: 0.4826 - val_loss: 1.2540 - val_acc: 0.3830\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 515us/step - loss: 1.3626 - acc: 0.4638 - val_loss: 1.2644 - val_acc: 0.4043\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 530us/step - loss: 1.1557 - acc: 0.5094 - val_loss: 1.2888 - val_acc: 0.4043\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 505us/step - loss: 1.1791 - acc: 0.5255 - val_loss: 1.3131 - val_acc: 0.4043\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 525us/step - loss: 1.1752 - acc: 0.5469 - val_loss: 1.3333 - val_acc: 0.3936\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 502us/step - loss: 1.0792 - acc: 0.5710 - val_loss: 1.3415 - val_acc: 0.3936\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 520us/step - loss: 0.9965 - acc: 0.6139 - val_loss: 1.3369 - val_acc: 0.3936\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 508us/step - loss: 1.0035 - acc: 0.6113 - val_loss: 1.3278 - val_acc: 0.4043\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 511us/step - loss: 1.0246 - acc: 0.6032 - val_loss: 1.3033 - val_acc: 0.4255\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 500us/step - loss: 0.8980 - acc: 0.6488 - val_loss: 1.2722 - val_acc: 0.4468\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 495us/step - loss: 0.8921 - acc: 0.6756 - val_loss: 1.2353 - val_acc: 0.4787\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 497us/step - loss: 0.8604 - acc: 0.6917 - val_loss: 1.1916 - val_acc: 0.4787\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 507us/step - loss: 0.8346 - acc: 0.6971 - val_loss: 1.1538 - val_acc: 0.5213\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 524us/step - loss: 0.7291 - acc: 0.7212 - val_loss: 1.1410 - val_acc: 0.5213\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 514us/step - loss: 0.6930 - acc: 0.7399 - val_loss: 1.1343 - val_acc: 0.5213\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 500us/step - loss: 0.6650 - acc: 0.7641 - val_loss: 1.1371 - val_acc: 0.5319\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 552us/step - loss: 0.6381 - acc: 0.7828 - val_loss: 1.1476 - val_acc: 0.5213\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 490us/step - loss: 0.6332 - acc: 0.7694 - val_loss: 1.1524 - val_acc: 0.5213\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 528us/step - loss: 0.5530 - acc: 0.7909 - val_loss: 1.1566 - val_acc: 0.5213\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 506us/step - loss: 0.4727 - acc: 0.8284 - val_loss: 1.1607 - val_acc: 0.5213\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 542us/step - loss: 0.4963 - acc: 0.8204 - val_loss: 1.1602 - val_acc: 0.5213\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 486us/step - loss: 0.4420 - acc: 0.8418 - val_loss: 1.1653 - val_acc: 0.5213\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 556us/step - loss: 0.4539 - acc: 0.8311 - val_loss: 1.1574 - val_acc: 0.5106\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 495us/step - loss: 0.3943 - acc: 0.8660 - val_loss: 1.1563 - val_acc: 0.5106\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 562us/step - loss: 0.4517 - acc: 0.8338 - val_loss: 1.1605 - val_acc: 0.5106\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 497us/step - loss: 0.3688 - acc: 0.8633 - val_loss: 1.1724 - val_acc: 0.5213\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 572us/step - loss: 0.2959 - acc: 0.8928 - val_loss: 1.1732 - val_acc: 0.5213\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 520us/step - loss: 0.3054 - acc: 0.8874 - val_loss: 1.1732 - val_acc: 0.5213\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 527us/step - loss: 0.3239 - acc: 0.8767 - val_loss: 1.1897 - val_acc: 0.5319\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 496us/step - loss: 0.3069 - acc: 0.8820 - val_loss: 1.2179 - val_acc: 0.5319\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 523us/step - loss: 0.2369 - acc: 0.9223 - val_loss: 1.2314 - val_acc: 0.5319\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 489us/step - loss: 0.2159 - acc: 0.9276 - val_loss: 1.2453 - val_acc: 0.5319\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 514us/step - loss: 0.2146 - acc: 0.9249 - val_loss: 1.2751 - val_acc: 0.5213\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 496us/step - loss: 0.2341 - acc: 0.9088 - val_loss: 1.3155 - val_acc: 0.5213\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 493us/step - loss: 0.1628 - acc: 0.9544 - val_loss: 1.3711 - val_acc: 0.5213\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "o.append(model.evaluate(X_test, y_test_for_keras, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    g, \n",
    "    columns=['Random Forest', 'LightGBM', 'XGBoost', 'Keras'], \n",
    "    index=['HCD35', 'HCD45', 'HCD65']\n",
    ").to_csv('../result/norm_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load  data\n",
    "df = pd.read_csv('../data/HCD35_pos_norm.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit\n",
    "clf = rf()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# add result to list \n",
    "o = []\n",
    "o.append(round((clf.score(X_test, y_test))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.29145\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.21452\n",
      "[3]\tvalid_0's multi_logloss: 1.15349\n",
      "[4]\tvalid_0's multi_logloss: 1.09671\n",
      "[5]\tvalid_0's multi_logloss: 1.04309\n",
      "[6]\tvalid_0's multi_logloss: 0.998792\n",
      "[7]\tvalid_0's multi_logloss: 0.958398\n",
      "[8]\tvalid_0's multi_logloss: 0.920585\n",
      "[9]\tvalid_0's multi_logloss: 0.884814\n",
      "[10]\tvalid_0's multi_logloss: 0.853752\n",
      "[11]\tvalid_0's multi_logloss: 0.826709\n",
      "[12]\tvalid_0's multi_logloss: 0.801109\n",
      "[13]\tvalid_0's multi_logloss: 0.776881\n",
      "[14]\tvalid_0's multi_logloss: 0.754607\n",
      "[15]\tvalid_0's multi_logloss: 0.732409\n",
      "[16]\tvalid_0's multi_logloss: 0.713332\n",
      "[17]\tvalid_0's multi_logloss: 0.695356\n",
      "[18]\tvalid_0's multi_logloss: 0.677332\n",
      "[19]\tvalid_0's multi_logloss: 0.662276\n",
      "[20]\tvalid_0's multi_logloss: 0.64722\n",
      "[21]\tvalid_0's multi_logloss: 0.635049\n",
      "[22]\tvalid_0's multi_logloss: 0.621298\n",
      "[23]\tvalid_0's multi_logloss: 0.610937\n",
      "[24]\tvalid_0's multi_logloss: 0.600643\n",
      "[25]\tvalid_0's multi_logloss: 0.590678\n",
      "[26]\tvalid_0's multi_logloss: 0.578924\n",
      "[27]\tvalid_0's multi_logloss: 0.569251\n",
      "[28]\tvalid_0's multi_logloss: 0.561031\n",
      "[29]\tvalid_0's multi_logloss: 0.555567\n",
      "[30]\tvalid_0's multi_logloss: 0.548559\n",
      "[31]\tvalid_0's multi_logloss: 0.540554\n",
      "[32]\tvalid_0's multi_logloss: 0.531922\n",
      "[33]\tvalid_0's multi_logloss: 0.525638\n",
      "[34]\tvalid_0's multi_logloss: 0.519043\n",
      "[35]\tvalid_0's multi_logloss: 0.51335\n",
      "[36]\tvalid_0's multi_logloss: 0.50602\n",
      "[37]\tvalid_0's multi_logloss: 0.499804\n",
      "[38]\tvalid_0's multi_logloss: 0.495077\n",
      "[39]\tvalid_0's multi_logloss: 0.489607\n",
      "[40]\tvalid_0's multi_logloss: 0.483309\n",
      "[41]\tvalid_0's multi_logloss: 0.479974\n",
      "[42]\tvalid_0's multi_logloss: 0.47645\n",
      "[43]\tvalid_0's multi_logloss: 0.472633\n",
      "[44]\tvalid_0's multi_logloss: 0.467581\n",
      "[45]\tvalid_0's multi_logloss: 0.466345\n",
      "[46]\tvalid_0's multi_logloss: 0.464921\n",
      "[47]\tvalid_0's multi_logloss: 0.463881\n",
      "[48]\tvalid_0's multi_logloss: 0.46077\n",
      "[49]\tvalid_0's multi_logloss: 0.456142\n",
      "[50]\tvalid_0's multi_logloss: 0.452324\n",
      "[51]\tvalid_0's multi_logloss: 0.448425\n",
      "[52]\tvalid_0's multi_logloss: 0.446951\n",
      "[53]\tvalid_0's multi_logloss: 0.443322\n",
      "[54]\tvalid_0's multi_logloss: 0.442566\n",
      "[55]\tvalid_0's multi_logloss: 0.439975\n",
      "[56]\tvalid_0's multi_logloss: 0.438725\n",
      "[57]\tvalid_0's multi_logloss: 0.436206\n",
      "[58]\tvalid_0's multi_logloss: 0.433237\n",
      "[59]\tvalid_0's multi_logloss: 0.430922\n",
      "[60]\tvalid_0's multi_logloss: 0.429589\n",
      "[61]\tvalid_0's multi_logloss: 0.428209\n",
      "[62]\tvalid_0's multi_logloss: 0.427241\n",
      "[63]\tvalid_0's multi_logloss: 0.425492\n",
      "[64]\tvalid_0's multi_logloss: 0.425918\n",
      "[65]\tvalid_0's multi_logloss: 0.423721\n",
      "[66]\tvalid_0's multi_logloss: 0.422438\n",
      "[67]\tvalid_0's multi_logloss: 0.42385\n",
      "[68]\tvalid_0's multi_logloss: 0.424204\n",
      "[69]\tvalid_0's multi_logloss: 0.422195\n",
      "[70]\tvalid_0's multi_logloss: 0.420943\n",
      "[71]\tvalid_0's multi_logloss: 0.419425\n",
      "[72]\tvalid_0's multi_logloss: 0.41987\n",
      "[73]\tvalid_0's multi_logloss: 0.418115\n",
      "[74]\tvalid_0's multi_logloss: 0.417988\n",
      "[75]\tvalid_0's multi_logloss: 0.415903\n",
      "[76]\tvalid_0's multi_logloss: 0.417172\n",
      "[77]\tvalid_0's multi_logloss: 0.415693\n",
      "[78]\tvalid_0's multi_logloss: 0.414962\n",
      "[79]\tvalid_0's multi_logloss: 0.414967\n",
      "[80]\tvalid_0's multi_logloss: 0.416348\n",
      "[81]\tvalid_0's multi_logloss: 0.416883\n",
      "[82]\tvalid_0's multi_logloss: 0.416799\n",
      "[83]\tvalid_0's multi_logloss: 0.4174\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 0.414962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    device = 'gpu'\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "\n",
    "# result append to list\n",
    "o.append(round(gbm.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "params = {}\n",
    "params['device'] = 'gpu'\n",
    "params['gpu_id'] = 1\n",
    "params['updater'] = 'grow_gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "o.append(round(model.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 2.2794 - acc: 0.2500 - val_loss: 1.5373 - val_acc: 0.2619\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 824us/step - loss: 1.8903 - acc: 0.2769 - val_loss: 1.4514 - val_acc: 0.2857\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 815us/step - loss: 1.7645 - acc: 0.3060 - val_loss: 1.3951 - val_acc: 0.3065\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 799us/step - loss: 1.6725 - acc: 0.3373 - val_loss: 1.3386 - val_acc: 0.3512\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 812us/step - loss: 1.6116 - acc: 0.3537 - val_loss: 1.2636 - val_acc: 0.4167\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 829us/step - loss: 1.5758 - acc: 0.3776 - val_loss: 1.2247 - val_acc: 0.4494\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 817us/step - loss: 1.4550 - acc: 0.4358 - val_loss: 1.2062 - val_acc: 0.4375\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 804us/step - loss: 1.4512 - acc: 0.4358 - val_loss: 1.1840 - val_acc: 0.4405\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 812us/step - loss: 1.3313 - acc: 0.4590 - val_loss: 1.1597 - val_acc: 0.4613\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 823us/step - loss: 1.2707 - acc: 0.5045 - val_loss: 1.1372 - val_acc: 0.4911\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 794us/step - loss: 1.2198 - acc: 0.5164 - val_loss: 1.1260 - val_acc: 0.5238\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 806us/step - loss: 1.0879 - acc: 0.5746 - val_loss: 1.1216 - val_acc: 0.5298\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 803us/step - loss: 1.0298 - acc: 0.6179 - val_loss: 1.1274 - val_acc: 0.5357\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 811us/step - loss: 0.9007 - acc: 0.6619 - val_loss: 1.1090 - val_acc: 0.5565\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 811us/step - loss: 0.8408 - acc: 0.6851 - val_loss: 1.0760 - val_acc: 0.5982\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 805us/step - loss: 0.7404 - acc: 0.7343 - val_loss: 1.0510 - val_acc: 0.6131\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 826us/step - loss: 0.6676 - acc: 0.7746 - val_loss: 1.0238 - val_acc: 0.6280\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 817us/step - loss: 0.6013 - acc: 0.7918 - val_loss: 1.0198 - val_acc: 0.6280\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 808us/step - loss: 0.4683 - acc: 0.8351 - val_loss: 1.0407 - val_acc: 0.6339\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 815us/step - loss: 0.4350 - acc: 0.8478 - val_loss: 1.0857 - val_acc: 0.6488\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 820us/step - loss: 0.3723 - acc: 0.8799 - val_loss: 1.1591 - val_acc: 0.6548\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 806us/step - loss: 0.3187 - acc: 0.8873 - val_loss: 1.2525 - val_acc: 0.6339\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 804us/step - loss: 0.2957 - acc: 0.9142 - val_loss: 1.3232 - val_acc: 0.6458\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 818us/step - loss: 0.2402 - acc: 0.9187 - val_loss: 1.3621 - val_acc: 0.6548\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 830us/step - loss: 0.1976 - acc: 0.9396 - val_loss: 1.3778 - val_acc: 0.6577\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 810us/step - loss: 0.2063 - acc: 0.9366 - val_loss: 1.3761 - val_acc: 0.6756\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 817us/step - loss: 0.1385 - acc: 0.9560 - val_loss: 1.3792 - val_acc: 0.6726\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 826us/step - loss: 0.1657 - acc: 0.9582 - val_loss: 1.4002 - val_acc: 0.6786\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 805us/step - loss: 0.1211 - acc: 0.9634 - val_loss: 1.4256 - val_acc: 0.6845\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 810us/step - loss: 0.0964 - acc: 0.9739 - val_loss: 1.4500 - val_acc: 0.6875\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 787us/step - loss: 0.0956 - acc: 0.9784 - val_loss: 1.4703 - val_acc: 0.6815\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 827us/step - loss: 0.0734 - acc: 0.9806 - val_loss: 1.4963 - val_acc: 0.6845\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 824us/step - loss: 0.0963 - acc: 0.9754 - val_loss: 1.5198 - val_acc: 0.6845\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 798us/step - loss: 0.0792 - acc: 0.9806 - val_loss: 1.5450 - val_acc: 0.6815\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 817us/step - loss: 0.0499 - acc: 0.9851 - val_loss: 1.5692 - val_acc: 0.6786\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 1s 831us/step - loss: 0.0578 - acc: 0.9873 - val_loss: 1.5919 - val_acc: 0.6786\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 1s 801us/step - loss: 0.0466 - acc: 0.9866 - val_loss: 1.6127 - val_acc: 0.6815\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 1s 791us/step - loss: 0.0385 - acc: 0.9925 - val_loss: 1.6291 - val_acc: 0.6845\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-672ac8567449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     ]\n\u001b[1;32m     49\u001b[0m )\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_for_keras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.append(model.evaluate(X_test, y_test_for_keras, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[75.0, 83.93, 78.57, 0.6845238095238095]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = []\n",
    "g.append(o)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load  data\n",
    "df = pd.read_csv('../data/HCD45_pos_norm.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit\n",
    "clf = rf()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# add result to list \n",
    "o = []\n",
    "o.append(round((clf.score(X_test, y_test))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.29231\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.22044\n",
      "[3]\tvalid_0's multi_logloss: 1.15759\n",
      "[4]\tvalid_0's multi_logloss: 1.10527\n",
      "[5]\tvalid_0's multi_logloss: 1.05431\n",
      "[6]\tvalid_0's multi_logloss: 1.01236\n",
      "[7]\tvalid_0's multi_logloss: 0.971375\n",
      "[8]\tvalid_0's multi_logloss: 0.935873\n",
      "[9]\tvalid_0's multi_logloss: 0.904783\n",
      "[10]\tvalid_0's multi_logloss: 0.874381\n",
      "[11]\tvalid_0's multi_logloss: 0.846309\n",
      "[12]\tvalid_0's multi_logloss: 0.822394\n",
      "[13]\tvalid_0's multi_logloss: 0.798726\n",
      "[14]\tvalid_0's multi_logloss: 0.777977\n",
      "[15]\tvalid_0's multi_logloss: 0.755864\n",
      "[16]\tvalid_0's multi_logloss: 0.737617\n",
      "[17]\tvalid_0's multi_logloss: 0.721305\n",
      "[18]\tvalid_0's multi_logloss: 0.706719\n",
      "[19]\tvalid_0's multi_logloss: 0.690823\n",
      "[20]\tvalid_0's multi_logloss: 0.678504\n",
      "[21]\tvalid_0's multi_logloss: 0.663004\n",
      "[22]\tvalid_0's multi_logloss: 0.650599\n",
      "[23]\tvalid_0's multi_logloss: 0.639505\n",
      "[24]\tvalid_0's multi_logloss: 0.630802\n",
      "[25]\tvalid_0's multi_logloss: 0.622712\n",
      "[26]\tvalid_0's multi_logloss: 0.615215\n",
      "[27]\tvalid_0's multi_logloss: 0.610225\n",
      "[28]\tvalid_0's multi_logloss: 0.60178\n",
      "[29]\tvalid_0's multi_logloss: 0.596656\n",
      "[30]\tvalid_0's multi_logloss: 0.589644\n",
      "[31]\tvalid_0's multi_logloss: 0.581762\n",
      "[32]\tvalid_0's multi_logloss: 0.577178\n",
      "[33]\tvalid_0's multi_logloss: 0.57317\n",
      "[34]\tvalid_0's multi_logloss: 0.569208\n",
      "[35]\tvalid_0's multi_logloss: 0.565927\n",
      "[36]\tvalid_0's multi_logloss: 0.558929\n",
      "[37]\tvalid_0's multi_logloss: 0.55334\n",
      "[38]\tvalid_0's multi_logloss: 0.549207\n",
      "[39]\tvalid_0's multi_logloss: 0.545964\n",
      "[40]\tvalid_0's multi_logloss: 0.542678\n",
      "[41]\tvalid_0's multi_logloss: 0.537893\n",
      "[42]\tvalid_0's multi_logloss: 0.534197\n",
      "[43]\tvalid_0's multi_logloss: 0.530472\n",
      "[44]\tvalid_0's multi_logloss: 0.526455\n",
      "[45]\tvalid_0's multi_logloss: 0.524251\n",
      "[46]\tvalid_0's multi_logloss: 0.520221\n",
      "[47]\tvalid_0's multi_logloss: 0.518518\n",
      "[48]\tvalid_0's multi_logloss: 0.515953\n",
      "[49]\tvalid_0's multi_logloss: 0.513839\n",
      "[50]\tvalid_0's multi_logloss: 0.510242\n",
      "[51]\tvalid_0's multi_logloss: 0.507345\n",
      "[52]\tvalid_0's multi_logloss: 0.504993\n",
      "[53]\tvalid_0's multi_logloss: 0.501786\n",
      "[54]\tvalid_0's multi_logloss: 0.500202\n",
      "[55]\tvalid_0's multi_logloss: 0.496159\n",
      "[56]\tvalid_0's multi_logloss: 0.494667\n",
      "[57]\tvalid_0's multi_logloss: 0.49334\n",
      "[58]\tvalid_0's multi_logloss: 0.492716\n",
      "[59]\tvalid_0's multi_logloss: 0.492272\n",
      "[60]\tvalid_0's multi_logloss: 0.490647\n",
      "[61]\tvalid_0's multi_logloss: 0.490881\n",
      "[62]\tvalid_0's multi_logloss: 0.489539\n",
      "[63]\tvalid_0's multi_logloss: 0.487363\n",
      "[64]\tvalid_0's multi_logloss: 0.486644\n",
      "[65]\tvalid_0's multi_logloss: 0.485954\n",
      "[66]\tvalid_0's multi_logloss: 0.48435\n",
      "[67]\tvalid_0's multi_logloss: 0.482743\n",
      "[68]\tvalid_0's multi_logloss: 0.481831\n",
      "[69]\tvalid_0's multi_logloss: 0.481107\n",
      "[70]\tvalid_0's multi_logloss: 0.483454\n",
      "[71]\tvalid_0's multi_logloss: 0.481564\n",
      "[72]\tvalid_0's multi_logloss: 0.48046\n",
      "[73]\tvalid_0's multi_logloss: 0.482764\n",
      "[74]\tvalid_0's multi_logloss: 0.483573\n",
      "[75]\tvalid_0's multi_logloss: 0.482159\n",
      "[76]\tvalid_0's multi_logloss: 0.482011\n",
      "[77]\tvalid_0's multi_logloss: 0.48121\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's multi_logloss: 0.48046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    device = 'gpu'\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "\n",
    "# result append to list\n",
    "o.append(round(gbm.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "params = {}\n",
    "params['device'] = 'gpu'\n",
    "params['gpu_id'] = 1\n",
    "params['updater'] = 'grow_gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "o.append(round(model.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 2.2043 - acc: 0.2507 - val_loss: 1.5073 - val_acc: 0.2768\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 854us/step - loss: 2.0194 - acc: 0.2881 - val_loss: 1.5037 - val_acc: 0.2887\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 854us/step - loss: 1.8062 - acc: 0.3149 - val_loss: 1.5428 - val_acc: 0.3095\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 877us/step - loss: 1.8060 - acc: 0.3433 - val_loss: 1.5150 - val_acc: 0.3155\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 953us/step - loss: 1.7186 - acc: 0.3657 - val_loss: 1.4256 - val_acc: 0.3274\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 898us/step - loss: 1.5927 - acc: 0.3761 - val_loss: 1.3668 - val_acc: 0.3363\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 860us/step - loss: 1.5062 - acc: 0.4179 - val_loss: 1.3188 - val_acc: 0.3988\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 859us/step - loss: 1.4657 - acc: 0.4187 - val_loss: 1.2856 - val_acc: 0.4107\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 852us/step - loss: 1.3760 - acc: 0.4567 - val_loss: 1.2707 - val_acc: 0.4107\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 854us/step - loss: 1.3212 - acc: 0.4843 - val_loss: 1.2458 - val_acc: 0.4583\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 851us/step - loss: 1.1936 - acc: 0.5291 - val_loss: 1.2148 - val_acc: 0.5089\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 854us/step - loss: 1.1968 - acc: 0.5373 - val_loss: 1.1868 - val_acc: 0.4821\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 861us/step - loss: 1.1230 - acc: 0.5746 - val_loss: 1.1707 - val_acc: 0.4821\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 851us/step - loss: 0.9884 - acc: 0.6351 - val_loss: 1.1626 - val_acc: 0.4762\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 861us/step - loss: 0.8513 - acc: 0.6843 - val_loss: 1.1534 - val_acc: 0.5060\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 852us/step - loss: 0.8073 - acc: 0.6828 - val_loss: 1.1627 - val_acc: 0.5119\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 910us/step - loss: 0.7143 - acc: 0.7276 - val_loss: 1.1771 - val_acc: 0.5327\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 875us/step - loss: 0.6545 - acc: 0.7597 - val_loss: 1.1979 - val_acc: 0.5327\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 846us/step - loss: 0.5558 - acc: 0.7948 - val_loss: 1.2268 - val_acc: 0.5417\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 860us/step - loss: 0.5022 - acc: 0.8045 - val_loss: 1.2738 - val_acc: 0.5565\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 856us/step - loss: 0.4311 - acc: 0.8515 - val_loss: 1.3397 - val_acc: 0.5655\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 844us/step - loss: 0.3816 - acc: 0.8657 - val_loss: 1.4246 - val_acc: 0.5655\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 861us/step - loss: 0.3370 - acc: 0.8821 - val_loss: 1.4994 - val_acc: 0.5685\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 882us/step - loss: 0.3072 - acc: 0.8948 - val_loss: 1.5496 - val_acc: 0.5655\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 858us/step - loss: 0.2495 - acc: 0.9187 - val_loss: 1.5848 - val_acc: 0.5804\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 866us/step - loss: 0.2413 - acc: 0.9284 - val_loss: 1.6292 - val_acc: 0.5774\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 859us/step - loss: 0.2171 - acc: 0.9366 - val_loss: 1.6968 - val_acc: 0.5804\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 854us/step - loss: 0.1794 - acc: 0.9403 - val_loss: 1.7544 - val_acc: 0.5863\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 1s 879us/step - loss: 0.1684 - acc: 0.9388 - val_loss: 1.7843 - val_acc: 0.5952\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 1s 874us/step - loss: 0.1545 - acc: 0.9433 - val_loss: 1.8078 - val_acc: 0.6012\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 1s 869us/step - loss: 0.1095 - acc: 0.9642 - val_loss: 1.8365 - val_acc: 0.5982\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 1s 836us/step - loss: 0.1268 - acc: 0.9672 - val_loss: 1.8534 - val_acc: 0.6071\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 1s 854us/step - loss: 0.0951 - acc: 0.9694 - val_loss: 1.8689 - val_acc: 0.6220\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 1s 872us/step - loss: 0.0838 - acc: 0.9672 - val_loss: 1.8929 - val_acc: 0.6161\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 1s 857us/step - loss: 0.0723 - acc: 0.9754 - val_loss: 1.9189 - val_acc: 0.6190\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "o.append(model.evaluate(X_test, y_test_for_keras, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load  data\n",
    "df = pd.read_csv('../data/HCD65_pos_norm.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit\n",
    "clf = rf()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# add result to list \n",
    "o = []\n",
    "o.append(round((clf.score(X_test, y_test))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.2955\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.22148\n",
      "[3]\tvalid_0's multi_logloss: 1.16028\n",
      "[4]\tvalid_0's multi_logloss: 1.10455\n",
      "[5]\tvalid_0's multi_logloss: 1.05653\n",
      "[6]\tvalid_0's multi_logloss: 1.01408\n",
      "[7]\tvalid_0's multi_logloss: 0.970765\n",
      "[8]\tvalid_0's multi_logloss: 0.93398\n",
      "[9]\tvalid_0's multi_logloss: 0.903181\n",
      "[10]\tvalid_0's multi_logloss: 0.872622\n",
      "[11]\tvalid_0's multi_logloss: 0.845132\n",
      "[12]\tvalid_0's multi_logloss: 0.823578\n",
      "[13]\tvalid_0's multi_logloss: 0.802204\n",
      "[14]\tvalid_0's multi_logloss: 0.780579\n",
      "[15]\tvalid_0's multi_logloss: 0.760263\n",
      "[16]\tvalid_0's multi_logloss: 0.745311\n",
      "[17]\tvalid_0's multi_logloss: 0.730848\n",
      "[18]\tvalid_0's multi_logloss: 0.715726\n",
      "[19]\tvalid_0's multi_logloss: 0.702982\n",
      "[20]\tvalid_0's multi_logloss: 0.691537\n",
      "[21]\tvalid_0's multi_logloss: 0.677025\n",
      "[22]\tvalid_0's multi_logloss: 0.666607\n",
      "[23]\tvalid_0's multi_logloss: 0.654698\n",
      "[24]\tvalid_0's multi_logloss: 0.647321\n",
      "[25]\tvalid_0's multi_logloss: 0.638452\n",
      "[26]\tvalid_0's multi_logloss: 0.630364\n",
      "[27]\tvalid_0's multi_logloss: 0.622426\n",
      "[28]\tvalid_0's multi_logloss: 0.61401\n",
      "[29]\tvalid_0's multi_logloss: 0.606361\n",
      "[30]\tvalid_0's multi_logloss: 0.603139\n",
      "[31]\tvalid_0's multi_logloss: 0.596327\n",
      "[32]\tvalid_0's multi_logloss: 0.591146\n",
      "[33]\tvalid_0's multi_logloss: 0.584506\n",
      "[34]\tvalid_0's multi_logloss: 0.579962\n",
      "[35]\tvalid_0's multi_logloss: 0.576159\n",
      "[36]\tvalid_0's multi_logloss: 0.571493\n",
      "[37]\tvalid_0's multi_logloss: 0.567249\n",
      "[38]\tvalid_0's multi_logloss: 0.563271\n",
      "[39]\tvalid_0's multi_logloss: 0.559678\n",
      "[40]\tvalid_0's multi_logloss: 0.554497\n",
      "[41]\tvalid_0's multi_logloss: 0.549866\n",
      "[42]\tvalid_0's multi_logloss: 0.546472\n",
      "[43]\tvalid_0's multi_logloss: 0.544807\n",
      "[44]\tvalid_0's multi_logloss: 0.543454\n",
      "[45]\tvalid_0's multi_logloss: 0.540525\n",
      "[46]\tvalid_0's multi_logloss: 0.536762\n",
      "[47]\tvalid_0's multi_logloss: 0.534274\n",
      "[48]\tvalid_0's multi_logloss: 0.533066\n",
      "[49]\tvalid_0's multi_logloss: 0.529903\n",
      "[50]\tvalid_0's multi_logloss: 0.52891\n",
      "[51]\tvalid_0's multi_logloss: 0.528636\n",
      "[52]\tvalid_0's multi_logloss: 0.525585\n",
      "[53]\tvalid_0's multi_logloss: 0.522779\n",
      "[54]\tvalid_0's multi_logloss: 0.523139\n",
      "[55]\tvalid_0's multi_logloss: 0.52258\n",
      "[56]\tvalid_0's multi_logloss: 0.521362\n",
      "[57]\tvalid_0's multi_logloss: 0.520577\n",
      "[58]\tvalid_0's multi_logloss: 0.521546\n",
      "[59]\tvalid_0's multi_logloss: 0.519061\n",
      "[60]\tvalid_0's multi_logloss: 0.519441\n",
      "[61]\tvalid_0's multi_logloss: 0.517731\n",
      "[62]\tvalid_0's multi_logloss: 0.517911\n",
      "[63]\tvalid_0's multi_logloss: 0.517542\n",
      "[64]\tvalid_0's multi_logloss: 0.517291\n",
      "[65]\tvalid_0's multi_logloss: 0.515649\n",
      "[66]\tvalid_0's multi_logloss: 0.513691\n",
      "[67]\tvalid_0's multi_logloss: 0.512932\n",
      "[68]\tvalid_0's multi_logloss: 0.511305\n",
      "[69]\tvalid_0's multi_logloss: 0.511691\n",
      "[70]\tvalid_0's multi_logloss: 0.509034\n",
      "[71]\tvalid_0's multi_logloss: 0.508058\n",
      "[72]\tvalid_0's multi_logloss: 0.50652\n",
      "[73]\tvalid_0's multi_logloss: 0.506099\n",
      "[74]\tvalid_0's multi_logloss: 0.505134\n",
      "[75]\tvalid_0's multi_logloss: 0.504918\n",
      "[76]\tvalid_0's multi_logloss: 0.503953\n",
      "[77]\tvalid_0's multi_logloss: 0.504323\n",
      "[78]\tvalid_0's multi_logloss: 0.506424\n",
      "[79]\tvalid_0's multi_logloss: 0.507708\n",
      "[80]\tvalid_0's multi_logloss: 0.506\n",
      "[81]\tvalid_0's multi_logloss: 0.507133\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 0.503953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    device = 'gpu'\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "\n",
    "# result append to list\n",
    "o.append(round(gbm.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "params = {}\n",
    "params['device'] = 'gpu'\n",
    "params['gpu_id'] = 1\n",
    "params['updater'] = 'grow_gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "o.append(round(model.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 3s 3ms/step - loss: 2.2147 - acc: 0.2507 - val_loss: 1.6337 - val_acc: 0.2619\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 1s 869us/step - loss: 1.8679 - acc: 0.3254 - val_loss: 1.7067 - val_acc: 0.2708\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 1s 898us/step - loss: 1.8764 - acc: 0.3276 - val_loss: 1.6233 - val_acc: 0.2827\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 1s 917us/step - loss: 1.7233 - acc: 0.3575 - val_loss: 1.5004 - val_acc: 0.3065\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 1s 918us/step - loss: 1.6823 - acc: 0.3657 - val_loss: 1.4325 - val_acc: 0.2887\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 1s 865us/step - loss: 1.6049 - acc: 0.3866 - val_loss: 1.4134 - val_acc: 0.3333\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 1s 906us/step - loss: 1.5064 - acc: 0.3888 - val_loss: 1.3960 - val_acc: 0.3482\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 1s 881us/step - loss: 1.5087 - acc: 0.4015 - val_loss: 1.3744 - val_acc: 0.4018\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 1s 872us/step - loss: 1.4192 - acc: 0.4306 - val_loss: 1.3756 - val_acc: 0.3750\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 1s 866us/step - loss: 1.3760 - acc: 0.4649 - val_loss: 1.3822 - val_acc: 0.3542\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 1s 869us/step - loss: 1.2615 - acc: 0.5082 - val_loss: 1.4059 - val_acc: 0.3661\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 1s 944us/step - loss: 1.2047 - acc: 0.5246 - val_loss: 1.4095 - val_acc: 0.3571\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 1s 907us/step - loss: 1.1176 - acc: 0.5530 - val_loss: 1.4080 - val_acc: 0.3452\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 1s 903us/step - loss: 1.0618 - acc: 0.5881 - val_loss: 1.4044 - val_acc: 0.3780\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 1s 870us/step - loss: 0.9806 - acc: 0.6142 - val_loss: 1.4043 - val_acc: 0.4077\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 1s 902us/step - loss: 0.8768 - acc: 0.6679 - val_loss: 1.4317 - val_acc: 0.4167\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 1s 932us/step - loss: 0.8284 - acc: 0.6694 - val_loss: 1.4516 - val_acc: 0.4524\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 1s 885us/step - loss: 0.7698 - acc: 0.6993 - val_loss: 1.4883 - val_acc: 0.4792\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 1s 895us/step - loss: 0.6777 - acc: 0.7463 - val_loss: 1.5432 - val_acc: 0.4494\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 1s 875us/step - loss: 0.6390 - acc: 0.7619 - val_loss: 1.5849 - val_acc: 0.4315\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 1s 883us/step - loss: 0.5506 - acc: 0.7910 - val_loss: 1.6187 - val_acc: 0.4405\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 1s 864us/step - loss: 0.5238 - acc: 0.8209 - val_loss: 1.6410 - val_acc: 0.4673\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 1s 858us/step - loss: 0.4709 - acc: 0.8373 - val_loss: 1.6833 - val_acc: 0.4762\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 1s 876us/step - loss: 0.3877 - acc: 0.8664 - val_loss: 1.7613 - val_acc: 0.4851\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 1s 877us/step - loss: 0.3463 - acc: 0.8776 - val_loss: 1.8449 - val_acc: 0.4762\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 1s 866us/step - loss: 0.2977 - acc: 0.8910 - val_loss: 1.9373 - val_acc: 0.4702\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 1s 890us/step - loss: 0.2833 - acc: 0.9104 - val_loss: 2.0227 - val_acc: 0.4643\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 1s 885us/step - loss: 0.2382 - acc: 0.9142 - val_loss: 2.1157 - val_acc: 0.4821\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "start = time.time()\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "o.append(model.evaluate(X_test, y_test_for_keras, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    g, \n",
    "    columns=['Random Forest', 'LightGBM', 'XGBoost','Keras'], \n",
    "    index=['HCD35', 'HCD45', 'HCD65']\n",
    ").to_csv('../result/norm_pos.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
