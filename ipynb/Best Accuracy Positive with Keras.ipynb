{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, GaussianNoise, GaussianDropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, Nadam, Adamax\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from  keras.regularizers import l1, l2\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\", \n",
    "        allow_growth=True,\n",
    "#         per_process_gpu_memory_fraction=0.5\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('../data/feature_importance_pos.csv', index_col=0)\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 SGD 0.3244047619047619\n",
      "128 RMSprop 0.7083333333333334\n",
      "128 Adagrad 0.6071428571428571\n",
      "128 Adadelta 0.5505952380952381\n",
      "128 Adam 0.5863095238095238\n",
      "128 Adamax 0.4375\n",
      "128 Nadam 0.6577380952380952\n",
      "256 SGD 0.4166666666666667\n",
      "256 RMSprop 0.6696428571428571\n",
      "256 Adagrad 0.6904761904761905\n",
      "256 Adadelta 0.6309523809523809\n",
      "256 Adam 0.6726190476190477\n",
      "256 Adamax 0.5297619047619048\n",
      "256 Nadam 0.6339285714285714\n",
      "512 SGD 0.39880952380952384\n",
      "512 RMSprop 0.6011904761904762\n",
      "512 Adagrad 0.6636904761904762\n",
      "512 Adadelta 0.6488095238095238\n",
      "512 Adam 0.6815476190476191\n",
      "512 Adamax 0.6607142857142857\n",
      "512 Nadam 0.6964285714285714\n"
     ]
    }
   ],
   "source": [
    "# gridsearch\n",
    "for i in [128, 256, 512]:  # layer\n",
    "    for p in ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']:  # optimizers\n",
    "        for m in ['softmax','softplus','softsign','relu','tanh','sigmoid','hard_sigmoid','linear']:  # activations\n",
    "            tf.set_random_seed(42)\n",
    "\n",
    "            # make keras model\n",
    "            start = time.time()\n",
    "            inputs = Input(shape=(X_train.shape[1],))\n",
    "            x = Dense(i, activation=m)(inputs)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "            x = Dense(i, activation=m)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "            x = Dense(i, activation=m)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "            x = Dense(i, activation=m)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "            predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "            model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "            # compile\n",
    "            model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=p,\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            epochs = 100\n",
    "            batch_size = 1000\n",
    "            es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train,\n",
    "                y_train_for_keras,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(X_test, y_test_for_keras),\n",
    "                verbose=0,\n",
    "                callbacks=[\n",
    "                    es,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            print(i, p, model.evaluate(X_test, y_test_for_keras, verbose=0)[1])\n",
    "\n",
    "            if model.evaluate(X_test, y_test_for_keras, verbose=0)[1] > load_model('../model/Keras_fs_pos.h5').evaluate(X_test, y_test_for_keras, verbose=0)[1]:\n",
    "                model.save('../model/Keras_fs_pos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 5s 4ms/step - loss: 1.9250 - acc: 0.2440 - val_loss: 1.4684 - val_acc: 0.2887\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 0s 100us/step - loss: 1.7934 - acc: 0.2560 - val_loss: 1.4713 - val_acc: 0.2798\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.6911 - acc: 0.2970 - val_loss: 1.3848 - val_acc: 0.3036\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 0s 90us/step - loss: 1.5790 - acc: 0.2903 - val_loss: 1.3398 - val_acc: 0.3036\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 0s 89us/step - loss: 1.5932 - acc: 0.3112 - val_loss: 1.2824 - val_acc: 0.3333\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 1.5472 - acc: 0.3231 - val_loss: 1.2621 - val_acc: 0.3363\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 1.4306 - acc: 0.3433 - val_loss: 1.2563 - val_acc: 0.3393\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.4954 - acc: 0.3448 - val_loss: 1.2529 - val_acc: 0.3393\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 0s 99us/step - loss: 1.5605 - acc: 0.3448 - val_loss: 1.2508 - val_acc: 0.3363\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 0s 88us/step - loss: 1.4980 - acc: 0.3597 - val_loss: 1.2434 - val_acc: 0.3393\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 0s 92us/step - loss: 1.4523 - acc: 0.3515 - val_loss: 1.2399 - val_acc: 0.3452\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 0s 88us/step - loss: 1.3807 - acc: 0.3731 - val_loss: 1.2409 - val_acc: 0.3810\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.3833 - acc: 0.3731 - val_loss: 1.2372 - val_acc: 0.4256\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 0s 98us/step - loss: 1.3892 - acc: 0.3851 - val_loss: 1.2312 - val_acc: 0.4048\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 0s 103us/step - loss: 1.3583 - acc: 0.3918 - val_loss: 1.2257 - val_acc: 0.4048\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 0s 105us/step - loss: 1.3829 - acc: 0.3828 - val_loss: 1.2199 - val_acc: 0.4077\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.2744 - acc: 0.4075 - val_loss: 1.2127 - val_acc: 0.4137\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.2715 - acc: 0.4090 - val_loss: 1.2037 - val_acc: 0.4345\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 0s 95us/step - loss: 1.3023 - acc: 0.4000 - val_loss: 1.1950 - val_acc: 0.4554\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 1.2818 - acc: 0.4149 - val_loss: 1.1863 - val_acc: 0.4643\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 1.2974 - acc: 0.4067 - val_loss: 1.1787 - val_acc: 0.4583\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 0s 97us/step - loss: 1.2624 - acc: 0.4343 - val_loss: 1.1706 - val_acc: 0.4702\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 1.3037 - acc: 0.4216 - val_loss: 1.1625 - val_acc: 0.4673\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 1.2430 - acc: 0.4410 - val_loss: 1.1557 - val_acc: 0.4673\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 1.2387 - acc: 0.4418 - val_loss: 1.1488 - val_acc: 0.4732\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.1937 - acc: 0.4485 - val_loss: 1.1427 - val_acc: 0.4732\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 0s 98us/step - loss: 1.2252 - acc: 0.4299 - val_loss: 1.1361 - val_acc: 0.4911\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 0s 89us/step - loss: 1.2100 - acc: 0.4470 - val_loss: 1.1306 - val_acc: 0.4881\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 0s 88us/step - loss: 1.1953 - acc: 0.4522 - val_loss: 1.1259 - val_acc: 0.4940\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 1.1802 - acc: 0.4694 - val_loss: 1.1226 - val_acc: 0.4940\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 0s 98us/step - loss: 1.1897 - acc: 0.4716 - val_loss: 1.1202 - val_acc: 0.4732\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 0s 90us/step - loss: 1.1783 - acc: 0.4687 - val_loss: 1.1156 - val_acc: 0.4702\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 0s 97us/step - loss: 1.1583 - acc: 0.4806 - val_loss: 1.1094 - val_acc: 0.4851\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 1.1766 - acc: 0.4724 - val_loss: 1.1030 - val_acc: 0.4881\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 0s 97us/step - loss: 1.1035 - acc: 0.4918 - val_loss: 1.0964 - val_acc: 0.5030\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 1.0996 - acc: 0.4963 - val_loss: 1.0904 - val_acc: 0.5149\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 0s 95us/step - loss: 1.1735 - acc: 0.4925 - val_loss: 1.0820 - val_acc: 0.5327\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 1.0994 - acc: 0.4963 - val_loss: 1.0736 - val_acc: 0.5536\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 1.0941 - acc: 0.5149 - val_loss: 1.0674 - val_acc: 0.5506\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 0s 98us/step - loss: 1.1103 - acc: 0.5037 - val_loss: 1.0595 - val_acc: 0.5387\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.0872 - acc: 0.5097 - val_loss: 1.0508 - val_acc: 0.5119\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 0s 99us/step - loss: 1.1096 - acc: 0.5157 - val_loss: 1.0433 - val_acc: 0.5149\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 1.1049 - acc: 0.5037 - val_loss: 1.0353 - val_acc: 0.5327\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 1.0963 - acc: 0.5201 - val_loss: 1.0289 - val_acc: 0.5417\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 0s 88us/step - loss: 1.0348 - acc: 0.5604 - val_loss: 1.0235 - val_acc: 0.5565\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 0s 89us/step - loss: 1.0487 - acc: 0.5164 - val_loss: 1.0193 - val_acc: 0.5625\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.0350 - acc: 0.5478 - val_loss: 1.0162 - val_acc: 0.5774\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 1.0456 - acc: 0.5343 - val_loss: 1.0142 - val_acc: 0.6220\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.0423 - acc: 0.5358 - val_loss: 1.0134 - val_acc: 0.5804\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 0s 98us/step - loss: 1.0227 - acc: 0.5590 - val_loss: 1.0119 - val_acc: 0.5625\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 1.0256 - acc: 0.5276 - val_loss: 1.0078 - val_acc: 0.5536\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 0s 98us/step - loss: 0.9979 - acc: 0.5604 - val_loss: 1.0028 - val_acc: 0.5476\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 0s 90us/step - loss: 0.9832 - acc: 0.5567 - val_loss: 0.9970 - val_acc: 0.5327\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 0.9641 - acc: 0.5582 - val_loss: 0.9909 - val_acc: 0.5387\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 0.9549 - acc: 0.5590 - val_loss: 0.9865 - val_acc: 0.5476\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 0s 98us/step - loss: 0.9503 - acc: 0.5858 - val_loss: 0.9809 - val_acc: 0.5625\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 0s 100us/step - loss: 0.9560 - acc: 0.5634 - val_loss: 0.9745 - val_acc: 0.5774\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 0s 100us/step - loss: 0.9426 - acc: 0.5866 - val_loss: 0.9682 - val_acc: 0.5774\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 0.9478 - acc: 0.5813 - val_loss: 0.9628 - val_acc: 0.5804\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 0s 96us/step - loss: 0.9442 - acc: 0.5828 - val_loss: 0.9573 - val_acc: 0.5804\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 0.9051 - acc: 0.5955 - val_loss: 0.9511 - val_acc: 0.5923\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 0s 97us/step - loss: 0.8962 - acc: 0.6030 - val_loss: 0.9444 - val_acc: 0.6071\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 0s 97us/step - loss: 0.8827 - acc: 0.6045 - val_loss: 0.9391 - val_acc: 0.6131\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 0.8771 - acc: 0.6127 - val_loss: 0.9348 - val_acc: 0.6042\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 0s 95us/step - loss: 0.8820 - acc: 0.6097 - val_loss: 0.9313 - val_acc: 0.6071\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 0s 112us/step - loss: 0.8718 - acc: 0.6090 - val_loss: 0.9275 - val_acc: 0.6101\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 0s 103us/step - loss: 0.8669 - acc: 0.6157 - val_loss: 0.9240 - val_acc: 0.6071\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 0s 107us/step - loss: 0.8762 - acc: 0.6082 - val_loss: 0.9208 - val_acc: 0.6042\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 0s 102us/step - loss: 0.8395 - acc: 0.6231 - val_loss: 0.9151 - val_acc: 0.6101\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 0s 112us/step - loss: 0.8389 - acc: 0.6231 - val_loss: 0.9082 - val_acc: 0.6131\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 0s 107us/step - loss: 0.8621 - acc: 0.6336 - val_loss: 0.9036 - val_acc: 0.6161\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 0s 108us/step - loss: 0.8254 - acc: 0.6336 - val_loss: 0.9014 - val_acc: 0.6250\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 0s 100us/step - loss: 0.8294 - acc: 0.6306 - val_loss: 0.9011 - val_acc: 0.6339\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 0s 104us/step - loss: 0.8593 - acc: 0.6142 - val_loss: 0.8996 - val_acc: 0.6339\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 0s 102us/step - loss: 0.7944 - acc: 0.6582 - val_loss: 0.8986 - val_acc: 0.6190\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 0s 100us/step - loss: 0.8046 - acc: 0.6493 - val_loss: 0.8973 - val_acc: 0.6161\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 0.7723 - acc: 0.6672 - val_loss: 0.8956 - val_acc: 0.6101\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 0s 89us/step - loss: 0.7864 - acc: 0.6627 - val_loss: 0.8937 - val_acc: 0.6042\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 0s 95us/step - loss: 0.7823 - acc: 0.6716 - val_loss: 0.8911 - val_acc: 0.6131\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 0s 96us/step - loss: 0.7466 - acc: 0.6627 - val_loss: 0.8872 - val_acc: 0.6280\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 0.7399 - acc: 0.6761 - val_loss: 0.8815 - val_acc: 0.6339\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 0.7513 - acc: 0.6709 - val_loss: 0.8756 - val_acc: 0.6429\n",
      "Epoch 83/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 0.7176 - acc: 0.6866 - val_loss: 0.8701 - val_acc: 0.6429\n",
      "Epoch 84/100\n",
      "1340/1340 [==============================] - 0s 90us/step - loss: 0.7440 - acc: 0.6746 - val_loss: 0.8635 - val_acc: 0.6488\n",
      "Epoch 85/100\n",
      "1340/1340 [==============================] - 0s 89us/step - loss: 0.7402 - acc: 0.6754 - val_loss: 0.8609 - val_acc: 0.6518\n",
      "Epoch 86/100\n",
      "1340/1340 [==============================] - 0s 90us/step - loss: 0.7444 - acc: 0.6709 - val_loss: 0.8615 - val_acc: 0.6399\n",
      "Epoch 87/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 0.6957 - acc: 0.7134 - val_loss: 0.8578 - val_acc: 0.6339\n",
      "Epoch 88/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 0.6785 - acc: 0.7060 - val_loss: 0.8529 - val_acc: 0.6220\n",
      "Epoch 89/100\n",
      "1340/1340 [==============================] - 0s 97us/step - loss: 0.7102 - acc: 0.6843 - val_loss: 0.8493 - val_acc: 0.6161\n",
      "Epoch 90/100\n",
      "1340/1340 [==============================] - 0s 97us/step - loss: 0.6667 - acc: 0.7179 - val_loss: 0.8465 - val_acc: 0.6101\n",
      "Epoch 91/100\n",
      "1340/1340 [==============================] - 0s 94us/step - loss: 0.6557 - acc: 0.7194 - val_loss: 0.8417 - val_acc: 0.6190\n",
      "Epoch 92/100\n",
      "1340/1340 [==============================] - 0s 89us/step - loss: 0.6610 - acc: 0.7187 - val_loss: 0.8372 - val_acc: 0.6250\n",
      "Epoch 93/100\n",
      "1340/1340 [==============================] - 0s 95us/step - loss: 0.6640 - acc: 0.7164 - val_loss: 0.8359 - val_acc: 0.6339\n",
      "Epoch 94/100\n",
      "1340/1340 [==============================] - 0s 88us/step - loss: 0.6618 - acc: 0.7194 - val_loss: 0.8334 - val_acc: 0.6339\n",
      "Epoch 95/100\n",
      "1340/1340 [==============================] - 0s 93us/step - loss: 0.6498 - acc: 0.7254 - val_loss: 0.8294 - val_acc: 0.6369\n",
      "Epoch 96/100\n",
      "1340/1340 [==============================] - 0s 101us/step - loss: 0.6443 - acc: 0.7187 - val_loss: 0.8236 - val_acc: 0.6488\n",
      "Epoch 97/100\n",
      "1340/1340 [==============================] - 0s 100us/step - loss: 0.6145 - acc: 0.7336 - val_loss: 0.8188 - val_acc: 0.6756\n",
      "Epoch 98/100\n",
      "1340/1340 [==============================] - 0s 101us/step - loss: 0.6355 - acc: 0.7343 - val_loss: 0.8144 - val_acc: 0.7054\n",
      "Epoch 99/100\n",
      "1340/1340 [==============================] - 0s 97us/step - loss: 0.6232 - acc: 0.7455 - val_loss: 0.8107 - val_acc: 0.7083\n",
      "Epoch 100/100\n",
      "1340/1340 [==============================] - 0s 92us/step - loss: 0.6289 - acc: 0.7328 - val_loss: 0.8097 - val_acc: 0.7083\n"
     ]
    }
   ],
   "source": [
    "# tf.set_random_seed(42)\n",
    "\n",
    "# # make keras model\n",
    "# start = time.time()\n",
    "# inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# x = Dense(512, activation='relu')(inputs)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# predictions = Dense(\n",
    "#     len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "# model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# # compile\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy',\n",
    "#     optimizer=Adamax(),\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# epochs = 100\n",
    "# batch_size = 1000\n",
    "# es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train_for_keras,\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     validation_data=(X_test, y_test_for_keras),\n",
    "#     verbose=1,\n",
    "#     callbacks=[\n",
    "#         es,\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.save('../model/Keras_fs_pos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
