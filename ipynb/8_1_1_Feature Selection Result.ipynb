{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### reproducibility for Keras\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(7)\n",
    "rn.seed(7)\n",
    "\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1,\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\", \n",
    "        allow_growth=True,\n",
    "#         per_process_gpu_memory_fraction=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(7)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "##### Import some librarys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, GaussianNoise, GaussianDropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from  keras.regularizers import l1, l2\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('../data/feature_selection_positive.csv')\n",
    "\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit\n",
    "clf = rf()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "t = []\n",
    "t.append(round(clf.score(X_test, y_test)*100, 2))\n",
    "pickle.dump(clf, open('../model/rf_pos_fs.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.29099\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.21112\n",
      "[3]\tvalid_0's multi_logloss: 1.14382\n",
      "[4]\tvalid_0's multi_logloss: 1.0832\n",
      "[5]\tvalid_0's multi_logloss: 1.02917\n",
      "[6]\tvalid_0's multi_logloss: 0.982285\n",
      "[7]\tvalid_0's multi_logloss: 0.939476\n",
      "[8]\tvalid_0's multi_logloss: 0.902268\n",
      "[9]\tvalid_0's multi_logloss: 0.869022\n",
      "[10]\tvalid_0's multi_logloss: 0.838978\n",
      "[11]\tvalid_0's multi_logloss: 0.811207\n",
      "[12]\tvalid_0's multi_logloss: 0.784389\n",
      "[13]\tvalid_0's multi_logloss: 0.761399\n",
      "[14]\tvalid_0's multi_logloss: 0.739735\n",
      "[15]\tvalid_0's multi_logloss: 0.720263\n",
      "[16]\tvalid_0's multi_logloss: 0.702614\n",
      "[17]\tvalid_0's multi_logloss: 0.682459\n",
      "[18]\tvalid_0's multi_logloss: 0.667015\n",
      "[19]\tvalid_0's multi_logloss: 0.650877\n",
      "[20]\tvalid_0's multi_logloss: 0.637697\n",
      "[21]\tvalid_0's multi_logloss: 0.625049\n",
      "[22]\tvalid_0's multi_logloss: 0.610747\n",
      "[23]\tvalid_0's multi_logloss: 0.598023\n",
      "[24]\tvalid_0's multi_logloss: 0.586897\n",
      "[25]\tvalid_0's multi_logloss: 0.575418\n",
      "[26]\tvalid_0's multi_logloss: 0.56474\n",
      "[27]\tvalid_0's multi_logloss: 0.556823\n",
      "[28]\tvalid_0's multi_logloss: 0.548267\n",
      "[29]\tvalid_0's multi_logloss: 0.53965\n",
      "[30]\tvalid_0's multi_logloss: 0.532279\n",
      "[31]\tvalid_0's multi_logloss: 0.525444\n",
      "[32]\tvalid_0's multi_logloss: 0.520452\n",
      "[33]\tvalid_0's multi_logloss: 0.515451\n",
      "[34]\tvalid_0's multi_logloss: 0.508334\n",
      "[35]\tvalid_0's multi_logloss: 0.502709\n",
      "[36]\tvalid_0's multi_logloss: 0.498747\n",
      "[37]\tvalid_0's multi_logloss: 0.49451\n",
      "[38]\tvalid_0's multi_logloss: 0.489705\n",
      "[39]\tvalid_0's multi_logloss: 0.485485\n",
      "[40]\tvalid_0's multi_logloss: 0.481227\n",
      "[41]\tvalid_0's multi_logloss: 0.47667\n",
      "[42]\tvalid_0's multi_logloss: 0.475194\n",
      "[43]\tvalid_0's multi_logloss: 0.474003\n",
      "[44]\tvalid_0's multi_logloss: 0.471756\n",
      "[45]\tvalid_0's multi_logloss: 0.469968\n",
      "[46]\tvalid_0's multi_logloss: 0.465753\n",
      "[47]\tvalid_0's multi_logloss: 0.46255\n",
      "[48]\tvalid_0's multi_logloss: 0.45893\n",
      "[49]\tvalid_0's multi_logloss: 0.455197\n",
      "[50]\tvalid_0's multi_logloss: 0.454486\n",
      "[51]\tvalid_0's multi_logloss: 0.454999\n",
      "[52]\tvalid_0's multi_logloss: 0.451936\n",
      "[53]\tvalid_0's multi_logloss: 0.450261\n",
      "[54]\tvalid_0's multi_logloss: 0.447788\n",
      "[55]\tvalid_0's multi_logloss: 0.444263\n",
      "[56]\tvalid_0's multi_logloss: 0.442964\n",
      "[57]\tvalid_0's multi_logloss: 0.441569\n",
      "[58]\tvalid_0's multi_logloss: 0.440478\n",
      "[59]\tvalid_0's multi_logloss: 0.439564\n",
      "[60]\tvalid_0's multi_logloss: 0.43765\n",
      "[61]\tvalid_0's multi_logloss: 0.437258\n",
      "[62]\tvalid_0's multi_logloss: 0.435878\n",
      "[63]\tvalid_0's multi_logloss: 0.434835\n",
      "[64]\tvalid_0's multi_logloss: 0.434072\n",
      "[65]\tvalid_0's multi_logloss: 0.433765\n",
      "[66]\tvalid_0's multi_logloss: 0.433802\n",
      "[67]\tvalid_0's multi_logloss: 0.433107\n",
      "[68]\tvalid_0's multi_logloss: 0.432523\n",
      "[69]\tvalid_0's multi_logloss: 0.432907\n",
      "[70]\tvalid_0's multi_logloss: 0.430747\n",
      "[71]\tvalid_0's multi_logloss: 0.431061\n",
      "[72]\tvalid_0's multi_logloss: 0.429249\n",
      "[73]\tvalid_0's multi_logloss: 0.428076\n",
      "[74]\tvalid_0's multi_logloss: 0.427967\n",
      "[75]\tvalid_0's multi_logloss: 0.430413\n",
      "[76]\tvalid_0's multi_logloss: 0.431572\n",
      "[77]\tvalid_0's multi_logloss: 0.430495\n",
      "[78]\tvalid_0's multi_logloss: 0.431871\n",
      "[79]\tvalid_0's multi_logloss: 0.432616\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_logloss: 0.427967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    device = 'gpu'\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "pickle.dump(gbm, open('../model/lgbm_pos_fs.sav', 'wb'))\n",
    "# result append to list\n",
    "t.append(round(gbm.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "params = {}\n",
    "params['device'] = 'gpu'\n",
    "params['gpu_id'] = 1\n",
    "params['updater'] = 'grow_gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "pickle.dump(model, open('../model/xgb_pos_fs.sav', 'wb'))\n",
    "t.append(round(model.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1340 samples, validate on 336 samples\n",
      "Epoch 1/100\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.8700 - acc: 0.2507 - val_loss: 1.4152 - val_acc: 0.3155\n",
      "Epoch 2/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 1.7653 - acc: 0.2582 - val_loss: 1.3522 - val_acc: 0.2976\n",
      "Epoch 3/100\n",
      "1340/1340 [==============================] - 0s 67us/step - loss: 1.6996 - acc: 0.2813 - val_loss: 1.3382 - val_acc: 0.2887\n",
      "Epoch 4/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 1.6141 - acc: 0.2985 - val_loss: 1.3362 - val_acc: 0.2976\n",
      "Epoch 5/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 1.5480 - acc: 0.3075 - val_loss: 1.3222 - val_acc: 0.3065\n",
      "Epoch 6/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 1.5700 - acc: 0.3299 - val_loss: 1.3119 - val_acc: 0.3214\n",
      "Epoch 7/100\n",
      "1340/1340 [==============================] - 0s 67us/step - loss: 1.5446 - acc: 0.3209 - val_loss: 1.2941 - val_acc: 0.4286\n",
      "Epoch 8/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 1.5496 - acc: 0.3328 - val_loss: 1.2672 - val_acc: 0.4256\n",
      "Epoch 9/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 1.5117 - acc: 0.3418 - val_loss: 1.2500 - val_acc: 0.4196\n",
      "Epoch 10/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 1.4626 - acc: 0.3448 - val_loss: 1.2299 - val_acc: 0.4405\n",
      "Epoch 11/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 1.4028 - acc: 0.3627 - val_loss: 1.2163 - val_acc: 0.4435\n",
      "Epoch 12/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.3644 - acc: 0.3836 - val_loss: 1.2061 - val_acc: 0.5536\n",
      "Epoch 13/100\n",
      "1340/1340 [==============================] - 0s 67us/step - loss: 1.3534 - acc: 0.3940 - val_loss: 1.2001 - val_acc: 0.4673\n",
      "Epoch 14/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 1.3120 - acc: 0.3918 - val_loss: 1.1944 - val_acc: 0.4524\n",
      "Epoch 15/100\n",
      "1340/1340 [==============================] - 0s 86us/step - loss: 1.3228 - acc: 0.4030 - val_loss: 1.1901 - val_acc: 0.4405\n",
      "Epoch 16/100\n",
      "1340/1340 [==============================] - 0s 84us/step - loss: 1.2804 - acc: 0.4127 - val_loss: 1.1826 - val_acc: 0.4583\n",
      "Epoch 17/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 1.3250 - acc: 0.3843 - val_loss: 1.1758 - val_acc: 0.4643\n",
      "Epoch 18/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 1.2540 - acc: 0.4410 - val_loss: 1.1649 - val_acc: 0.5238\n",
      "Epoch 19/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.2344 - acc: 0.4328 - val_loss: 1.1559 - val_acc: 0.5030\n",
      "Epoch 20/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 1.2179 - acc: 0.4560 - val_loss: 1.1468 - val_acc: 0.4702\n",
      "Epoch 21/100\n",
      "1340/1340 [==============================] - 0s 68us/step - loss: 1.2227 - acc: 0.4724 - val_loss: 1.1417 - val_acc: 0.4524\n",
      "Epoch 22/100\n",
      "1340/1340 [==============================] - 0s 69us/step - loss: 1.1984 - acc: 0.4612 - val_loss: 1.1346 - val_acc: 0.4554\n",
      "Epoch 23/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 1.2089 - acc: 0.4582 - val_loss: 1.1282 - val_acc: 0.4613\n",
      "Epoch 24/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.1637 - acc: 0.5000 - val_loss: 1.1188 - val_acc: 0.4702\n",
      "Epoch 25/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 1.1362 - acc: 0.4881 - val_loss: 1.1061 - val_acc: 0.5030\n",
      "Epoch 26/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 1.1240 - acc: 0.4963 - val_loss: 1.0932 - val_acc: 0.5357\n",
      "Epoch 27/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 1.1194 - acc: 0.5127 - val_loss: 1.0823 - val_acc: 0.5387\n",
      "Epoch 28/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 1.0968 - acc: 0.5060 - val_loss: 1.0723 - val_acc: 0.5327\n",
      "Epoch 29/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 1.0987 - acc: 0.5157 - val_loss: 1.0630 - val_acc: 0.5476\n",
      "Epoch 30/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 1.0735 - acc: 0.5187 - val_loss: 1.0543 - val_acc: 0.5565\n",
      "Epoch 31/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 1.0488 - acc: 0.5179 - val_loss: 1.0462 - val_acc: 0.5595\n",
      "Epoch 32/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 1.0573 - acc: 0.5254 - val_loss: 1.0370 - val_acc: 0.5685\n",
      "Epoch 33/100\n",
      "1340/1340 [==============================] - 0s 81us/step - loss: 1.0293 - acc: 0.5448 - val_loss: 1.0281 - val_acc: 0.5744\n",
      "Epoch 34/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 1.0480 - acc: 0.5231 - val_loss: 1.0214 - val_acc: 0.5685\n",
      "Epoch 35/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.9915 - acc: 0.5470 - val_loss: 1.0190 - val_acc: 0.5446\n",
      "Epoch 36/100\n",
      "1340/1340 [==============================] - 0s 98us/step - loss: 0.9933 - acc: 0.5537 - val_loss: 1.0104 - val_acc: 0.5476\n",
      "Epoch 37/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.9695 - acc: 0.5590 - val_loss: 1.0005 - val_acc: 0.5595\n",
      "Epoch 38/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.9331 - acc: 0.6067 - val_loss: 0.9907 - val_acc: 0.5506\n",
      "Epoch 39/100\n",
      "1340/1340 [==============================] - 0s 82us/step - loss: 0.9080 - acc: 0.5896 - val_loss: 0.9780 - val_acc: 0.5625\n",
      "Epoch 40/100\n",
      "1340/1340 [==============================] - 0s 68us/step - loss: 0.9940 - acc: 0.5799 - val_loss: 0.9660 - val_acc: 0.5923\n",
      "Epoch 41/100\n",
      "1340/1340 [==============================] - 0s 78us/step - loss: 0.9224 - acc: 0.5843 - val_loss: 0.9567 - val_acc: 0.6310\n",
      "Epoch 42/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.9199 - acc: 0.5813 - val_loss: 0.9488 - val_acc: 0.6250\n",
      "Epoch 43/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.9058 - acc: 0.6022 - val_loss: 0.9421 - val_acc: 0.6131\n",
      "Epoch 44/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.8603 - acc: 0.6142 - val_loss: 0.9376 - val_acc: 0.5863\n",
      "Epoch 45/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.8692 - acc: 0.6164 - val_loss: 0.9378 - val_acc: 0.5804\n",
      "Epoch 46/100\n",
      "1340/1340 [==============================] - 0s 80us/step - loss: 0.8518 - acc: 0.6157 - val_loss: 0.9410 - val_acc: 0.5714\n",
      "Epoch 47/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.8447 - acc: 0.6433 - val_loss: 0.9427 - val_acc: 0.5655\n",
      "Epoch 48/100\n",
      "1340/1340 [==============================] - 0s 67us/step - loss: 0.8419 - acc: 0.6351 - val_loss: 0.9423 - val_acc: 0.5595\n",
      "Epoch 49/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.8071 - acc: 0.6537 - val_loss: 0.9356 - val_acc: 0.5952\n",
      "Epoch 50/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.8473 - acc: 0.6396 - val_loss: 0.9232 - val_acc: 0.6042\n",
      "Epoch 51/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.7814 - acc: 0.6642 - val_loss: 0.9113 - val_acc: 0.5952\n",
      "Epoch 52/100\n",
      "1340/1340 [==============================] - 0s 84us/step - loss: 0.7731 - acc: 0.6604 - val_loss: 0.9015 - val_acc: 0.5923\n",
      "Epoch 53/100\n",
      "1340/1340 [==============================] - 0s 81us/step - loss: 0.7423 - acc: 0.6701 - val_loss: 0.8959 - val_acc: 0.5952\n",
      "Epoch 54/100\n",
      "1340/1340 [==============================] - 0s 85us/step - loss: 0.7453 - acc: 0.6701 - val_loss: 0.8909 - val_acc: 0.5893\n",
      "Epoch 55/100\n",
      "1340/1340 [==============================] - 0s 79us/step - loss: 0.7452 - acc: 0.6918 - val_loss: 0.8834 - val_acc: 0.5923\n",
      "Epoch 56/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.7367 - acc: 0.6903 - val_loss: 0.8738 - val_acc: 0.6369\n",
      "Epoch 57/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.7312 - acc: 0.6955 - val_loss: 0.8676 - val_acc: 0.6548\n",
      "Epoch 58/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.6539 - acc: 0.7231 - val_loss: 0.8652 - val_acc: 0.6696\n",
      "Epoch 59/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.6646 - acc: 0.7216 - val_loss: 0.8641 - val_acc: 0.6845\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.6562 - acc: 0.7090 - val_loss: 0.8641 - val_acc: 0.6845\n",
      "Epoch 61/100\n",
      "1340/1340 [==============================] - 0s 89us/step - loss: 0.6338 - acc: 0.7396 - val_loss: 0.8670 - val_acc: 0.6786\n",
      "Epoch 62/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.6181 - acc: 0.7299 - val_loss: 0.8718 - val_acc: 0.6518\n",
      "Epoch 63/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.5973 - acc: 0.7418 - val_loss: 0.8769 - val_acc: 0.6548\n",
      "Epoch 64/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.6177 - acc: 0.7478 - val_loss: 0.8780 - val_acc: 0.6131\n",
      "Epoch 65/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.5866 - acc: 0.7552 - val_loss: 0.8833 - val_acc: 0.5893\n",
      "Epoch 66/100\n",
      "1340/1340 [==============================] - 0s 81us/step - loss: 0.5622 - acc: 0.7701 - val_loss: 0.8912 - val_acc: 0.5685\n",
      "Epoch 67/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.5543 - acc: 0.7739 - val_loss: 0.8898 - val_acc: 0.5685\n",
      "Epoch 68/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.5436 - acc: 0.7784 - val_loss: 0.8754 - val_acc: 0.5774\n",
      "Epoch 69/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.5224 - acc: 0.7888 - val_loss: 0.8617 - val_acc: 0.5923\n",
      "Epoch 70/100\n",
      "1340/1340 [==============================] - 0s 91us/step - loss: 0.5189 - acc: 0.7993 - val_loss: 0.8546 - val_acc: 0.6071\n",
      "Epoch 71/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.4801 - acc: 0.8097 - val_loss: 0.8522 - val_acc: 0.6190\n",
      "Epoch 72/100\n",
      "1340/1340 [==============================] - 0s 80us/step - loss: 0.4884 - acc: 0.8007 - val_loss: 0.8466 - val_acc: 0.6280\n",
      "Epoch 73/100\n",
      "1340/1340 [==============================] - 0s 79us/step - loss: 0.4997 - acc: 0.8187 - val_loss: 0.8374 - val_acc: 0.6488\n",
      "Epoch 74/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.4782 - acc: 0.8112 - val_loss: 0.8367 - val_acc: 0.6548\n",
      "Epoch 75/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.4452 - acc: 0.8261 - val_loss: 0.8353 - val_acc: 0.6488\n",
      "Epoch 76/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.4438 - acc: 0.8321 - val_loss: 0.8308 - val_acc: 0.6518\n",
      "Epoch 77/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.4249 - acc: 0.8343 - val_loss: 0.8268 - val_acc: 0.6458\n",
      "Epoch 78/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.4247 - acc: 0.8396 - val_loss: 0.8270 - val_acc: 0.6310\n",
      "Epoch 79/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.3951 - acc: 0.8396 - val_loss: 0.8316 - val_acc: 0.6220\n",
      "Epoch 80/100\n",
      "1340/1340 [==============================] - 0s 76us/step - loss: 0.4005 - acc: 0.8403 - val_loss: 0.8349 - val_acc: 0.6250\n",
      "Epoch 81/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.3926 - acc: 0.8507 - val_loss: 0.8390 - val_acc: 0.6250\n",
      "Epoch 82/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 0.3726 - acc: 0.8627 - val_loss: 0.8497 - val_acc: 0.6250\n",
      "Epoch 83/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.3791 - acc: 0.8530 - val_loss: 0.8558 - val_acc: 0.6220\n",
      "Epoch 84/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 0.3414 - acc: 0.8687 - val_loss: 0.8477 - val_acc: 0.6250\n",
      "Epoch 85/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.3582 - acc: 0.8582 - val_loss: 0.8331 - val_acc: 0.6429\n",
      "Epoch 86/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 0.3357 - acc: 0.8709 - val_loss: 0.8228 - val_acc: 0.6726\n",
      "Epoch 87/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.3382 - acc: 0.8679 - val_loss: 0.8240 - val_acc: 0.6815\n",
      "Epoch 88/100\n",
      "1340/1340 [==============================] - 0s 79us/step - loss: 0.3105 - acc: 0.8851 - val_loss: 0.8248 - val_acc: 0.6905\n",
      "Epoch 89/100\n",
      "1340/1340 [==============================] - 0s 78us/step - loss: 0.3249 - acc: 0.8821 - val_loss: 0.8221 - val_acc: 0.6905\n",
      "Epoch 90/100\n",
      "1340/1340 [==============================] - 0s 70us/step - loss: 0.3065 - acc: 0.8821 - val_loss: 0.8196 - val_acc: 0.6905\n",
      "Epoch 91/100\n",
      "1340/1340 [==============================] - 0s 75us/step - loss: 0.2620 - acc: 0.9067 - val_loss: 0.8245 - val_acc: 0.6696\n",
      "Epoch 92/100\n",
      "1340/1340 [==============================] - 0s 74us/step - loss: 0.3266 - acc: 0.8843 - val_loss: 0.8565 - val_acc: 0.6339\n",
      "Epoch 93/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 0.2705 - acc: 0.8993 - val_loss: 0.9164 - val_acc: 0.6012\n",
      "Epoch 94/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.2679 - acc: 0.8888 - val_loss: 0.9871 - val_acc: 0.5804\n",
      "Epoch 95/100\n",
      "1340/1340 [==============================] - 0s 73us/step - loss: 0.2857 - acc: 0.8910 - val_loss: 1.0267 - val_acc: 0.5714\n",
      "Epoch 96/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.2830 - acc: 0.8948 - val_loss: 1.0215 - val_acc: 0.5714\n",
      "Epoch 97/100\n",
      "1340/1340 [==============================] - 0s 78us/step - loss: 0.2563 - acc: 0.9067 - val_loss: 1.0010 - val_acc: 0.5774\n",
      "Epoch 98/100\n",
      "1340/1340 [==============================] - 0s 71us/step - loss: 0.2609 - acc: 0.9045 - val_loss: 0.9733 - val_acc: 0.5833\n",
      "Epoch 99/100\n",
      "1340/1340 [==============================] - 0s 77us/step - loss: 0.2504 - acc: 0.9104 - val_loss: 0.9478 - val_acc: 0.6042\n",
      "Epoch 100/100\n",
      "1340/1340 [==============================] - 0s 72us/step - loss: 0.2614 - acc: 0.9052 - val_loss: 0.9395 - val_acc: 0.6161\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_pos_fs.h5')\n",
    "t.append(round(model.evaluate(X_test, y_test_for_keras, verbose=0)[1]*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "f.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[71.43, 84.52, 81.25, 61.61]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df = pd.read_csv('../data/feature_selection_negative.csv')\n",
    "\n",
    "# divide objective and target\n",
    "objective = df.Subclass\n",
    "le = preprocessing.LabelEncoder()\n",
    "objective = le.fit_transform(objective)\n",
    "features = df.drop('Subclass', axis=1)\n",
    "\n",
    "# train test split\n",
    "random_state=np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    objective,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# transform  for keras's target label\n",
    "y_train_for_keras = np_utils.to_categorical(y_train)\n",
    "y_test_for_keras = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.21\n"
     ]
    }
   ],
   "source": [
    "# define and fit \n",
    "clf = rf()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "t = []\n",
    "t.append(round(clf.score(X_test, y_test)*100, 2))\n",
    "print(round(clf.score(X_test, y_test)*100, 2))\n",
    "pickle.dump(clf, open('../model/rf_ng_fs.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.31034\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.24189\n",
      "[3]\tvalid_0's multi_logloss: 1.18161\n",
      "[4]\tvalid_0's multi_logloss: 1.1357\n",
      "[5]\tvalid_0's multi_logloss: 1.08979\n",
      "[6]\tvalid_0's multi_logloss: 1.0541\n",
      "[7]\tvalid_0's multi_logloss: 1.01417\n",
      "[8]\tvalid_0's multi_logloss: 0.980564\n",
      "[9]\tvalid_0's multi_logloss: 0.95256\n",
      "[10]\tvalid_0's multi_logloss: 0.920911\n",
      "[11]\tvalid_0's multi_logloss: 0.898194\n",
      "[12]\tvalid_0's multi_logloss: 0.880716\n",
      "[13]\tvalid_0's multi_logloss: 0.856573\n",
      "[14]\tvalid_0's multi_logloss: 0.838118\n",
      "[15]\tvalid_0's multi_logloss: 0.821115\n",
      "[16]\tvalid_0's multi_logloss: 0.803997\n",
      "[17]\tvalid_0's multi_logloss: 0.788368\n",
      "[18]\tvalid_0's multi_logloss: 0.77776\n",
      "[19]\tvalid_0's multi_logloss: 0.766919\n",
      "[20]\tvalid_0's multi_logloss: 0.758397\n",
      "[21]\tvalid_0's multi_logloss: 0.749307\n",
      "[22]\tvalid_0's multi_logloss: 0.739203\n",
      "[23]\tvalid_0's multi_logloss: 0.733061\n",
      "[24]\tvalid_0's multi_logloss: 0.72484\n",
      "[25]\tvalid_0's multi_logloss: 0.720758\n",
      "[26]\tvalid_0's multi_logloss: 0.715925\n",
      "[27]\tvalid_0's multi_logloss: 0.710369\n",
      "[28]\tvalid_0's multi_logloss: 0.705516\n",
      "[29]\tvalid_0's multi_logloss: 0.704505\n",
      "[30]\tvalid_0's multi_logloss: 0.701383\n",
      "[31]\tvalid_0's multi_logloss: 0.699063\n",
      "[32]\tvalid_0's multi_logloss: 0.694421\n",
      "[33]\tvalid_0's multi_logloss: 0.687706\n",
      "[34]\tvalid_0's multi_logloss: 0.684572\n",
      "[35]\tvalid_0's multi_logloss: 0.682182\n",
      "[36]\tvalid_0's multi_logloss: 0.679916\n",
      "[37]\tvalid_0's multi_logloss: 0.676125\n",
      "[38]\tvalid_0's multi_logloss: 0.673024\n",
      "[39]\tvalid_0's multi_logloss: 0.669276\n",
      "[40]\tvalid_0's multi_logloss: 0.665214\n",
      "[41]\tvalid_0's multi_logloss: 0.664138\n",
      "[42]\tvalid_0's multi_logloss: 0.663451\n",
      "[43]\tvalid_0's multi_logloss: 0.66408\n",
      "[44]\tvalid_0's multi_logloss: 0.660228\n",
      "[45]\tvalid_0's multi_logloss: 0.658381\n",
      "[46]\tvalid_0's multi_logloss: 0.654898\n",
      "[47]\tvalid_0's multi_logloss: 0.654019\n",
      "[48]\tvalid_0's multi_logloss: 0.65185\n",
      "[49]\tvalid_0's multi_logloss: 0.649227\n",
      "[50]\tvalid_0's multi_logloss: 0.645333\n",
      "[51]\tvalid_0's multi_logloss: 0.643438\n",
      "[52]\tvalid_0's multi_logloss: 0.640734\n",
      "[53]\tvalid_0's multi_logloss: 0.640639\n",
      "[54]\tvalid_0's multi_logloss: 0.634972\n",
      "[55]\tvalid_0's multi_logloss: 0.634538\n",
      "[56]\tvalid_0's multi_logloss: 0.635857\n",
      "[57]\tvalid_0's multi_logloss: 0.640551\n",
      "[58]\tvalid_0's multi_logloss: 0.639147\n",
      "[59]\tvalid_0's multi_logloss: 0.641818\n",
      "[60]\tvalid_0's multi_logloss: 0.643934\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 0.634538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    device = 'gpu'\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "# pickle.dump(gbm, open('../model/lgbm_ng_fs.sav', 'wb'))\n",
    "# result append to list\n",
    "t.append(\n",
    "round(gbm.score(X_test, y_test)*100, 2)\n",
    ")\n",
    "pickle.dump(gbm, open('../model/lgbm_ng_fs.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "params = {}\n",
    "params['device'] = 'gpu'\n",
    "params['gpu_id'] = 1\n",
    "params['updater'] = 'grow_gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshitaka-i/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# define and fit \n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# result append to list\n",
    "t.append(round(model.score(X_test, y_test)*100, 2))\n",
    "pickle.dump(model, open('../model/xgb_ng_fs.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "373/373 [==============================] - 2s 4ms/step - loss: 2.1786 - acc: 0.2225 - val_loss: 1.3061 - val_acc: 0.4149\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 61us/step - loss: 1.9127 - acc: 0.2654 - val_loss: 1.3591 - val_acc: 0.4574\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 89us/step - loss: 1.8433 - acc: 0.3137 - val_loss: 1.5017 - val_acc: 0.4894\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 71us/step - loss: 1.6841 - acc: 0.3592 - val_loss: 1.6397 - val_acc: 0.5106\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 74us/step - loss: 1.6561 - acc: 0.3753 - val_loss: 1.6861 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 71us/step - loss: 1.7015 - acc: 0.3700 - val_loss: 1.6637 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 53us/step - loss: 1.6823 - acc: 0.3753 - val_loss: 1.5997 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 66us/step - loss: 1.5479 - acc: 0.4048 - val_loss: 1.4979 - val_acc: 0.5106\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 55us/step - loss: 1.4495 - acc: 0.4343 - val_loss: 1.3933 - val_acc: 0.5213\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 61us/step - loss: 1.4363 - acc: 0.4021 - val_loss: 1.2840 - val_acc: 0.5213\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 60us/step - loss: 1.5113 - acc: 0.4263 - val_loss: 1.1906 - val_acc: 0.5213\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 70us/step - loss: 1.3097 - acc: 0.4209 - val_loss: 1.1214 - val_acc: 0.5426\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 69us/step - loss: 1.3672 - acc: 0.4370 - val_loss: 1.0815 - val_acc: 0.5532\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 62us/step - loss: 1.4232 - acc: 0.4155 - val_loss: 1.0451 - val_acc: 0.5638\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 69us/step - loss: 1.3622 - acc: 0.4477 - val_loss: 1.0224 - val_acc: 0.5957\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 72us/step - loss: 1.2242 - acc: 0.4584 - val_loss: 1.0095 - val_acc: 0.6064\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 63us/step - loss: 1.2115 - acc: 0.4638 - val_loss: 0.9984 - val_acc: 0.6064\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 55us/step - loss: 1.2546 - acc: 0.4745 - val_loss: 0.9879 - val_acc: 0.6170\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 61us/step - loss: 1.2124 - acc: 0.5147 - val_loss: 0.9836 - val_acc: 0.6277\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 57us/step - loss: 1.1640 - acc: 0.4960 - val_loss: 0.9908 - val_acc: 0.6277\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 66us/step - loss: 1.1090 - acc: 0.5282 - val_loss: 1.0058 - val_acc: 0.6064\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 73us/step - loss: 1.1057 - acc: 0.5255 - val_loss: 1.0259 - val_acc: 0.6064\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 67us/step - loss: 1.1650 - acc: 0.5040 - val_loss: 1.0403 - val_acc: 0.6064\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 0s 53us/step - loss: 1.2057 - acc: 0.5040 - val_loss: 1.0581 - val_acc: 0.6064\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 47us/step - loss: 1.0252 - acc: 0.5335 - val_loss: 1.0635 - val_acc: 0.5957\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 48us/step - loss: 1.0078 - acc: 0.5576 - val_loss: 1.0737 - val_acc: 0.5851\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 70us/step - loss: 1.0778 - acc: 0.5121 - val_loss: 1.0707 - val_acc: 0.5851\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 66us/step - loss: 0.9954 - acc: 0.5737 - val_loss: 1.0625 - val_acc: 0.5957\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 76us/step - loss: 1.0188 - acc: 0.5684 - val_loss: 1.0528 - val_acc: 0.5957\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 67us/step - loss: 0.9492 - acc: 0.6059 - val_loss: 1.0421 - val_acc: 0.6064\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 76us/step - loss: 0.9519 - acc: 0.5657 - val_loss: 1.0314 - val_acc: 0.6064\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 66us/step - loss: 0.9597 - acc: 0.5818 - val_loss: 1.0203 - val_acc: 0.6064\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 66us/step - loss: 0.8977 - acc: 0.6220 - val_loss: 1.0109 - val_acc: 0.6064\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 70us/step - loss: 0.9405 - acc: 0.5952 - val_loss: 1.0027 - val_acc: 0.6064\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 61us/step - loss: 0.9026 - acc: 0.5925 - val_loss: 0.9944 - val_acc: 0.6170\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 73us/step - loss: 0.9043 - acc: 0.6059 - val_loss: 0.9878 - val_acc: 0.6170\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 72us/step - loss: 0.9077 - acc: 0.5979 - val_loss: 0.9843 - val_acc: 0.6277\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 64us/step - loss: 0.7955 - acc: 0.6622 - val_loss: 0.9841 - val_acc: 0.6170\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 61us/step - loss: 0.9083 - acc: 0.6139 - val_loss: 0.9865 - val_acc: 0.6170\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "# make keras model\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(df['Subclass'].value_counts()), activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_for_keras,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test_for_keras),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        es,\n",
    "#         lr_decay\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save('../model/Keras_ng_fs.h5')\n",
    "t.append(round(model.evaluate(X_test, y_test_for_keras, verbose=0)[1]*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Keras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature_Selection_Positive</th>\n",
       "      <td>71.43</td>\n",
       "      <td>84.52</td>\n",
       "      <td>81.25</td>\n",
       "      <td>61.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_Selection_Negative</th>\n",
       "      <td>70.21</td>\n",
       "      <td>72.34</td>\n",
       "      <td>73.40</td>\n",
       "      <td>61.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Random Forest  LightGBM  XGBoost  Keras\n",
       "Feature_Selection_Positive          71.43     84.52    81.25  61.61\n",
       "Feature_Selection_Negative          70.21     72.34    73.40  61.70"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    f, \n",
    "    columns=['Random Forest', 'LightGBM', 'XGBoost', 'Keras'],\n",
    "    index=['Feature_Selection_Positive', 'Feature_Selection_Negative']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    f, \n",
    "    columns=['Random Forest', 'LightGBM', 'XGBoost', 'Keras'],\n",
    "    index=['Feature_Selection_Positive', 'Feature_Selection_Negative']\n",
    ").to_csv('../result/Feature_Selection_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
